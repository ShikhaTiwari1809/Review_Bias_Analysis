paper_id,title,abstract,authors,authorids,keywords,primary_area,venue,year,pdf_url,forum_url
PxL35zAxvT,Test Time Adaptation with Auxiliary Tasks,"This work work tackles a key challenge in Test Time Adaptation~(TTA): adapting on limited data. This challenge arises naturally from two scenarios. (i) Current TTA methods are limited by the bandwidth with which the stream reveals data, since conducting several adaptation steps on each revealed batch from the stream will lead to overfitting. (ii) In many realistic scenarios, the stream reveals insufficient data for the model to fully adapt to a given distribution shift. We tackle the first scenario problem with auxiliary tasks where we leverage unlabeled data from the training distribution. In particular, we propose distilling the predictions of an originally pretrained model on clean data during adaptation. We found that our proposed auxiliary task significantly accelerates the adaptation to distribution shifts. We report a performance improvement over the state of the art by 1.5% and 6% on average across all corruptions on ImageNet-C under episodic and continual evaluation, respectively. To combat the second scenario of limited data, we analyze the effectiveness of combining federated adaptation with our proposed auxiliary task across different models even when different clients observe different distribution shifts. We find that not only federated averaging enhances adaptation, but combining it with our auxiliary task provides a notable 6% performance improvement over previous TTA methods.","Motasem Alfarra, Alvaro Correia, Bernard Ghanem, Christos Louizos","~Motasem_Alfarra1, ~Alvaro_Correia1, ~Bernard_Ghanem1, ~Christos_Louizos1","Test Time Adaptation, Auxiliary Tasks","transfer learning, meta learning, and lifelong learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=PxL35zAxvT,https://openreview.net/forum?id=PxL35zAxvT
ZiYdjVDgYY,Online Learning in Varying Feature Spaces with Informative Variation,"Most conventional online learning literature implicitly assumed a static feature space, while in practice the feature space may vary over time with the emerging of new features and vanishing of outdated features, which is named as online learning with Varying Feature Space (VFS). There have been increasing attention that initiated the exploration into this novel online learning paradigm. However, none of them was aware of the potentially informative information embodied as presence / absence (i.e., variation in this paper) for each feature, which indicates that the existence of some features of this VFS can be correlated with the class labels. Such information can be potentially beneficial to predictive performance if properly used for the learning purpose. To this end, we formally formulate this specific learning scenario, namely Online learning in Varying Feature space with Informative Variation (OVFIV), and present a learning framework to address this problem. The essence of the framework aim for answering the following two questions: how to learn a model to capture the association of the existence of features with the class labels and how to incorporate such information into the prediction process in order to gain performance improvement. Theoretical analyses and empirical studies based on 17 datasets from diverse fields verify the validity of our proposed method.","Peijia Qin, Liyan Song, Xin Yao","~Peijia_Qin1, ~Liyan_Song1, ~Xin_Yao1","online learning, varying feature space, variation feature space, infomative message","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=ZiYdjVDgYY,https://openreview.net/forum?id=ZiYdjVDgYY
PwoplYNsBI,Demystifying the Myths and Legends of Nonconvex Convergence of SGD,"Stochastic gradient descent (SGD) and its variants are the main workhorses for solving large-scale optimization problems with nonconvex objective functions. Although the convergence of SGDs in the (strongly) convex case is well-understood, their convergence for nonconvex functions stands on weak mathematical foundations. Most existing studies on the nonconvex convergence of SGD show the complexity results based on either the minimum of the expected gradient norm or the functional sub-optimality gap (for functions with extra structural property) by searching the entire range of iterates. Hence the last iterations of SGDs do not necessarily maintain the same complexity guarantee. This paper shows that an $\epsilon$-stationary point exists in the final iterates of SGDs, given a large enough total iteration budget, $T$, not just anywhere in the entire range of iterates --- a much stronger result than the existing one. Additionally, our analyses allow us to measure the \emph{density of the $\epsilon$-stationary points} in the final iterates of SGD, and we recover the classical ${O(\frac{1}{\sqrt{T}})}$ asymptotic rate under various existing assumptions on the objective function and the bounds on the stochastic gradient. As a result of our analyses, we addressed certain myths and legends related to the nonconvex convergence of SGD and posed some thought-provoking questions that could set new directions for research.","Aritra Dutta, El houcine Bergou, Soumia Boucherouite, Nicklas Werge, Melih Kandemir, Xin Li","~Aritra_Dutta1, ~El_houcine_Bergou1, ~Soumia_Boucherouite1, ~Nicklas_Werge1, ~Melih_Kandemir1, ~Xin_Li39","Stochastic gradient descent, nonconvex optimization, nonsmooth optimization, random-reshuffling stochstic gradient descent, nonconvex convergence",optimization,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=PwoplYNsBI,https://openreview.net/forum?id=PwoplYNsBI
KY8ZNcljVU,NetInfoF Framework: Measuring and Exploiting Network Usable Information,"Given a node-attributed graph, and a graph task (link prediction or node classification), can we tell if a graph neural network (GNN) will perform well? More specifically, do the graph structure and the node features carry enough usable information for the task? Our goals are
(1) to develop a fast tool to measure how much information is in the graph structure and in the node features, and
(2) to exploit the information to solve the task, if there is enough.
We propose NetInfoF, a framework including NetInfoF_Probe and NetInfoF_Act, for the measurement and the exploitation of network usable information (NUI), respectively. Given a graph data, NetInfoF_Probe measures NUI without any model training, and NetInfoF_Act solves link prediction and node classification, while two modules share the same backbone.
In summary, NetInfoF has following notable advantages:
(a) General, handling both link prediction and node classification;
(b) Principled, with theoretical guarantee and closed-form solution;
(c) Effective, thanks to the proposed adjustment to node similarity;
(d) Scalable, scaling linearly with the input size.
In our carefully designed synthetic datasets, NetInfoF correctly identifies the ground truth of NUI and is the only method being robust to all graph scenarios. Applied on real-world datasets, NetInfoF wins in 11 out of 12 times on link prediction compared to general GNN baselines.","Meng-Chieh Lee, Haiyang Yu, Jian Zhang, Vassilis N. Ioannidis, Xiang song, Soji Adeshina, Da Zheng, Christos Faloutsos","~Meng-Chieh_Lee1, ~Haiyang_Yu6, ~Jian_Zhang32, ~Vassilis_N._Ioannidis1, ~Xiang_song1, ~Soji_Adeshina1, ~Da_Zheng1, ~Christos_Faloutsos1","Graph Neural Networks, Information Theory, Heterophily Graphs",learning on graphs and other geometries & topologies,ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=KY8ZNcljVU,https://openreview.net/forum?id=KY8ZNcljVU
vRgMxGmEz9,SAM-guided Unsupervised Domain Adaptation for 3D Segmentation,"Unsupervised domain adaptation (UDA) in 3D segmentation tasks presents a formidable challenge, primarily stemming from the sparse and unordered nature of point cloud data.  Especially for LiDAR point clouds, the domain discrepancy becomes obvious across varying capture scenes, fluctuating weather conditions, and the diverse array of LiDAR devices in use. While previous UDA methodologies have often sought to mitigate this gap by aligning features between source and target domains, this approach falls short when applied to 3D segmentation due to the substantial domain variations. Inspired by the remarkable generalization capabilities exhibited by the vision foundation model, SAM, in the realm of image segmentation, our approach leverages the wealth of general knowledge embedded within SAM to unify feature representations across diverse 3D domains, and further solves the 3D domain adaptation problem. Specifically, we harness the corresponding images associated with point clouds to facilitate knowledge transfer and propose an innovative hybrid feature augmentation methodology, which significantly enhances the alignment between the 3D feature space and SAM's feature space, operating at both the scene and instance levels. Our method is evaluated on many widely-recognized datasets, and achieves state-of-the-art performance.","Xidong Peng, Runnan Chen, Feng Qiao, Lingdong Kong, Youquan Liu, Tai Wang, Xinge ZHU, Yuexin Ma","~Xidong_Peng1, ~Runnan_Chen1, ~Feng_Qiao1, ~Lingdong_Kong1, ~Youquan_Liu1, ~Tai_Wang2, ~Xinge_ZHU2, ~Yuexin_Ma2","scene understanding, 3D segmentation, unsupervised domain adaptation, vision foundation model","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=vRgMxGmEz9,https://openreview.net/forum?id=vRgMxGmEz9
85Af6AcMo5,SciRE-Solver: Accelerating  Diffusion Models Sampling by Score-integrand Solver with Recursive Difference,"One downside of Diffusion models (DMs) is their slow iterative process. Recent algorithms for fast sampling are designed from the 
differential equations. However, in the fast algorithms, estimating the derivative of the score function evaluations becomes intractable due to the complexity of large-scale, well-trained neural networks.  In this work, we introduce the recursive difference method to calculate the derivative of the score function networks. Building upon, we propose \emph{SciRE-Solver} with the convergence order guarantee for accelerating DMs sampling. Our proposed sampling algorithms attain SOTA FIDs in comparison to existing training-free sampling algorithms, 
under various number of score function evaluations (NFE).   Such as, we achieve $3.48$ FID with $12$ NFE, and $2.42$ FID with $20$ NFE for continuous-time model on CIFAR-10;  $1.79$ FID with $20$ NFE and  $1.76$ FID with $100$ NFE for the pretrained model of EDM. Experiments demonstrate also that demonstrate that SciRE-Solver with multi-step methods can achieve high-quality samples on popular text-to-image generation tasks with only 6$\sim$20 NFEs.","Shigui Li, Wei Chen, Delu Zeng","~Shigui_Li2, ~Wei_Chen52, ~Delu_Zeng4","Diffusion Models, Sampler, Accelerating",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=85Af6AcMo5,https://openreview.net/forum?id=85Af6AcMo5
NFAjyyeSfB,Enhancing Image Restoration Transformer with Adaptive Token Dictionary,"Image restoration is a classic computer vision problem that involves estimating high-quality (HQ) images from low-quality (LQ) ones. To compensate the information loss in the degradation process, prior knowledge of HQ image is indispensable. While deep neural networks (DNNs), especially Transformers for image restoration, have seen significant advancements in recent years, challenges still remain, particularly in the explicit incorporation of external priors, managing computational complexity, and tailoring generalized external priors to image specifics. To address these issues, we propose to enhance Transformer with Adaptive Token Dictionary (ATD), leading to a novel architecture which introduces a token dictionary to explicitly model external prior in the attention mechanism. The proposed ATD calculates the attention between the input features and the token dictionary, which integrates similar features on a global scale. Furthermore, we propose an adaptive dictionary refinement mechanism (ADR) to progressively customize the shared tokens to image specifics from shallow to deep layers. Crucially, benefiting from the condensed token dictionary, the computational complexity of the new attention mechanism is reduced from quadratic to linear with respect to the number of image tokens. This efficiency makes our network notably advantageous in constrained settings. Experimental results show that our method achieves best performance on various image restoration benchmark.","Leheng Zhang, Yawei Li, Xingyu Zhou, Xiaorui Zhao, Shuhang Gu","~Leheng_Zhang2, ~Yawei_Li1, ~Xingyu_Zhou4, ~Xiaorui_Zhao1, ~Shuhang_Gu3","image restoration, transformer, dictionary learning","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=NFAjyyeSfB,https://openreview.net/forum?id=NFAjyyeSfB
Uhxtq4nCzS,"Divergence at the Interpolation Threshold: Identifying, Interpreting & Ablating the Sources of a Deep Learning Puzzle","Machine learning models misbehave, often in unexpected ways. One prominent misbehavior is when the test loss diverges at the interpolation threshold, perhaps best known from its distinctive appearance in double descent. While considerable theoretical effort has gone into understanding generalization of overparameterized models, less effort has been made at understanding why the test loss misbehaves at the interpolation threshold. Moreover, analytically solvable models in this area employ a range of assumptions and use complex techniques from random matrix theory, statistical mechanics, and kernel methods, making it difficult to assess when and why test error might diverge; for instance, recent work found a divergence in noise-free toy nonlinear autoencoders, surprising the authors and raising questions about whether such an outcome should have been anticipated. In this work, we analytically study the simplest supervised model - ordinary linear regression - and show intuitively and rigorously when and why a divergence occurs at the interpolation threshold using basic linear algebra. We identify three interpretable factors that, when simultaneously all present, cause double descent. We demonstrate on real data that both models' test losses diverge at the interpolation threshold and that the divergence disappears when we ablate any one of the three identified factors. We conclude by using our fresh perspective to shed light on recent observations in nonlinear models concerning superposition and double descent.","Rylan Schaeffer, Zachary Robertson, Akhilan Boopathy, Mikail Khona, Ila R Fiete, Andrey Gromov, Sanmi Koyejo","~Rylan_Schaeffer2, ~Zachary_Robertson1, ~Akhilan_Boopathy1, ~Mikail_Khona2, ~Ila_R_Fiete1, ~Andrey_Gromov1, ~Sanmi_Koyejo1","mechanistic interpretability, interpretability, double descent",visualization or interpretation of learned representations,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=Uhxtq4nCzS,https://openreview.net/forum?id=Uhxtq4nCzS
BifeBRhikU,PB-LLM: Partially Binarized Large Language Models,"This paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. 
Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. 
Specifically, our exploration first uncovers the ineffectiveness of naïve applications of existing binarization algorithms and highlights the imperative role of salient weights in achieving low-bit quantization. 
Thus, PB-LLM filters a small ratio of salient weights during binarization, allocating them to higher-bit storage, i.e., partially-binarization. 
PB-LLM is extended to recover the capacities of quantized LMMs, by analyzing from the perspective of post-training quantization (PTQ) and quantization-aware training (QAT). 
Under PTQ, combining the concepts from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian matrix and successfully recover the reasoning capacity of PB-LLM in low-bit. 
Under QAT, we freeze the salient weights during training, explore the derivation of optimal scaling factors crucial for minimizing the quantization error, and propose a scaling mechanism based on this derived scaling strategy for residual binarized weights. 
Those explorations and the developed methodologies significantly contribute to rejuvenating the performance of low-bit quantized LLMs and present substantial advancements in the field of network binarization for LLMs. 
Code is available at https://github.com/hahnyuan/PB-LLM.","Zhihang Yuan, Yuzhang Shang, Zhen Dong","~Zhihang_Yuan1, ~Yuzhang_Shang1, ~Zhen_Dong3","Large Language Model, Network Compression",generative models,ICLR 2024 poster,2024,https://openreview.net/pdf?id=BifeBRhikU,https://openreview.net/forum?id=BifeBRhikU
xh3XUaB8M9,Visual Evidence Prompting Mitigates Hallucinations in Multimodal Large Language Models,"Despite the promising progress achieved, Large Vision-Language Models (LVLMs)  still suffer from the hallucination problem, i.e., they tend to predict objects and relations which are non-existent in the target images. These unfaithful outputs degrade the model performance and greatly harm the user experiences in real-world applications.  Fortunately, traditional small visual models excel at producing professional and faithful outputs, but they are not adept at interacting with humans. Therefore, this work explores how small visual models complement the LVLMs by effectively extracting contextual information from images to generate precise answers.
In particular, we show how such hallucination mitigates naturally in LVLMs via a simple method called visual evidence prompting, where a few visual knowledge evidences are provided as contexts in prompting. Experiments on three large language models show that visual evidence prompting improves performance on the evaluation of object hallucinations, as well as the new benchmark for relation hallucinations. We hope our work will not only serve as the minimal strongest baseline for the challenging hallucination benchmarks, but also highlight the importance of carefully exploring and analyzing the enormous visual evidence hidden inside small visual models before crafting ﬁnetuning LVLMs.","Wei Li, Zhen Huang, Houqiang Li, Le Lu, Yang Lu, Xinmei Tian, Xu Shen, Jieping Ye","~Wei_Li52, ~Zhen_Huang4, ~Houqiang_Li1, ~Le_Lu3, ~Yang_Lu5, ~Xinmei_Tian1, ~Xu_Shen1, ~Jieping_Ye4","Large Vision-Language Models, Hallucination, Visual model","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=xh3XUaB8M9,https://openreview.net/forum?id=xh3XUaB8M9
gzYgsZgwXa,Path Choice Matters for Clear Attributions in Path Methods,"Rigorousness and clarity are both essential for interpretations of DNNs to engender human trust. Path methods are commonly employed to generate rigorous attributions that satisfy three axioms. However, the meaning of attributions remains ambiguous due to distinct path choices. To address the ambiguity, we introduce Concentration Principle, which centrally allocates high attributions to indispensable features, thereby endowing aesthetic and sparsity. We then present SAMP, a model-agnostic interpreter, which efficiently searches the near-optimal path from a pre-defined set of manipulation paths. Moreover, we propose the infinitesimal constraint (IC) and momentum strategy (MS) to improve the rigorousness and optimality. Visualizations show that SAMP can precisely reveal DNNs by pinpointing salient image pixels.
We also perform quantitative experiments and observe that our method significantly outperforms the counterparts.","Borui Zhang, Wenzhao Zheng, Jie Zhou, Jiwen Lu","~Borui_Zhang1, ~Wenzhao_Zheng1, ~Jie_Zhou3, ~Jiwen_Lu1","explainable AI, integrated gradient, attribution, path method",visualization or interpretation of learned representations,ICLR 2024 poster,2024,https://openreview.net/pdf?id=gzYgsZgwXa,https://openreview.net/forum?id=gzYgsZgwXa
ZuYvrjh2od,ReForm-Eval: Evaluating Large Vision Language Models via Unified Re-Formulation of Task-Oriented Benchmarks,"Recent years have witnessed remarkable progress in the development of large vision-language models (LVLMs). Benefiting from the strong language backbones and efficient cross-modal alignment strategies, LVLMs exhibit surprising capabilities to perceive visual signals and perform visually grounded reasoning. However, the capabilities of LVLMs have not been comprehensively and quantitatively evaluated, as most existing multi-modal benchmarks require task-oriented input-output formats, posing great challenges to automatically assess the free-form text output of LVLMs. To effectively leverage the annotations available in existing benchmarks and reduce the manual effort required for constructing new benchmarks, we propose to re-formulate existing benchmarks into unified LVLM-compatible formats. Through systematic data collection and reformulation, we present the ReForm-Eval benchmark, offering substantial data for evaluating various capabilities of LVLMs. Based on ReForm-Eval, we conduct extensive experiments, thoroughly analyze the strengths and weaknesses of existing LVLMs, and identify the underlying factors. Our benchmark and evaluation framework will be open-sourced as a cornerstone for advancing the development of LVLMs.","Zejun Li, Ye Wang, Mengfei Du, Qingwen Liu, Binhao Wu, Jiwen Zhang, Chengxing Zhou, Zhihao Fan, Jie Fu, Jingjing Chen, zhongyu wei","~Zejun_Li1, ~Ye_Wang24, ~Mengfei_Du1, ~Qingwen_Liu3, ~Binhao_Wu1, ~Jiwen_Zhang1, ~Chengxing_Zhou1, ~Zhihao_Fan1, ~Jie_Fu2, ~Jingjing_Chen3, ~zhongyu_wei1","Benchmarks, Large Vision-Language Model Evaluation, Multi-modal Large Language Model Evaluation",datasets and benchmarks,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=ZuYvrjh2od,https://openreview.net/forum?id=ZuYvrjh2od
E296x0YpML,Fooling the Textual Fooler via Randomizing Latent Representations,"Despite outstanding performance in a variety of NLP tasks, recent studies have revealed that NLP models are vulnerable to adversarial attacks that slightly perturb the input to cause the models to misbehave. Among these attacks, adversarial word-level perturbations are well-studied and effective attack strategies. These attacks involve querying the victim model many times to determine the most important words in an input text and to replace these words with their corresponding synonyms. Query-based attacks as such work in black-box settings, which can be detrimental to NLP applications that can be accessed publicly. In this work, we propose a lightweight and attack-agnostic defense whose main goal is to perplex the process of generating an adversarial example in these query-based black-box attacks; that is to fool the textual fooler. This defense, named AdvFooler, works by randomizing the latent representation of the input at inference time. Different from existing defenses, AdvFooler does not necessitate additional computational overhead during training nor relies on assumptions about the potential adversarial perturbation set while having a negligible impact on the model's accuracy. Our theoretical and empirical analyses highlight the significance of robustness resulting from confusing the adversary via randomizing the latent space, as well as the impact of randomization on clean accuracy. Finally, we empirically demonstrate the near state-of-the-art robustness of AdvFooler against representative adversarial word-level attacks on two benchmark datasets.","Duy Cao Hoang, Nguyen Hung-Quang, Saurav Manchanda, Minlong Peng, Kok-Seng Wong, Khoa D Doan","~Duy_Cao_Hoang1, ~Nguyen_Hung-Quang1, ~Saurav_Manchanda1, ~Minlong_Peng1, ~Kok-Seng_Wong1, ~Khoa_D_Doan1","NLP, Adversarial Defense, Robustbess","societal considerations including fairness, safety, privacy",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=E296x0YpML,https://openreview.net/forum?id=E296x0YpML
auUngos7eR,Implicit Maximum a Posteriori Filtering via Adaptive Optimization,"Bayesian filtering approximates the true underlying behavior of a time-varying system by inverting an explicit generative model to convert noisy measurements into state estimates. This process typically requires matrix storage, inversion, and multiplication or Monte Carlo estimation, none of which are practical in high-dimensional state spaces such as the weight spaces of artificial neural networks. Here, we consider the standard Bayesian filtering problem as optimization over a time-varying objective. Instead of maintaining matrices for the filtering equations or simulating particles, we specify an optimizer that defines the Bayesian filter implicitly. In the linear-Gaussian setting, we show that every Kalman filter has an equivalent formulation using K steps of gradient descent. In the nonlinear setting, our experiments demonstrate that our framework results in filters that are effective, robust, and scalable to high-dimensional systems, comparing well against the standard toolbox of Bayesian filtering solutions. We suggest that it is easier to fine-tune an optimizer than it is to specify the correct filtering equations, making our framework an attractive option for high-dimensional filtering problems.","Gianluca Bencomo, Jake Snell, Thomas L. Griffiths","~Gianluca_Bencomo1, ~Jake_Snell1, ~Thomas_L._Griffiths1","Bayesian filtering, optimization, neural networks","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2024 poster,2024,https://openreview.net/pdf?id=auUngos7eR,https://openreview.net/forum?id=auUngos7eR
8euJaTveKw,Prometheus: Inducing Fine-Grained Evaluation Capability in Language Models,"Recently, GPT-4 has become the de facto evaluator for long-form text generated by large language models (LLMs). However, for practitioners and researchers with large and custom evaluation tasks, GPT-4 is unreliable due to its closed-source nature, uncontrolled versioning, and prohibitive costs. In this work, we propose PROMETHEUS a fully open-source LLM that is on par with GPT-4’s evaluation capabilities when the appropriate reference materials (reference answer, score rubric) are accompanied. For this purpose, we construct a new dataset – FEEDBACK COLLECTION – that consists of 1K fine-grained score rubrics, 20K instructions, and 100K natural language feedback generated by GPT-4. Using the FEEDBACK COLLECTION, we train PROMETHEUS, a 13B evaluation-specific LLM that can assess any given response based on novel and unseen score rubrics and reference materials provided by the user. Our dataset’s versatility and diversity make our model generalize to challenging real-world criteria, such as prioritizing conciseness, child-readability, or varying levels of formality. We show that PROMETHEUS shows a stronger correlation with GPT-4 evaluation compared to ChatGPT on seven evaluation benchmarks (Two Feedback Collection testsets, MT Bench, Vicuna Bench, Flask Eval, MT Bench Human Judgment, and HHH Alignment), showing the efficacy of our model and dataset design. During human evaluation with hand-crafted score rubrics, PROMETHEUS shows a Pearson correlation of 0.897 with human evaluators, which is on par with GPT-4-0613 (0.882), and greatly outperforms ChatGPT (0.392). Remarkably, when assessing the quality of the generated feedback, PROMETHEUS demonstrates a win rate of 58.62% when compared to GPT-4 evaluation and a win rate of 79.57% when compared to ChatGPT evaluation. Our findings suggests that by adding reference materials and training on GPT-4 feedback, we can obtain effective open-source evaluator LMs.","Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, Minjoon Seo","~Seungone_Kim1, ~Jamin_Shin1, ~Yejin_Cho2, ~Joel_Jang1, ~Shayne_Longpre1, ~Hwaran_Lee1, ~Sangdoo_Yun1, ~Seongjin_Shin1, ~Sungdong_Kim1, ~James_Thorne1, ~Minjoon_Seo1","automatic evaluation, large language models, llm-as-a-judge",datasets and benchmarks,ICLR 2024 poster,2024,https://openreview.net/pdf?id=8euJaTveKw,https://openreview.net/forum?id=8euJaTveKw
HeNuL50C60,CARD: Certifiable Reweighting for Single Domain Generalization Object Detection,"Single Domain Generalization Object Detection (S-DGOD) is a challenging yet practical task, where we only have access to data from one specific source domain to train an object detection network, but have to generalize to numerous unseen target domains. Recent works point out that the learning dynamics of Deep Neural Networks (DNNs) are biased by gradient descent to learn simple semantics, which are usually non-causal and spuriously correlated to the ground truth labels, as a result, DNN-based object detection networks fail to consistently generalize well in the Out-of-Domain (OoD) scenario. In this paper, we focus on S-DGOD based on theoretical analysis, exploring a classic and widely-used approach, Generalizable Reweighting (GRW), which iteratively reweightes the training samples to improve generalization performance. In our theoretical analysis, we first identify that the vanilla GRW hardly outperforms Empirical Risk Minimization (ERM) in the S-DGOD scenario. To provide a generalization guarantee, we further derive Certifiable Feature Perturbation (CFP) based on our theory, which aims to train a robust object detection network against additional perturbations added to the extracted features. We demonstrate that GRW works well with CFP in achieving OoD generalization, thus, surpassing ERM by a large margin under worse conditions. This brand new reweighting strategy is named Certifiable Reweighting (CARD). Our extensive experiments show that the proposed CARD achieves SOTA performance compared to baseline methods on the five urban-scene S-DGOD benchmarks.","Fan Wu, Xue Zhao, Jinling Gao, Nanyang Ye","~Fan_Wu14, ~Xue_Zhao4, ~Jinling_Gao1, ~Nanyang_Ye1","single domain generalization, object detection","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=HeNuL50C60,https://openreview.net/forum?id=HeNuL50C60
UHIKtKzTj7,PAPM: A Physics-aware Proxy Model for Process Systems,"Process systems, which play a fundamental role in various scientific and engineering fields, often rely on computational models to capture their complex temporal-spatial dynamics. However, due to limited insights into the intricate physical principles, these models can be imprecise or inapplicable, coupled with a significant computational demand exacerbating inefficiencies. To address these challenges, we propose a physics-aware proxy model (PAPM) to explicitly incorporate partial prior mechanistic knowledge, including conservation and constitutive relations. Additionally, to enhance the inductive biases about strict physical laws and broaden the applicability scope, we introduce a holistic temporal and spatial stepping method (TSSM) aligned with the distinct equation characteristics of different process systems, resulting in better out-of-sample generalization. We systematically compare state-of-the-art pure data-driven models and physics-aware models, spanning five two-dimensional non-trivial benchmarks in nine generalization tasks. Notably, PAPM achieves an average absolute performance improvement of 6.4%, while requiring fewer FLOPs, and only 1% of the parameters compared to the prior leading method, PPNN. Through such analysis, the structural design and specialized spatio-temporal modeling schemes (i.e., TSSM) of PAPM exhibit not only the most balanced trade-off between accuracy and computational efficiency among all methods evaluated, but also an impressive out-of-sample generalization.","Pengwei Liu, Zhongkai Hao, Xingyu Ren, Hangjie Yuan, Dong Ni","~Pengwei_Liu1, ~Zhongkai_Hao1, ~Xingyu_Ren2, ~Hangjie_Yuan1, ~Dong_Ni3","Process systems modeling, Physics-informed machine learning, Temporal-spatial stepping method, Out-of-sample generalizability.","neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=UHIKtKzTj7,https://openreview.net/forum?id=UHIKtKzTj7
likXVjmh3E,The Expressive Power of Low-Rank Adaptation,"*Low-Rank Adaptation* (LoRA), a parameter-efficient fine-tuning method that leverages low-rank adaptation of weight matrices, has emerged as a prevalent technique for fine-tuning pre-trained models such as large language models and diffusion models.
Despite its huge success in practice, the theoretical underpinnings of LoRA have largely remained unexplored. 
This paper takes the first step to bridge this gap by theoretically analyzing the expressive power of LoRA. 
We prove that, for fully connected neural networks, LoRA can adapt any model $f$ to accurately represent any smaller target model $\bar{f}$ if LoRA-rank $\geq(\text{width of }f) \times \frac{\text{depth of }\bar{f}}{\text{depth of }f}$, under a mild assumption. 
We also quantify the approximation error when the LoRA-rank is lower than the threshold. 
For Transformer networks, we show any model can be adapted to a target model of the same size with rank-$(\frac{\text{embedding size}}{2})$ LoRA adapters.
All our theoretical insights are validated by numerical experiments.","Yuchen Zeng, Kangwook Lee","~Yuchen_Zeng1, ~Kangwook_Lee1","LoRA, expressive power, parameter-efficient fine-tuning, adaptation, neural networks, transformer",learning theory,ICLR 2024 poster,2024,https://openreview.net/pdf?id=likXVjmh3E,https://openreview.net/forum?id=likXVjmh3E
1GdAJ3GsOw,DISTPAR:TENSOR PARTITIONING FOR DISTRIBUTED NEURAL NETWORK COMPUTING,"Existing distributed training systems suffer from the difficulties of adapting to diverse model architectures and balancing the trade-off between computational and communication costs. We introduce Distributed Partitioning (DistPar), a framework that allows users to develop parallel models with the ease of writing single-device programs. We establish the basic properties of tensor partitioning, which significantly expand the search space for optimal parallel strategies. The process of distributing global tensors from a single-device perspective is driven by the innovative use of collective communication primitives and their extensions which represent conversions between arbitrary tensor distribution properties. To further address the challenge of parallel scheme optimization, we carry out a cost function that considers both computational and communication costs. Guided by the cost function, the best-performing parallel scheme is automatically selected with configurable parameters, thus simplifying the process of developing parallel models. We demonstrate state-of-the-art results on extensive experiments. Moreover, DistPar reaches 50% higher throughput in large-scale face recognition tasks and a 20% improvement in language modeling tasks compared to data parallelism provided by PyTorch. This performance improvement aligns with the expected speedup and is particularly notable as the number of computing devices increases. The code will be released at https://github.com/DistPar.","Hongsheng Wang, Jinhui Yuan, Shun Liu, Weijie Xia, Xinyi Zhou, Shengyu Zhang, Fei Wu, Mohamed Jaward Bah, Feng Lin","~Hongsheng_Wang1, ~Jinhui_Yuan1, ~Shun_Liu1, ~Weijie_Xia1, ~Xinyi_Zhou5, ~Shengyu_Zhang2, ~Fei_Wu1, ~Mohamed_Jaward_Bah1, ~Feng_Lin10","Deep Learning Framework, Tensor Partitioning, Parallel Computation","infrastructure, software libraries, hardware, etc.",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=1GdAJ3GsOw,https://openreview.net/forum?id=1GdAJ3GsOw
jolYuxpVn1,FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios,"The emergence of generative pre-trained models has facilitated the synthesis of high-quality text but has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) The content generated by these models tends to be lengthy and lacks clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a tool augmented multi-task and multi-domain framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.","I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu","~I-Chun_Chern1, ~Steffi_Chern1, ~Shiqi_Chen3, ~Weizhe_Yuan1, ~Kehua_Feng1, ~Chunting_Zhou1, ~Junxian_He1, ~Graham_Neubig1, ~Pengfei_Liu1","Factuality, LLM","general machine learning (i.e., none of the above)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=jolYuxpVn1,https://openreview.net/forum?id=jolYuxpVn1
MK7TEe7SJ3,USTAM: UNIFIED SPATIO-TEMPORAL ATTENTION MIXFORMER FOR VISUAL OBJECT TRACKING,"In this paper, we present a unified spatio-temporal attention MixFormer framework for visual object tracking. Within the vision transformer framework, we design a cohesive network consisting of target template and search region feature extraction, cross-attention utilizing spatial and temporal information, and task-specific heads, all operating in an end-to-end manner. Incorporating spatial and temporal attention modules within the network enables simultaneous feature extraction and emphasis, allowing the model to concentrate on target-specific discriminative features despite changes in illumination, occlusion, scale, camera pose, and background clutter. Stacking multiple non-hierarchical blocks allows meaningful features to be extracted while irrelevant features are discarded from the provided target template and search region. The simultaneous spatio-temporal attention module is employed to accentuate target appearance features and alleviate variation in the object state across frame sequences. Qualitative and quantitative analysis, including ablation tests based on various tracking benchmarks, validates the robustness of the proposed tracking methodology.","Minho Park, Jinjoo Song, Gangjoon Yoon, Sang Min Yoon","~Minho_Park4, ~Jinjoo_Song1, ~Gangjoon_Yoon1, ~Sang_Min_Yoon1","Visual object tracking, Spartiotemporal attention","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=MK7TEe7SJ3,https://openreview.net/forum?id=MK7TEe7SJ3
HDbKLu0bkn,Heterogeneity of Regularization between adjacent periods,"Since the inception of deep learning, regularization techniques have been developed for the purpose of preventing the overfitting phenomenon. Regularization is typically accomplished in two ways: incorporating randomness (e.g., injecting noise into data, activating nodes, or using dropout) or heterogeneity (e.g., data augmentation). These approaches are known to lead to better generalization and, consequently, improved performance. In the case of introducing heterogeneity by adjusting the hyperparameter during the training process, such as the drop rate of dropout, experiments have shown that tuning hyperparameters after a period, which consists of a certain number of forward propagations, is more effective than either uniformly sustaining hyperparameters or tuning them during every propagation. Therefore, this paper proposes a novel regularization technique named Periodic Regularization that introduces periodicity into the dynamic hyperparameter tuning of other regularization methods. Furthermore, this paper suggests combining Periodic Regularization and other learning techniques such as Reinforcement Learning and Transfer Learning. This approach, particularly when combining dropout and reinforcement learning, shows significant improvement in empirical testing across various popular datasets. This is notably evident in Facial Expression Recognition (FER) tasks, where conventional methods, such as noise injection and dropout, have proven ineffective. Our proposed periodic regularization method not only can fill the research gap found in traditional regularization techniques but also can be a cornerstone for further research where the concept of periodic regularization is combined with diverse vanilla regularization techniques and learning techniques.","SangHwa Hong, Bongseok Kim, Min Kyu Sim","~SangHwa_Hong1, ~Bongseok_Kim1, ~Min_Kyu_Sim1","Regularization, Heterogeneity, Periodic Regularization, Reinforcement Learning, Transfer Learning","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=HDbKLu0bkn,https://openreview.net/forum?id=HDbKLu0bkn
xmQuUqSynb,Rethinking Adversarial Robustness in the Context of the Right to be Forgotten,"The past few years have seen an intense research interest in the practical needs of the ""right to be forgotten"", which enables machine learning models to unlearn a fraction of training data and its lineage. As a result of this growing interest, numerous machine unlearning methods have been proposed and developed to address this important aspect of data privacy. While existing machine unlearning methods prioritize the protection of individuals' private and sensitive data, they overlook investigating the unlearned models' susceptibility to adversarial attacks and security breaches. In this work, we uncover a novel security vulnerability of machine unlearning based on the insight that the adversarial vulnerabilities can be bolstered especially for adversarial robust models. To exploit this observed vulnerability, we propose a novel attack called Adversarial Unlearning Attack (AdvUA), which aims to generate a small fraction of malicious unlearning requests during the unlearning process. AdvUA causes a significant reduction of adversarial robustness in the unlearned model compared to the original model, providing an entirely new capability for adversaries that is infeasible in conventional machine learning pipelines. Notably, we also show that AdvUA can effectively enhance model stealing attacks by extracting additional decision boundary information, further emphasizing the breadth and significance of our research. Extensive numerical studies are conducted to demonstrate the effectiveness of the proposed attack. Our code is available in the supplementary material.","CHENXU ZHAO, Wei Qian, Yangyi Li, Wang Li, Mengdi Huai","~CHENXU_ZHAO2, ~Wei_Qian5, ~Yangyi_Li1, ~Wang_Li6, ~Mengdi_Huai1","Adversarial robustness, Machine unlearning, Model stealing attack","societal considerations including fairness, safety, privacy",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=xmQuUqSynb,https://openreview.net/forum?id=xmQuUqSynb
VqEE9i6jhE,Tensor methods to learn the Green's function to solve high-dimensional PDE,"The method of Green's function plays an important role in solving PDEs. Recently deep learning models have been used to  explicitly learn the Green's function to  parameterize solutions of PDEs. DecGreenNet uses  low-rank decomposition of the Green's function to obtain computational efficiency by separated learning from training data and Monte-Carlo samples. However, learning from a large number of Monte-Carlo samples for a high-dimensional PDE can lead to slow training and large memory requirements. As a solution we investigate on learning the Green's function by using tensor product grids generated by  random  partitions of dimensions. We propose DecGreenNet-TT by applying tensor-train structured low-rank decomposition to the Green's function and replace its components with  neural networks  that learn from partitions of  each dimensions instead of all grid elements. We further propose  DecGreenNet-TT-C to learn with a reduced number of neural networks by combining dimensions to generate combined tensor product grids.  We further show that for the special case of separable source functions  the Green's function can be constructed without multiplication of all tensor-train component neural networks leading to memory and computational efficiency. Using several Poisson equations we show that the proposed methods can  learn  with a collection of smaller neural networks compared to DecGreenNet to  efficiently parameterize solutions with faster training times and low errors.","Kishan Wimalawarne, Taiji Suzuki","~Kishan_Wimalawarne2, ~Taiji_Suzuki1","Green's function, high-dimensional PDE, neural networks, tensor-train, low-rank, tensor product grid","general machine learning (i.e., none of the above)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=VqEE9i6jhE,https://openreview.net/forum?id=VqEE9i6jhE
NGVljI6HkR,Reclaiming the Source of Programmatic Policies: Programmatic versus Latent Spaces,"Recent works have introduced LEAPS and HPRL, systems that learn latent spaces of domain-specific languages, which are used to define programmatic policies for partially observable Markov decision processes (POMDPs). These systems induce a latent space while optimizing losses such as the behavior loss, which aim to achieve locality in program behavior, meaning that vectors close in the latent space should correspond to similarly behaving programs. In this paper, we show that the programmatic space, induced by the domain-specific language and requiring no training, presents values for the behavior loss similar to those observed in latent spaces presented in previous work. Moreover, algorithms searching in the programmatic space significantly outperform those in LEAPS and HPRL. To explain our results, we measured the ""friendliness"" of the two spaces to local search algorithms. We discovered that algorithms are more likely to stop at local maxima when searching in the latent space than when searching in the programmatic space. This implies that the optimization topology of the programmatic space, induced by the reward function in conjunction with the neighborhood function, is more conducive to search than that of the latent space. This result provides an explanation for the superior performance in the programmatic space.","Tales Henrique Carvalho, Kenneth Tjhia, Levi Lelis","~Tales_Henrique_Carvalho1, ~Kenneth_Tjhia1, ~Levi_Lelis1","programmatic policy, reinforcement learning","neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)",ICLR 2024 poster,2024,https://openreview.net/pdf?id=NGVljI6HkR,https://openreview.net/forum?id=NGVljI6HkR
JbOsMrwjZ3,BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge,"Pre-trained language models like ChatGPT have significantly improved code generation. As these models scale up, there is an increasing need for the output to handle more intricate tasks and to be appropriately specialized to particular domains. Bioinformatics provides an important domain. In this field generating functional programs poses additional notable challenges due to the amount of specialized domain knowledge, the need for complicated data operations, and intricate functional dependencies between the operations. Here, we present BioCoder, a benchmark developed to evaluate existing pre-trained models in generating bioinformatics code. In relation to function-code generation, BioCoder covers potential package dependencies, class declarations, and global variables. It incorporates 1026 functions and 1243 methods in Python and Java from GitHub and 253 examples from the Rosalind Project. BioCoder incorporates a fuzz-testing framework for evaluation, and we have applied it to evaluate many models including InCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+, InstructCodeT5+, GPT-3.5, and GPT-4. The results highlight two key aspects of successful models: 1) that they contain specific domain knowledge of bioinformatics (beyond just coding knowledge); 2) that they accommodate a long prompt with full context (i.e. functional dependencies).","Xiangru Tang, Bill Qian, Rick Gao, Jiakang Chen, Xinyun Chen, Mark Gerstein","~Xiangru_Tang2, ~Bill_Qian1, ~Rick_Gao1, ~Jiakang_Chen1, ~Xinyun_Chen1, ~Mark_Gerstein2","Code Generation, Benchmark, Large Language Models, Dataset",datasets and benchmarks,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=JbOsMrwjZ3,https://openreview.net/forum?id=JbOsMrwjZ3
hSyW5go0v8,"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called **Self-Reflective Retrieval-Augmented Generation (Self-RAG)** that enhances an LM's quality and factuality through retrieval and self-reflection. 
Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its generations using special tokens, called {\it reflection} tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. 
Experiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. 
Specifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning, and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. Our code and trained models are available at https://selfrag.github.io/","Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, Hannaneh Hajishirzi","~Akari_Asai2, ~Zeqiu_Wu1, ~Yizhong_Wang2, ~Avirup_Sil1, ~Hannaneh_Hajishirzi1","Retrieval-augmented Generation, Language Models, Retrieval-augmented LMs, Factuality","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 oral,2024,https://openreview.net/pdf?id=hSyW5go0v8,https://openreview.net/forum?id=hSyW5go0v8
fTiU8HhdBD,A Unified Framework for Reinforcement Learning under Policy and Dynamic Shifts,"Training reinforcement learning policies using environment interaction data collected from varying policies or dynamics presents a fundamental challenge. Existing works often overlook the distribution discrepancies induced by policy or dynamics shifts, or rely on specialized algorithms with task priors, thus often resulting in suboptimal policy performances and high variances. In this paper, we identify a unified strategy for online RL policy learning under diverse settings of policy and dynamics shifts: transition occupancy matching. In light of this, we introduce a surrogate policy learning objective by considering the transition occupancy discrepancies and then cast it into a tractable \textit{min-max} optimization problem through dual reformulation. Our method, dubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized actor-critic structure and a distribution discriminator. We conduct extensive experiments based on the OpenAI Gym, Meta-World, and Panda Robots environments, encompassing policy shifts under stationary and non-stationary dynamics, as well as domain adaption. The results demonstrate that OMPO outperforms the specialized baselines from different categories in all settings. We also find that OMPO exhibits particularly strong performance when combined with domain randomization, highlighting its potential in RL-based robotics applications.","Yu Luo, Tianying Ji, Fuchun Sun, Jianwei Dr. Zhang, Huazhe Xu, Xianyuan Zhan","~Yu_Luo5, ~Tianying_Ji2, ~Fuchun_Sun1, ~Jianwei_Dr._Zhang1, ~Huazhe_Xu1, ~Xianyuan_Zhan1","Reinforcement Learning, mismatched data, policy and dynamic shifts",reinforcement learning,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=fTiU8HhdBD,https://openreview.net/forum?id=fTiU8HhdBD
vnKf1jG5eK,Making Multimodal Generation Easier: When Diffusion Models Meet LLMS,"We present EasyGen, an efficient model designed to enhance multimodal understanding and generation by harnessing the capabilities of diffusion models and large language models (LLMs). Unlike existing multimodal models that predominately depend on encoders like CLIP or ImageBind and need ample amounts of training data to bridge the gap between modalities, EasyGen is built upon a bidirectional conditional diffusion model named BiDiffuser, which promotes more efficient interactions between modalities. EasyGen handles image-to-text generation by integrating BiDiffuser and an LLM via a simple projection layer. Unlike most existing multimodal models that are limited to generating text responses, EasyGen can also facilitate text-to-image generation by leveraging the LLM to create  textual descriptions, which can be interpreted by BiDiffuser to generate appropriate visual response. Extensive quantitative and qualitative experiments demonstrate the effectiveness of EasyGen, whose training can be easily achieved in a lab setting.","Xiangyu Zhao, Bo LIU, Qijiong Liu, Guangyuan SHI, Xiao-Ming Wu","~Xiangyu_Zhao6, ~Bo_LIU28, ~Qijiong_Liu1, ~Guangyuan_SHI1, ~Xiao-Ming_Wu1","Multimodal Generation, Diffusion Models, Large Language Models",generative models,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=vnKf1jG5eK,https://openreview.net/forum?id=vnKf1jG5eK
dteBEZiCxB,Necessary and Sufficient Watermark for Large Language Models,"In recent years, large language models (LLMs) have achieved remarkable performances in various NLP tasks. They can generate texts that are indistinguishable from those written by humans. Such remarkable performance of LLMs increases their risk of being used for malicious purposes, such as generating fake news articles. Therefore, it is necessary to develop methods for distinguishing texts written by LLMs from those written by humans. Watermarking is one of the most powerful methods for achieving this. Although existing watermarking methods have successfully detected text generated by LLMs, they significantly degrade the quality of the generated text. In this study, we propose the Necessary and Sufficient Watermark (NS-Watermark) for inserting watermarks into generated texts without degrading the text quality. More specifically, we derive minimum constraints required to be imposed on the generated texts to distinguish whether LLMs or humans write the texts. Then, we formulate NS-Watermark as a constrained optimization problem and propose an efficient algorithm to solve it. Through the experiments, we demonstrate that NS-Watermark can generate more natural texts than existing watermarking methods and distinguish more accurately between texts written by LLMs and those written by humans. Especially in machine translation tasks, the NS-Watermark can outperform the existing watermarking method by up to $30$ BLEU scores.","Yuki Takezawa, Ryoma Sato, Han Bao, Kenta Niwa, Makoto Yamada","~Yuki_Takezawa1, ~Ryoma_Sato1, ~Han_Bao2, ~Kenta_Niwa1, ~Makoto_Yamada3","watermarking method, large language models",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=dteBEZiCxB,https://openreview.net/forum?id=dteBEZiCxB
P6PPBq8K2B,Diffusion-based Data Generation for Out-of-Distribution Object Detection,"Generating out-of-distribution (OOD) data is critical for training OOD object detectors, enabling them to identify OOD objects or categories as ``unknown''. Previous methods may generate imprecise OOD features due to incorrect assumptions on in-distribution (ID) data distribution. In this paper, we propose to discard any distribution assumption, leveraging a diffusion model to faithfully model the ID data distribution, and design a filtering strategy to generate accurate OOD data samples for training an unknown-aware object detector. Unlike previous methods that rely on predefined parametric models for modeling distributions, our diffusion model captures the latent feature distributions of ID data, which allows us to synthesize data samples within a compact feature space. We further design a filtering strategy based on K-Nearest Neighbors (KNN) to select low-density data samples proximate to the ID data as generated OOD samples, which are more challenging and effective for improving the OOD detector. Our method is generic and can be easily integrated with existing baseline methods, demonstrating superior performance on multiple benchmark datasets. The code will be made publicly available.","Jiahui Liu, Xin Yu, Anlin Zheng, Kevin Li Sun, XIAOJUAN QI","~Jiahui_Liu2, ~Xin_Yu6, ~Anlin_Zheng1, ~Kevin_Li_Sun1, ~XIAOJUAN_QI2","OOD detection, diffusion model, object detection","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=P6PPBq8K2B,https://openreview.net/forum?id=P6PPBq8K2B
T1Y2KmVtUn,Differentiable Sensor Layouts for End-to-End Learning of Task-Specific Camera Parameters,"Computational imaging concepts based on integrated edge AI and and neural sensor concepts solve vision problems in an end-to-end, task-specific manner, by jointly optimizing the algorithmic and hardware parameters to sense data with high information value. They yield energy, data, and privacy efficient solutions, but rely on novel hardware concepts, yet to be scaled up. In this work, we present the first truly end-to-end trained imaging pipeline that optimizes imaging sensor parameters, available in standard CMOS design methods, jointly with the parameters of a given neural network on a specific task. Specifically, we derive an analytic, differentiable approach for the sensor layout parameterization that allows for task-specific, local varying  pixel resolutions. We present two pixel layout parameterization functions: rectangular and curvilinear grid shapes that retain a regular topology. We provide a drop-in module that approximates sensor simulation given existing high-resolution images to directly connect our method with existing deep learning models. We show that network predictions benefit from learnable pixel layouts for two different downstream tasks, classification and semantic segmentation. Moreover, we give a fully featured design for the hardware implementation of the learned chip layout for a semantic segmentation task.","Hendrik Sommerhoff, Shashank Agnihotri, Mohamed Emam Saleh, Michael Moeller, Margret Keuper, Bhaskar Choubey, Andreas Kolb","~Hendrik_Sommerhoff2, ~Shashank_Agnihotri1, ~Mohamed_Emam_Saleh1, ~Michael_Moeller1, ~Margret_Keuper1, ~Bhaskar_Choubey1, ~Andreas_Kolb1","sensors, computer vision, computer graphics, semantic segmentation, classification","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=T1Y2KmVtUn,https://openreview.net/forum?id=T1Y2KmVtUn
hkWHdI8ss5,SITTO: Single-Image Textured Mesh Reconstruction through Test-Time Optimization,"Reconstruction of a 3D textured mesh from a single image has been a long-standing and challenging problem. To address this challenge, we aim to leverage existing feed-forward-based models designed for predicting shape (i.e., textureless mesh) from a single image. However, there are difficulties that have to be overcome.  Firstly, methods that estimate shape using feed-forward approaches cannot always guarantee high-quality results. A test-time optimization technique with feedback loops specified to each target object instance is necessary to apply these methods practically.  To tackle this, we unlock the recent advancements in multi-view diffusion models, showing impressive multi-view image generation performances. Nonetheless, there are challenges associated with utilizing diffusion models. Specifically, it is crucial to estimate the viewpoint of the given reference image (i.e., its elevation and azimuth angles) and sample relative viewpoints from the reference viewpoint. We solely employ neural mesh representation and texture optimization to optimize training efficiency in terms of time and memory complexity. SITTO tackles these challenges by introducing an automatic pipeline for monocular 3D textured mesh reconstruction with test-time optimization. Our method demonstrates impressive results in fine-grained geometry details and the generation of realistic texture appearances.","Kim Yu-Ji, Hyunwoo Ha, Kim Youwang, Jaeheung Surh, Hyowon Ha, Tae-Hyun Oh","~Kim_Yu-Ji1, ~Hyunwoo_Ha1, ~Kim_Youwang1, ~Jaeheung_Surh2, ~Hyowon_Ha3, ~Tae-Hyun_Oh3","Feed-forward Mesh Prediction, Multi-View Diffusion, Test-Time Optimization, Textured Mesh Generation, DMTet, Physically Based Rendering (PBR)","general machine learning (i.e., none of the above)",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=hkWHdI8ss5,https://openreview.net/forum?id=hkWHdI8ss5
YSTaRLVP2G,The Power of Linear Combinations: Learning with Random Convolutions,"Following the traditional paradigm of convolutional neural networks (CNNs), modern CNNs manage to keep pace with more recent, for example, transformer-based, models by not only increasing model depth and width but also the kernel size. This results in large amounts of learnable model parameters that need to be handled during training. While following the convolutional paradigm with the according spatial inductive bias, we question the significance of *learned* convolution filters. In fact, our findings demonstrate that many contemporary CNN architectures can achieve high test accuracies without ever updating randomly initialized (spatial) convolution filters. Instead, simple linear combinations (implemented through efficient $1\times 1$ convolutions) suffice to effectively recombine even random filters into expressive network operators. Furthermore, these combinations of random filters can implicitly regularize the resulting operations, mitigating overfitting and enhancing overall performance and robustness. Conversely, retaining the ability to learn filter updates can impair network performance. Finally, although the improvement we see from learning $3\times 3$ convolutions is relatively small, the learning gains increase proportionally with kernel size. We attribute this to the independently and identically distributed (*i.i.d.*) nature of default initialization schemes.","Paul Gavrikov, Janis Keuper","~Paul_Gavrikov1, ~Janis_Keuper1","Convolution, random parameters","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=YSTaRLVP2G,https://openreview.net/forum?id=YSTaRLVP2G
JorjkFYatI,Go beyond End-to-End Training: Boosting Greedy Local Learning with Context Supply,"Traditional end-to-end (E2E) training of deep networks necessitates storing intermediate activations for back-propagation, resulting in a large memory footprint on GPUs and restricted model parallelization. As an alternative, greedy local learning partitions the network into gradient-isolated modules and trains supervisely based on local preliminary losses, thereby providing asynchronous and parallel training methods that substantially reduce memory cost. However, empirical experiments reveal that as the number of segmentations of the gradient-isolated module increases, the performance of the local learning scheme degrades substantially, severely limiting its expansibility. To avoid this issue, we theoretically analyze the greedy local learning from the standpoint of information theory and propose a ContSup scheme, which incorporates context supply between isolated modules to compensate for information loss. Experiments on benchmark datasets (i.e. CIFAR, SVHN, STL-10) achieve SOTA results and indicate that our proposed method can significantly improve the performance of greedy local learning with minimal memory and computational overhead, allowing for the boost of the number of isolated modules.","Chengting Yu, Fengzhao Zhang, Hanzhi Ma, Aili Wang, Erping Li","~Chengting_Yu1, ~Fengzhao_Zhang1, ~Hanzhi_Ma1, ~Aili_Wang2, ~Erping_Li1","Greedy Local Learning, End-to-End Training, Memory Cost Optimization, Model Parallelization",learning theory,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=JorjkFYatI,https://openreview.net/forum?id=JorjkFYatI
MtzHEqqUm0,In-Depth Comparison of Regularization Methods For Long-Tailed Learning in Trajectory Prediction,"Autonomous robots have the biggest potential for risk because they operate in open-ended environments where humans interact in complex, diverse ways. To operate, such systems must predict this behaviour, especially if it's part of the unexpected and potentially dangerous long tail of the dataset. Previous works on long-tailed trajectory prediction use models which do not predict a distribution of trajectories with likelihoods associated with each prediction. Furthermore, they report metrics which are biased by the ground-truth. Therefore, we aim to examine regularization methods for long-tailed trajectory prediction by comparing them on the KDE metric, which is designed to compare distributions of trajectories. Moreover, we are the first to report the performance of these methods on both the pedestrian and vehicle classes of the NuScenes dataset.","Divya Thuremella, Lars Kunze","~Divya_Thuremella1, ~Lars_Kunze1","Trajectory Prediction, Long-Tailed Learning, Imbalanced Regression, Autonomous Vehicles","applications to robotics, autonomy, planning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=MtzHEqqUm0,https://openreview.net/forum?id=MtzHEqqUm0
D3JpYSn7dL,An Instance-Level Framework for Multi-tasking Graph Self-Supervised Learning,"With hundreds of graph self-supervised pretext tasks proposed over the past few years, the research community has greatly developed, and the key is no longer to design more powerful but complex pretext tasks, but to make more effective use of those already on hand. There have been some pioneering works, such as AutoSSL and ParetoGNN, proposed to balance multiple pretext tasks by global loss weighting in the pre-training phase. Despite their great successes, several tricky challenges remain: (i) they ignore instance-level requirements, i.e., different instances (nodes) may require localized combinations of tasks; (ii) poor scalability to emerging tasks, i.e., all task losses need to be re-weighted along with the new task and pre-trained from scratch; (iii) no theoretical guarantee of benefiting from more tasks, i.e., more tasks do not necessarily lead to better performance. To address the above issues, we propose in this paper a novel multi-teacher knowledge distillation framework for instance-level Multi-tasking Graph Self-Supervised Learning (MGSSL), which trains multiple teachers with different pretext tasks, then integrates the knowledge of different teachers for each instance separately by two parameterized knowledge integration schemes (MGSSL-TS and MGSSL-LF), and finally distills it into the student model. Such a framework shifts the trade-off among multiple pretext tasks from loss weighting in the pre-training phase to knowledge integration in the fine-tuning phase, making it compatible with an arbitrary number of pretext tasks without the need to pre-train the entire model from scratch. Furthermore, we theoretically justify that MGSSL has the potential to benefit from a wider range of teachers (tasks). Extensive experiments have shown that by combining a few simple but classical pretext tasks, the resulting performance is comparable to the state-of-the-art competitors.","Lirong Wu, Tianyu Fan, Yufei Huang, Haitao Lin, Zicheng Liu, Stan Z. Li","~Lirong_Wu1, ~Tianyu_Fan1, ~Yufei_Huang4, ~Haitao_Lin2, ~Zicheng_Liu2, ~Stan_Z._Li2","Graph Self-supervised Learning, Graph Knowledge Distillation","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=D3JpYSn7dL,https://openreview.net/forum?id=D3JpYSn7dL
gmHtBH8Fnp,Biased Binary Attribute Classifiers Ignore the Majority Classes,"To visualize the regions of interest that classifiers base their decisions on, different Class Activation Mapping (CAM) methods have been developed.
However, all of these techniques target categorical classifiers only, though most real-world tasks are binary classification.
In this paper, we extend gradient-based CAM techniques to work with binary classifiers and visualize the active regions for binary attribute classifiers.
When training an unbalanced binary classifier on a biased dataset, it is well-known that the majority class is mostly predicted much better than minority class.
In our experiments on the CelebA dataset, we verify these results, when training an unbalanced classifier to extract 40 facial attributes simultaneously.
One would expect that the biased classifier has learned to extract features mainly for the majority classes and that the proportional energy of the activations mainly reside in certain specific regions of the image where the attribute is located.
However, we find very little regular activation for samples of majority classes, while the active regions for minority classes seem mostly reasonable and overlap with our expectations.
These results suggest that biased classifiers only rely on bias activation for majority classes.
When training a balanced classifier on the unbalanced data by employing attribute-specific class weights, positive and negative classes are classified similarly well and show expected activations for almost all attributes.","Xinyi Zhang, Johanna Sophie Bieri, Manuel Günther","~Xinyi_Zhang11, ~Johanna_Sophie_Bieri1, ~Manuel_Günther1","Facial Attribute Classification, Class Activation Mapping, Binary Classifiers",visualization or interpretation of learned representations,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=gmHtBH8Fnp,https://openreview.net/forum?id=gmHtBH8Fnp
5ES5Hdlbxw,The Effective Horizon Explains Deep RL Performance in Stochastic Environments,"Reinforcement learning (RL) theory has largely focused on proving minimax sample complexity bounds. These require strategic exploration algorithms that use relatively limited function classes for representing the policy or value function. Our goal is to explain why deep RL algorithms often perform well in practice, despite using random exploration and much more expressive function classes like neural networks. Our work arrives at an explanation by showing that many stochastic MDPs can be solved by performing only a few steps of value iteration on the random policy’s Q function and then acting greedily. When this is true, we find that it is possible to separate the exploration and learning components of RL, making it much easier to analyze. We introduce a new RL algorithm, SQIRL, that iteratively learns a near-optimal policy by exploring randomly to collect rollouts and then performing a limited number of steps of fitted-Q iteration over those roll- outs. We find that any regression algorithm that satisfies basic in-distribution generalization properties can be used in SQIRL to efficiently solve common MDPs. This can explain why deep RL works with complex function approximators like neural networks, since it is empirically established that neural networks generalize well in-distribution. Furthermore, SQIRL explains why random exploration works well in practice, since we show many environments can be solved by effectively estimating the random policy’s Q-function and then applying zero or a few steps of value iteration. We leverage SQIRL to derive instance-dependent sample complexity bounds for RL that are exponential only in an “effective horizon” of lookahead—which is typically much smaller than the full horizon—and on the complexity of the class used for function approximation. Empirically, we also find that SQIRL performance strongly correlates with PPO and DQN performance in a variety of stochastic environments, supporting that our theoretical analysis is predictive of practical performance. Our code and data are available at https://github.com/cassidylaidlaw/effective-horizon.","Cassidy Laidlaw, Banghua Zhu, Stuart Russell, Anca Dragan","~Cassidy_Laidlaw1, ~Banghua_Zhu1, ~Stuart_Russell1, ~Anca_Dragan1","reinforcement learning, effective horizon, RL theory, theory of reinforcement learning, instance-dependent bounds, empirical validation of theory",reinforcement learning,ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=5ES5Hdlbxw,https://openreview.net/forum?id=5ES5Hdlbxw
mt5NPvTp5a,Improved Operator Learning by Orthogonal Attention,"Neural operators, as an efficient surrogate model for learning the solutions of PDEs, have received extensive attention in the field of scientific machine learning.
Among them, attention-based neural operators have become one of the mainstreams in related research.
However, existing approaches overfit the limited training data due to the considerable number of parameters in the attention mechanism.
To address this, we develop an orthogonal attention based on the eigendecomposition of the kernel integral operator and the neural approximation of eigenfunctions. 
The orthogonalization naturally poses a proper regularization effect on the resulting neural operator, which aids in resisting overfitting and boosting generalization. 
Experiments on six standard neural operator benchmark datasets comprising both regular and irregular geometries show that our method can outperform competing baselines with decent margins.","Zipeng Xiao, Zhongkai Hao, Bokai Lin, Zhijie Deng, Hang Su","~Zipeng_Xiao1, ~Zhongkai_Hao1, ~Bokai_Lin1, ~Zhijie_Deng1, ~Hang_Su3","neural operator, attention, transformer, PDE","applications to physical sciences (physics, chemistry, biology, etc.)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=mt5NPvTp5a,https://openreview.net/forum?id=mt5NPvTp5a
GrRZz9qqJp,Mask Models are Token Level Contrastive Learners,"In recent years, the field of self-supervised learning has seen a surge in the development of mask models, which have been demonstrated to have strong performance on downstream tasks and efficient training. To better understand the underlying mechanism behind these models' success, we propose a theoretical framework for understanding mask models. By treating mask modeling as a low-rank recovery task, we demonstrate that it is a parametric version of Spectral Clustering and the reconstruction loss conforms to the form of Spectral Contrastive loss. This means that mask modeling can be understood as a token level Contrastive Learning. Our framework can be used to explain why optimal masking ratios vary among modalities and why there is a large gap between linear probing and finetuning performance for mask models. Additionally, our analysis suggests that the success of mask models depends on the model architecture, where a token mixing layer and layer normalization are crucial for the success of mask models. Our framework has the potential to be a step stone for future algorithm and network architecture design in the field of self-supervised learning.","Zixuan Pan, Zihao Wei","~Zixuan_Pan1, ~Zihao_Wei1","mask model, self-supervised learning, Contrastive Learning","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=GrRZz9qqJp,https://openreview.net/forum?id=GrRZz9qqJp
O04DqGdAqQ,Ada-Instruct: Adapting Instruction Generators For Complex Reasoning,"Generating diverse and sophisticated instructions for downstream tasks by Large Language Models (LLMs) is pivotal for advancing the effect. Current approaches leverage closed-source LLMs, employing in-context prompting for instruction generation. However, in this paper, we found that in-context prompting cannot generate complex instructions with length $\ge 100$ for tasks like code completion.

To solve this problem, we introduce Ada-Instruct, an adaptive instruction generator developed by fine-tuning open-source LLMs. Our pivotal finding illustrates that fine-tuning open-source LLMs with a mere ten samples generates long instructions that maintain distributional consistency for complex reasoning tasks. We empirically validated Ada-Instruct's efficacy across different applications, including code completion, mathematical reasoning, and commonsense reasoning. The results underscore Ada-Instruct’s superiority, evidencing its improvements over its base models, current self-instruct methods, and other state-of-the-art models.","Wanyun Cui, Qianle Wang","~Wanyun_Cui1, ~Qianle_Wang1","large language model, few-shot learning, self-instruct","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=O04DqGdAqQ,https://openreview.net/forum?id=O04DqGdAqQ
Abr7dU98ME,Forward Learning of Graph Neural Networks,"Graph neural networks (GNNs) have achieved remarkable success across a wide range of applications, such as recommendation, drug discovery, and question answering. Behind the success of GNNs lies the backpropagation (BP) algorithm, which is the de facto standard for training deep neural networks (NNs). However, despite its effectiveness, BP imposes several constraints, which are not only biologically implausible, but also limit the scalability, parallelism, and flexibility in learning NNs. Examples of such constraints include storage of neural activities computed in the forward pass for use in the subsequent backward pass, and the dependence of parameter updates on non-local signals. To address these limitations, the forward-forward algorithm (FF) was recently proposed as an alternative to BP in the image classification domain, which trains NNs by performing two forward passes over positive and negative data. Inspired by this advance, we propose ForwardGNN in this work, a new forward learning procedure for GNNs, which avoids the constraints imposed by BP via an effective layer-wise local forward training. ForwardGNN extends the original FF to deal with graph data and GNNs, and makes it possible to operate without generating negative inputs (hence no longer forward-forward). Further, ForwardGNN enables each layer to learn from both the bottom-up and top-down signals without relying on the backpropagation of errors. Extensive experiments on real-world datasets show the effectiveness and generality of the proposed forward graph learning framework. We release our code at https://github.com/facebookresearch/forwardgnn.","Namyong Park, Xing Wang, Antoine Simoulin, Shuai Yang, Grey Yang, Ryan A. Rossi, Puja Trivedi, Nesreen K. Ahmed","~Namyong_Park1, ~Xing_Wang8, ~Antoine_Simoulin1, ~Shuai_Yang9, ~Grey_Yang1, ~Ryan_A._Rossi2, ~Puja_Trivedi1, ~Nesreen_K._Ahmed2","graph neural networks, forward learning, forward-forward algorithm",learning on graphs and other geometries & topologies,ICLR 2024 poster,2024,https://openreview.net/pdf?id=Abr7dU98ME,https://openreview.net/forum?id=Abr7dU98ME
7gUrYE50Rb,EQA-MX: Embodied Question Answering using Multimodal Expression,"Humans predominantly use verbal utterances and nonverbal gestures (e.g., eye gaze and pointing gestures) in their natural interactions. For instance, pointing gestures and verbal information is often required to comprehend questions such as ""what object is that?"" Thus, this question-answering (QA) task involves complex reasoning of multimodal expressions (verbal utterances and nonverbal gestures). However, prior works have explored QA tasks in non-embodied settings, where questions solely contain verbal utterances from a single verbal and visual perspective. In this paper, we have introduced 8 novel embodied question answering (EQA) tasks to develop learning models to comprehend embodied questions with multimodal expressions. We have developed a novel large-scale dataset, EQA-MX, with over 8 million diverse embodied QA data samples involving multimodal expressions from multiple visual and verbal perspectives. To learn salient multimodal representations from discrete verbal embeddings and continuous wrapping of multiview visual representations, we propose a vector-quantization (VQ) based multimodal representation learning model, VQ-Fusion, for the EQA tasks. Our extensive experimental results suggest that VQ-Fusion can improve the performance of existing state-of-the-art visual-language models up to 13% across EQA tasks.","Md Mofijul Islam, Alexi Gladstone, Riashat Islam, Tariq Iqbal","~Md_Mofijul_Islam1, ~Alexi_Gladstone1, ~Riashat_Islam1, ~Tariq_Iqbal1","multimodal representation learning, visual-language models, embodied question answering",datasets and benchmarks,ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=7gUrYE50Rb,https://openreview.net/forum?id=7gUrYE50Rb
Aq35gl2c1k,Critical Learning Periods Emerge Even in Deep Linear Networks,"Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. 
Despite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology.
Yet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show analytically and in simulations that the learning of features is tied to competition between sources. Finally, we extend our analysis to multi-task learning to show that pre-training on certain tasks can damage the transfer performance on new tasks, and show how this depends on the relationship between tasks and the duration of the pre-training stage. To the best of our knowledge, our work provides the first analytically tractable model that sheds light into why critical learning periods emerge in biological and artificial networks.","Michael Kleinman, Alessandro Achille, Stefano Soatto","~Michael_Kleinman2, ~Alessandro_Achille1, ~Stefano_Soatto1","critical learning periods, deep neural networks, gradient descent, linear networks",applications to neuroscience & cognitive science,ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=Aq35gl2c1k,https://openreview.net/forum?id=Aq35gl2c1k
xw29VvOMmU,LQ-LoRA: Low-rank plus Quantized Matrix Decomposition for Efficient Language Model Finetuning,"We propose a simple approach for memory-efficient adaptation of pretrained language models. Our approach uses an iterative  algorithm  to decompose each  pretrained  matrix into a high-precision low-rank component  and a memory-efficient quantized component. During finetuning, the quantized component remains fixed and only the  low-rank component is updated. We present an integer linear programming formulation of the quantization component which enables dynamic  configuration of quantization parameters (e.g., bit-width, block size) for each matrix given an overall target memory budget.  We further explore a data-aware version of the algorithm which uses an approximation of the Fisher information matrix to weight the  reconstruction objective during matrix decomposition. Experiments on finetuning RoBERTa and LLaMA-2 (7B and 70B) demonstrate that our low-rank plus quantized matrix decomposition approach (LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and enables aggressive quantization to sub-3 bits with only minor performance degradations. When finetuned on a language modeling calibration dataset, LQ-LoRA can also be used for model compression; in this setting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when including the low-rank components and requires 27GB of GPU memory) performs respectably compared to the 16-bit baseline.","Han Guo, Philip Greengard, Eric Xing, Yoon Kim","~Han_Guo1, ~Philip_Greengard1, ~Eric_Xing1, ~Yoon_Kim1","Low-rank plus Quantized Matrix Decomposition, Efficient Language Model Finetuning","general machine learning (i.e., none of the above)",ICLR 2024 poster,2024,https://openreview.net/pdf?id=xw29VvOMmU,https://openreview.net/forum?id=xw29VvOMmU
x7cuUZxwFS,Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models,"In spite of their huge success, transformer models remain difficult to scale in depth. In this work, we provide formulae that govern the moments of the forward and backward signal through all transformer components, and develop a unified signal propagation theory for transformers. Our framework can be used to understand and mitigate vanishing/exploding gradients, rank collapse, and instability associated with high attention scores. We also propose DeepScaleLM, an initialization and scaling scheme that conserves unit output/gradient moments throughout the model, enabling the training of very deep models with $100$s of layers. We find that transformer models could be much deeper -- our deep models improve $1.0$ points in perplexity, and $2.2$ points in downstream tasks compared to shallow models across multiple model sizes, without any extra parameters, and even outperform larger shallow models using only half the number of parameters.","Akhil Kedia, Mohd Abbas Zaidi, Sushil Khyalia, Haejun Lee","~Akhil_Kedia1, ~Mohd_Abbas_Zaidi2, ~Sushil_Khyalia1, ~Haejun_Lee2","Signal Propagation, Language Model, Training Stability, Gradient Explosion, Moment Control, Rank Collapse","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=x7cuUZxwFS,https://openreview.net/forum?id=x7cuUZxwFS
rYhDcQudVI,Score-based Conditional Generation with Fewer Labeled Data by Self-calibrating Classifier Guidance,"Score-based generative models (SGMs) are a popular family of deep generative models that achieve leading image generation quality. Early studies extend SGMs to tackle class-conditional generation by coupling an unconditional SGM with the guidance of a trained classifier. Nevertheless, such classifier-guided SGMs do not always achieve accurate conditional generation, especially when trained with fewer labeled data. We argue that the problem is rooted in the classifier's tendency to overfit without coordinating with the underlying unconditional distribution. We propose improving classifier-guided SGMs by letting the classifier regularize itself to respect the unconditional distribution. Our key idea is to use principles from energy-based models to convert the classifier as another view of the unconditional SGM. Then, existing loss for the unconditional SGM can be leveraged to achieve regularization by calibrating the classifier's internal unconditional scores. The regularization scheme can be applied to not only the labeled data but also unlabeled ones to further improve the classifier. Empirical results show that the proposed approach significantly improves conditional generation quality across various percentages of fewer labeled data. The results confirm the potential of the proposed approach for generative modeling with limited labeled data.","Paul Kuo-Ming Huang, Si-An Chen, Hsuan-Tien Lin","~Paul_Kuo-Ming_Huang1, ~Si-An_Chen1, ~Hsuan-Tien_Lin1","Score-based Model, Classifier Guidance, Conditional Generation",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=rYhDcQudVI,https://openreview.net/forum?id=rYhDcQudVI
FPpLTTvzR0,IDEA: Invariant Causal Defense for Graph Adversarial Robustness,"Despite the success of graph neural networks (GNNs), their vulnerability to adversarial attacks poses tremendous challenges for practical applications. Existing defense methods suffer from severe performance decline under some unknown attacks, due to either limited observed adversarial examples (adversarial training) or pre-deﬁned heuristics (graph puriﬁcation or robust aggregation). To address these limitations, we analyze the causalities in graph adversarial attacks and conclude that causal features are desirable to achieve graph adversarial robustness, owing to their determinedness for labels and invariance across attacks. To learn these causal features, we innovatively propose an Invariant causal DEfense method against adversarial Attacks (IDEA). We derive node-based and structurebased invariance objectives from an information-theoretic perspective. IDEA is provably a causally invariant defense across various attacks. Extensive experiments demonstrate that IDEA signiﬁcantly outperforms all baselines under both poisoning and evasion attacks on ﬁve benchmark datasets, highlighting its strong and invariant predictability. The implementation of IDEA is available at https://anonymous.4open.science/r/IDEA_repo-666B.","Shuchang Tao, Qi Cao, Huawei Shen, Yunfan Wu, Bingbing Xu, Xueqi Cheng","~Shuchang_Tao1, ~Qi_Cao1, ~Huawei_Shen1, ~Yunfan_Wu1, ~Bingbing_Xu2, ~Xueqi_Cheng1","Invariant Causal Defense, Adversarial Robustness, Invariant Learning, Graph Neural Networks","societal considerations including fairness, safety, privacy",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=FPpLTTvzR0,https://openreview.net/forum?id=FPpLTTvzR0
0tWTxYYPnW,Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF,"In practice, preference learning from human feedback depends on incomplete data with hidden context. Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model. This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria. We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called *Borda count*. We show this can produce counter-intuitive results that are very different from other methods which implicitly aggregate via expected utility. Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function. A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF. As a step towards mitigating these problems, we introduce a class of methods called *distributional preference learning* (DPL). DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context. Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability.","Anand Siththaranjan, Cassidy Laidlaw, Dylan Hadfield-Menell","~Anand_Siththaranjan1, ~Cassidy_Laidlaw1, ~Dylan_Hadfield-Menell2","Preference Learning, Reinforcement Learning from Human Feedback, Social Choice Theory","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 poster,2024,https://openreview.net/pdf?id=0tWTxYYPnW,https://openreview.net/forum?id=0tWTxYYPnW
324zEJCo3a,Local Vs. Global Interpretability: A Computational Perspective,"The local and global interpretability of various ML models has been studied extensively in recent years. Yet despite significant progress in the field, many of the known results are either informal or lack sufficient mathematical rigor. In this work, we propose a framework based on computational complexity theory to systematically evaluate the local and global interpretability of different ML models. In essence, our framework examines various forms of explanations that can be computed either locally or globally and assesses the computational complexity involved in generating them. We begin by rigorously studying global explanations, and establish: (1) a duality relationship between local and global forms of explanations; and (2) the inherent uniqueness associated with certain global forms of explanations. We then proceed to evaluate the computational complexity associated with these forms of explanations, with a particular emphasis on three model types usually positioned at the extremes of the interpretability spectrum: (1) linear models; (2) decision trees; and (3) neural networks.
Our findings reveal that, assuming standard complexity assumptions such as P!=NP, computing global explanations is computationally more difficult for linear models than for their local counterparts. Surprisingly, this phenomenon is not universally applicable to decision trees and neural networks: in certain scenarios, computing a global explanation is actually more tractable than computing a local one. We consider these results as compelling evidence of the importance of analyzing ML explainability from a computational complexity perspective, as the means of gaining a deeper understanding of the inherent interpretability of diverse ML models.","Shahaf Bassan, Guy Amir, Guy Katz","~Shahaf_Bassan1, ~Guy_Amir1, ~Guy_Katz1","interpretability, explainable AI","general machine learning (i.e., none of the above)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=324zEJCo3a,https://openreview.net/forum?id=324zEJCo3a
AMDKqZcZbi,Rapid Learning without Catastrophic Forgetting in the Morris Water Maze,"Machine learning models typically struggle to swiftly adapt to novel tasks while maintaining proficiency on previously trained tasks. This contrasts starkly with animals, which demonstrate these capabilities easily. The differences between ML models and animals must stem from particular neural architectures and representations for memory and memory-policy interactions. We propose a new task that requires rapid and continual learning, the sequential Morris Water Maze (sWM). Drawing inspiration from biology, we show that 1) a content-addressable heteroassociative memory based on the entorhinal-hippocampal circuit with grid cells that retain knowledge across diverse environments, and 2) a spatially invariant convolutional network architecture for rapid adaptation across unfamiliar environments together perform rapid learning, good generalization, and continual learning without forgetting. Our model simultaneously outperforms ANN baselines from both the continual and few-shot learning contexts. It retains knowledge of past environments while rapidly acquiring the skills to navigate new ones, thereby addressing the seemingly opposing challenges of quick knowledge transfer and sustaining proficiency in previously learned tasks.","Raymond Wang, Jaedong Hwang, Akhilan Boopathy, Ila R Fiete","~Raymond_Wang1, ~Jaedong_Hwang1, ~Akhilan_Boopathy1, ~Ila_R_Fiete1","neuroscience, cognitive science, water maze, continual learning, catastrophic forgetting",applications to neuroscience & cognitive science,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=AMDKqZcZbi,https://openreview.net/forum?id=AMDKqZcZbi
qIRkFyLZnR,Robustify the Latent Space: Offline Distributionally Robust Reinforcement Learning with Linear Function Approximation,"Among the reasons hindering the applications of reinforcement learning (RL) to real-world problems, two factors are critical: limited data and the mismatch between the test environment (real environment in which the policy is deployed) and the training environment (e.g., a simulator). This paper simultaneously addresses these issues with offline distributionally robust RL, where a distributionally robust policy is learned using historical data from the source environment by optimizing against a worst-case perturbation thereof. In particular, we move beyond tabular settings and design a novel linear function approximation framework that robustifies the latent space. Our framework is instantiated into two settings, one where the dataset is well-explored and the other where the dataset has weaker data coverage. In addition, we introduce a value shift algorithmic technique specifically designed to suit the distributionally robust nature, which contributes to our improved theoretical results and empirical performance. Sample complexities $\tilde{O}(d^{1/2}/N^{1/2})$ and $\tilde{O}(d^{3/2}/N^{1/2})$ are established respectively as the first non-asymptotic results in these settings, where $d$ denotes the dimension in the linear function space and $N$ represents the number of trajectories in the dataset. Diverse experiments are conducted to demonstrate our theoretical findings, showing the superiority of our algorithms against the non-robust one.","Zhipeng Liang, Xiaoteng Ma, Jose Blanchet, Mingwen Liu, Jiheng Zhang, Zhengyuan Zhou","~Zhipeng_Liang1, ~Xiaoteng_Ma1, ~Jose_Blanchet1, ~Mingwen_Liu1, ~Jiheng_Zhang1, ~Zhengyuan_Zhou2","Distributionally robust optimization, Offline Reinforcement Learning, Linear Function Approximation",reinforcement learning,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=qIRkFyLZnR,https://openreview.net/forum?id=qIRkFyLZnR
q7XxKp2rHs,SMAFace: Sample Mining Guided Adaptive Loss for Face Recognition,"Traditional face recognition (FR) algorithms often rely merely on margin-based softmax loss functions. However, due to noisy training data and varied image quality in datasets, these models often falter when dealing with low-quality images. To address this issue, we introduce SMAFace, an innovative FR algorithm that enhances performance by incorporating sample mining into conventional margin-based methods. At its core, SMAFace focuses on prioritizing information-dense samples, namely hard samples or easy samples, which present more distinctive features. In this study, we employ a probability-driven mining strategy, enabling the model to adeptly navigate hard samples, thereby bolstering its robustness and adaptability. The mathematical evaluation and empirical tests of SMAFace indicate its effectiveness. Moreover, experimental results reveal that our approach surpasses the state-of-the-art (SoTA) on four renowned datasets (CPLFW, VGG2-FP, IJB-B and TinyFace), highlighting its potential and efficiency.","Yang Wang, Fan Xie, Ao Wang, Jiawei Xv, Chang Ma, shijia song, Zhenyu Yuan, lijun zhao","~Yang_Wang48, ~Fan_Xie2, ~Ao_Wang3, ~Jiawei_Xv1, ~Chang_Ma3, ~shijia_song1, ~Zhenyu_Yuan1, ~lijun_zhao2","face recognition, sample mining, low-quality images","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=q7XxKp2rHs,https://openreview.net/forum?id=q7XxKp2rHs
oO6FsMyDBt,Graph Neural Networks for Learning Equivariant Representations of Neural Networks,"Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalization performance, and learning to optimize, while consistently outperforming state-of-the-art methods. The source code is open-sourced at https://github.com/mkofinas/neural-graphs.","Miltiadis Kofinas, Boris Knyazev, Yan Zhang, Yunlu Chen, Gertjan J. Burghouts, Efstratios Gavves, Cees G. M. Snoek, David W. Zhang","~Miltiadis_Kofinas2, ~Boris_Knyazev1, ~Yan_Zhang1, ~Yunlu_Chen1, ~Gertjan_J._Burghouts1, ~Efstratios_Gavves1, ~Cees_G._M._Snoek1, ~David_W._Zhang1","Deep weight space, Graph neural networks, Transformers, Permutation equivariance, Implicit neural representations, Networks for networks, Neural graphs",learning on graphs and other geometries & topologies,ICLR 2024 oral,2024,https://openreview.net/pdf?id=oO6FsMyDBt,https://openreview.net/forum?id=oO6FsMyDBt
5j6wtOO6Fk,Hieros: Hierarchical Imagination on Structured State Space Sequence World Models,"One of the biggest challenges to modern deep reinforcement learning (DRL) algorithms is sample efficiency. Many approaches learn a world model in order to train an agent entirely in imagination, eliminating the need for direct environment interaction during training. However, these methods often suffer from either a lack of imagination accuracy, exploration capabilities, or runtime efficiency. We propose HIEROS, a hierarchical policy that learns time abstracted world representations and imagines trajectories at multiple time scales in latent space. HIEROS uses an S5 layer-based world model, which predicts next world states in parallel during training and iteratively during environment interaction. Due to the special properties of S5 layers, our method can train in parallel and predict next world states iteratively during imagination. This allows for more efficient training than RNN-based world models and more efficient imagination than Transformer-based world models. We show that our approach outperforms the state of the art in terms of mean and median normalized human score on the Atari 100k benchmark, and that our proposed world model is able to predict complex dynamics very accurately. We also show that HIEROS displays superior exploration capabilities compared to existing approaches.","Paul Mattes, Rainer Schlosser, Ralf Herbrich","~Paul_Mattes1, ~Rainer_Schlosser1, ~Ralf_Herbrich1","Reinforcement Learning, Hierarchical Models, Deep Learning, Structured State Space Model",reinforcement learning,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=5j6wtOO6Fk,https://openreview.net/forum?id=5j6wtOO6Fk
8ishA3LxN8,Finite Scalar Quantization: VQ-VAE Made Simple,"We propose to replace vector quantization (VQ) in the latent representation of VQ-VAEs
with a simple scheme termed finite scalar quantization (FSQ), where we project the VAE representation down to a few dimensions (typically less than 10).
Each dimension is quantized to a small set of fixed values, leading to an (implicit) codebook given by the product of these sets.
By appropriately choosing the number of dimensions and values each dimension can take, we obtain the same codebook size as in VQ.
On top of such discrete representations,
we can train the same models that have been trained on VQ-VAE representations. For example, autoregressive and masked transformer models for image generation, multimodal generation, and dense prediction computer vision tasks.
Concretely, we employ FSQ with MaskGIT for image generation, and with UViM for depth estimation, colorization, and panoptic segmentation.
Despite the much simpler design of FSQ, we obtain competitive performance in all these tasks.
We emphasize that FSQ does not suffer from codebook collapse and does not need the complex machinery employed in VQ (commitment losses, codebook reseeding, code splitting, entropy penalties, etc.) to learn expressive discrete representations.","Fabian Mentzer, David Minnen, Eirikur Agustsson, Michael Tschannen","~Fabian_Mentzer2, ~David_Minnen1, ~Eirikur_Agustsson1, ~Michael_Tschannen1","representation learning, vector quantization, quantization","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 poster,2024,https://openreview.net/pdf?id=8ishA3LxN8,https://openreview.net/forum?id=8ishA3LxN8
3y2TfP966N,T-Rep: Representation Learning for Time Series using Time-Embeddings,"Multivariate time series present challenges to standard machine learning techniques, as they are often unlabeled, high dimensional, noisy, and contain missing data. To address this, we propose T-Rep, a self-supervised method to learn time series representations at a timestep granularity. T-Rep learns vector embeddings of time alongside its feature extractor, to extract temporal features such as trend, periodicity, or distribution shifts from the signal. These time-embeddings are leveraged in pretext tasks, to incorporate smooth and fine-grained temporal dependencies in the representations, as well as reinforce robustness to missing data. We evaluate T-Rep on downstream classification, forecasting, and anomaly detection tasks. It is compared to existing self-supervised algorithms for time series, which it outperforms in all three tasks. We test T-Rep in missing data regimes, where it proves more resilient than its counterparts. Finally, we provide latent space visualisation experiments, highlighting the interpretability of the learned representations.","Archibald Felix Fraikin, Adrien Bennetot, Stephanie Allassonniere","~Archibald_Felix_Fraikin1, ~Adrien_Bennetot1, ~Stephanie_Allassonniere1","Multivariate time series, Self-supervised, Time series representations, Temporal features, Time-Embeddings, Representation Learning, Missing data","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 poster,2024,https://openreview.net/pdf?id=3y2TfP966N,https://openreview.net/forum?id=3y2TfP966N
3pWSL8My6B,Where We Have Arrived in Proving the Emergence of Sparse Interaction Primitives in DNNs,"This study aims to prove the emergence of symbolic concepts (or more precisely, sparse primitive inference patterns) in well-trained deep neural networks (DNNs). Specifically, we prove the following three conditions for the emergence. (i) The high-order derivatives of the network output with respect to the input variables are all zero. (ii) The DNN can be used on occluded samples, and when the input sample is less occluded, the DNN will yield higher confidence. (iii) The confidence of the DNN does not significantly degrade on occluded samples. These conditions are quite common, and we prove that under these conditions, the DNN will only encode a relatively small number of sparse interactions between input variables. Moreover, we can consider such interactions as symbolic primitive inference patterns encoded by a DNN, because we show that inference scores of the DNN on an exponentially large number of randomly masked samples can always be well mimicked by numerical effects of just a few interactions.","Qihan Ren, Jiayang Gao, Wen Shen, Quanshi Zhang","~Qihan_Ren1, ~Jiayang_Gao1, ~Wen_Shen3, ~Quanshi_Zhang1","Explainable AI, Neural networks, Symbolism",visualization or interpretation of learned representations,ICLR 2024 poster,2024,https://openreview.net/pdf?id=3pWSL8My6B,https://openreview.net/forum?id=3pWSL8My6B
yR5QbFv4Xb,Towards Faithful Neural Network Intrinsic Interpretation with Shapley Additive Self-Attribution,"Self-interpreting neural networks have garnered significant interest in research. Existing works in this domain often (1) lack a solid theoretical foundation ensuring genuine interpretability or (2) compromise model expressiveness. In response, we formulate a generic Additive Self-Attribution (ASA) framework. Observing the absence of Shapley value in Additive Self-Attribution, we propose Shapley Additive Self-Attributing Neural Network (SASANet), with theoretical guarantees for the self-attribution value equal to the output's Shapley values. Specifically, SASANet uses a marginal contribution-based sequential schema and internal distillation-based training strategies to model meaningful outputs for any number of features, resulting in un-approximated meaningful value function. Our experimental results indicate SASANet surpasses existing self-attributing models in performance and rivals black-box models. Moreover, SASANet is shown more precise and efficient than post-hoc methods in interpreting its own predictions.","Ying Sun, Hengshu Zhu, Hui Xiong","~Ying_Sun4, ~Hengshu_Zhu1, ~Hui_Xiong1","interpretability, neural networks, additive attribution, Shapley value","general machine learning (i.e., none of the above)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=yR5QbFv4Xb,https://openreview.net/forum?id=yR5QbFv4Xb
PqGPjts7Ug,Probabilistic Neural Transfer Function Estimation with Bayesian System Identification,"Neural population responses in sensory systems are driven by external physical stimuli. This stimulus-response relationship is typically characterized by receptive fields, which have been estimated by neural system identification approaches. Such models usually requires a large amount of training data, yet, the recording time for animal experiments is limited, giving rise to epistemic uncertainty for the learned neural transfer functions. While deep neural network models have demonstrated excellent power on neural prediction, they usually do not provide the uncertainty of the resulting neural representations and derived statistics, such as the stimuli driving neurons optimally, from in silico experiments. Here, we present a Bayesian system identification approach to predict neural responses to visual stimuli, and explore whether explicitly modeling network weight variability can be beneficial for identifying neural response properties. To this end, we use variational inference to estimate the posterior distribution of each model weight given the training data. Tests with different neural datasets demonstrate that this method can achieve higher or comparable performance on neural prediction, with a much higher data efficiency compared to Monte Carlo dropout methods and traditional models using point estimates of the model parameters. At the same time, our variational method allows to estimate the uncertainty of stimulus-response function, which we have found to be negatively correlated with the predictive performance and may serve to evaluate models. Furthermore, our approach enables to identify response properties with credible intervals and perform statistical test for the learned neural features, which avoid the idiosyncrasy of a single model. Finally, in silico experiments show that our model generates stimuli driving neuronal activity significantly better than traditional models, particularly in the limited-data regime.","Nan Wu, Isabel Valera, Fabian H. Sinz, Alexander S Ecker, Thomas Euler, Yongrong Qiu","~Nan_Wu4, ~Isabel_Valera1, ~Fabian_H._Sinz1, ~Alexander_S_Ecker1, ~Thomas_Euler1, ~Yongrong_Qiu1","neural system identification, Bayes, neuron, vision, receptive field, neural prediction, uncertainty, most exciting input, variational inference, stimulus-response function",applications to neuroscience & cognitive science,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=PqGPjts7Ug,https://openreview.net/forum?id=PqGPjts7Ug
13D1zn0mpd,Effective and Parameter-Efficient Reusing Fine-Tuned Models,"Many pre-trained large-scale models provided online have become highly effective in transferring to downstream tasks. At the same time, various task-specific models fine-tuned on these pre-trained models are available online for public use. In practice, collecting task-specific data is labor-intensive and fine-tuning the large pre-trained models is computationally expensive, one can reuse task-specific fine-tuned models to deal with downstream tasks. However, using a model per task causes a heavy burden on storage and serving. Recently, many training-free and parameter-efficient methods have been proposed for merging multiple fine-tuned task-specific models into a single multi-task model. However, these methods exhibit a large accuracy gap compared with using a fine-tuned model per task. In this paper, we propose parameter-efficient methods for Reusing fine-tuned models. For reusing fully fine-tuned models, we inject sparse task vectors to a merged model by magnitude pruning. For reusing LoRA fine-tuned models, we use a lower-rank matrix to approximate the LoRA matrix by singular value decomposition. Extensive experiments conducted on computer vision and natural language process tasks demonstrate the effectiveness and parameter-efficiency of the proposed methods. The proposed methods outperform existing merging models method by a large margin and achieve comparable performance to using a fine-tuned model per task.","Weisen Jiang, Baijiong Lin, Han Shi, Yu Zhang, Zhenguo Li, James Kwok","~Weisen_Jiang1, ~Baijiong_Lin1, ~Han_Shi1, ~Yu_Zhang3, ~Zhenguo_Li1, ~James_Kwok1","merging models, fine-tune models","general machine learning (i.e., none of the above)",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=13D1zn0mpd,https://openreview.net/forum?id=13D1zn0mpd
pJ55L21Tay,Two subspace clustering methods with prior masks,"To further utilize the unsupervised features and pairwise information, we propose an embedding method to joint two clustering methods, and an unified Bilevel Clustering Optimization (BCO) framework to improve the clustering performance. At first, we reformulate the original subspace clustering as a Basic Masked Subspace Clustering (BMSC), which reformulate the diagonal constraints to a hard mask. Then, we provide a General Masked Subspace Clustering (GMSC) method to integrate different clustering via a soft mask. Furthermore, based on BCO and GMSC, we induce a learnable soft mask and design a Recursive Masked Subspace Clustering (RMSC) method that can alternately update the affinity matrix and the soft mask. Numerical experiments show that our models obtain significant improvement compared with the baselines on several commonly used datasets, such as MNIST, USPS, ORL, COIL20 and COIL100.",Jiebo Song,~Jiebo_Song1,"subspace clustering, prior mask, bilevel clustering","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=pJ55L21Tay,https://openreview.net/forum?id=pJ55L21Tay
1EyS6udrLa,Towards Bringing Advanced Restoration Networks into Self-Supervised Image Denoising,"Self-supervised image denoising (SSID) has witnessed significant progress in recent years. Therein, most methods focus on exploring blind-spot techniques while only employing a simple network architecture (\eg, plain CNN or U-Net) as a denoising backbone. However, with the ongoing advancements in image restoration networks, these architectures have become somewhat outdated. In this work, we aim to migrate the advanced restoration network designs (\eg, SwinIR, Restormer, NAFNet, and HAT) into SSID methods. We begin by conducting an analysis of the fundamental concepts in existing typical blind-spot networks (BSN). Subsequently, we introduce a series of approaches to adapt restoration networks into various blind-spot ones. In particular, we suggest effective adjustment for window attention to mimic the convolution layers in BSN. And we discourage the adoption of channel attention, as it can potentially lead to the leakage of blind-spot information, consequently impeding performance. Experiments on both synthetic and real-world RGB noisy images demonstrate our methods substantially enhance SSID performance. Furthermore, we hope this study could enable SIDD methods to keep pace with the progress in restoration networks, and serve as benchmarks for future works. The code and pre-trained models will be publicly available.","Junyi Li, Zhilu Zhang, Dongsheng Jiang, XIAOPENG ZHANG, Wangmeng Zuo, Qi Tian","~Junyi_Li5, ~Zhilu_Zhang2, ~Dongsheng_Jiang2, ~XIAOPENG_ZHANG7, ~Wangmeng_Zuo3, ~Qi_Tian3",Self-Supervised Denoising; Restoration Networks,"representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=1EyS6udrLa,https://openreview.net/forum?id=1EyS6udrLa
GrunXMbdXY,FLAT-Chat: A Word Recovery Attack on Federated Language Model Training,"Gradient exchange is widely applied in collaborative training of machine learning models, including Federated Learning. Curious-but-honest participants could potentially infer the output labels in recently used training data by analyzing the latest gradient updates. Previous works mostly demonstrate the attack performance under constraint training settings, such as dozens of short sentences in a batch and a small output space for labels. In this work, we propose a novel gradient flattening attack on the last linear layer of a language model, which significantly improves the attacker's efficiency in inferring the words used in training. We validate the capability of the attack on two language generation tasks: machine translation and language modeling. The attack environment is scaled up to industrial settings of a large output vocabulary and realistic training batch sizes. To mitigate the negative impact of the new attack, we explore two defense methods and demonstrate that adding differential privacy with small noise could effectively defend against our new attack without degrading model utility.","Qiongkai Xu, Jun Wang, Olga Ohrimenko, Trevor Cohn","~Qiongkai_Xu1, ~Jun_Wang29, ~Olga_Ohrimenko1, ~Trevor_Cohn1","Label inference attack, Large-scale language model, Matrix flattening","societal considerations including fairness, safety, privacy",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=GrunXMbdXY,https://openreview.net/forum?id=GrunXMbdXY
R3Tf7LDdX4,Memory-Consistent Neural Networks for Imitation Learning,"Imitation learning considerably simplifies policy synthesis compared to alternative approaches by exploiting access to expert demonstrations. For such imitation policies, errors away from the training samples are particularly critical. Even rare slip-ups in the policy action outputs can compound quickly over time, since they lead to unfamiliar future states where the policy is still more likely to err, eventually causing task failures. We revisit simple supervised ""behavior cloning"" for conveniently training the policy from nothing more than pre-recorded demonstrations, but carefully design the model class to counter the compounding error phenomenon. Our ""memory-consistent neural network"" (MCNN) outputs are hard-constrained to stay within clearly specified permissible regions anchored to prototypical ""memory"" training samples. We provide a guaranteed upper bound for the sub-optimality gap induced by MCNN policies. Using MCNNs on 10 imitation learning tasks, with MLP, Transformer, and Diffusion backbones, spanning dexterous robotic manipulation and driving, proprioceptive inputs and visual inputs, and varying sizes and types of demonstration data, we find large and consistent gains in performance, validating that MCNNs are better-suited than vanilla deep neural networks for imitation learning applications. Website: https://sites.google.com/view/mcnn-imitation","Kaustubh Sridhar, Souradeep Dutta, Dinesh Jayaraman, James Weimer, Insup Lee","~Kaustubh_Sridhar1, ~Souradeep_Dutta2, ~Dinesh_Jayaraman2, ~James_Weimer1, ~Insup_Lee1","Imitation Learning, Behavior Cloning, Deep Learning",reinforcement learning,ICLR 2024 poster,2024,https://openreview.net/pdf?id=R3Tf7LDdX4,https://openreview.net/forum?id=R3Tf7LDdX4
ykhRO1mAg3,FPTQ: FINE-GRAINED POST-TRAINING QUANTIZATION FOR LARGE LANGUAGE MODELS,"In the era of large-scale language models, the substantial parameter size poses significant challenges for deployment. Being a prevalent compression technique, quantization has emerged as the mainstream practice to tackle this issue, which is mainly centered on two recipes W8A8 and W4A16 (i.e. weights and activations in such bit widths). In this study, we propose a novel W4A8 post-training quantization method for the available open-sourced LLMs, which combines the advantages of both two recipes. Therefore, we can leverage the benefit in the I/O utilization of 4-bit weight quantization and the acceleration due to 8-bit matrix computation. Nevertheless, the W4A8 faces notorious performance degradation. As a remedy, we involve layerwise activation quantization strategies which feature a novel logarithmic equalization for most intractable layers, and we combine them with fine-grained weight quantization. Without whistles and bells, we eliminate the necessity for further fine-tuning and obtain the state-of-the-art W4A8 quantized performance on BLOOM, LLaMA, and LLaMA-2 on standard benchmarks. We confirm that the W4A8 quantization is achievable for the deployment of large language models, fostering their wide-spreading real-world applications.","QINGYUAN LI, Yifan Zhang, Liang Li, Bo Zhang","~QINGYUAN_LI3, ~Yifan_Zhang14, ~Liang_Li10, ~Bo_Zhang7","LLMs, quantization","general machine learning (i.e., none of the above)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=ykhRO1mAg3,https://openreview.net/forum?id=ykhRO1mAg3
n9CqhWGK4o,Cellular Interplay in COVID-19: Insights from Graph Neural Networks with Multidimensional Edge Features,"The COVID-19 has emerged as a global pandemic, posing a significant public health threat with its widespread infection and the potential for severe respiratory complications. Among the various methodologies employed, single-cell omics-based studies have been at the forefront, concentrating on “intra”-cellular properties exhibited by gene expression. However, given its infectious nature, complex biological processes, such as immune responses performed between immune cells, infected cells, etc., necessitate a deeper analysis on “inter”-cellular properties exhibited by cell-cell interaction scores calculated using ligand and receptor expression information. The differences in these interactions in addition to gene expression between severe and non-severe cases could be pivotal in understanding the disease’s onset and progression, including mechanism leading to disease severity. Since the structure representing the overall nature of immune response can be implemented by directed graph with cell types as nodes and their interactions as edges, we employed a Graph Neural Network (GNN) model architecture accommodating multi-dimensional edge features, one of the first applications in biological context. In this study, our model incorporates edge features of cell-cell interaction scores, and node features of transcriptional factors and their target genes, which are “intra”-cellular features affected in the downstream by “inter”-cellular features. By leveraging the power of GNNs and the innovative use of multiple edge features, our model offers a groundbreaking perspective on the biological complexity of COVID-19, holding promise for the development of more effective treatments and preventive measures.","Kyeonghun Jeong, Yooeun Kim, Kwangsoo Kim","~Kyeonghun_Jeong1, ~Yooeun_Kim1, ~Kwangsoo_Kim1","Graph neural network, Classification, Biological application, Single cell RNA-seq, Cell-Cell Interaction","applications to physical sciences (physics, chemistry, biology, etc.)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=n9CqhWGK4o,https://openreview.net/forum?id=n9CqhWGK4o
i8PjQT3Uig,Locality Sensitive Sparse Encoding for Learning World Models Online,"Acquiring an accurate world model $\textit{online}$ for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs). From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round. Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents. In this paper, we revisit models that can achieve FTL with incremental updates. Specifically, our world model is a linear regression model supported by nonlinear random features. The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments. To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features. We validate the representation power of our encoding and verify that it allows efficient online learning under data covariate shift. We also show, in the Dyna MBRL setting, that our world models learned online using a $\textit{single pass}$ of trajectory data either surpass or match the performance of deep world models trained with replay and other continual learning methods.","Zichen Liu, Chao Du, Wee Sun Lee, Min Lin","~Zichen_Liu1, ~Chao_Du1, ~Wee_Sun_Lee1, ~Min_Lin1","model-based rl, online learning, incremental learning, catastrophic forgetting",reinforcement learning,ICLR 2024 poster,2024,https://openreview.net/pdf?id=i8PjQT3Uig,https://openreview.net/forum?id=i8PjQT3Uig
cLIvvqf3Wk,Attribute-Guided Diffusion for Unsupervised Few-Shot Font Generation,"Font generation is a challenging problem, especially for some writing systems composed of a large number of characters, such as Chinese, which has attracted the attention of many scholars in recent years. However, existing font generation methods are usually based on generative adversarial networks. Due to the problems of training instability and mode collapse in generative adversarial networks, the performance of many methods has encountered bottlenecks. In order to solve this problem, we apply the latest generative model — the diffusion model to this task. We use the method of decoupling content and style to extract image attributes, combine the required content and style with the input diffusion model as a condition, and then guide diffusion models to generate glyphs corresponding to styles. Our method can be stably trained on large datasets and our model achieves pretty good performance both qualitatively and quantitatively compared with previous font generation methods.","Yan He, Xiang Xiang","~Yan_He1, ~Xiang_Xiang1",Diffusion Models; Font Generation,generative models,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=cLIvvqf3Wk,https://openreview.net/forum?id=cLIvvqf3Wk
UMfcdRIotC,Faithful Explanations of Black-box NLP Models Using LLM-generated Counterfactuals,"Causal explanations of the predictions of NLP systems are essential to ensure safety and establish trust. Yet, existing methods often fall short of explaining model predictions effectively or efficiently and are often model-specific. In this paper, we address model-agnostic explanations, proposing two approaches for counterfactual (CF) approximation. The first approach is CF generation, where a large language model (LLM) is prompted to change a specific text concept while keeping confounding concepts unchanged. While this approach is demonstrated to be very effective, applying LLM at inference-time is costly. We hence present a second approach based on matching, and propose a method that is guided by an LLM at training-time and learns a dedicated embedding space. This space is faithful to a given causal graph and effectively serves to identify matches that approximate CFs. After showing theoretically that approximating CFs is required in order to construct faithful explanations, we benchmark our approaches and explain several models, including LLMs with billions of parameters. Our empirical results demonstrate the excellent performance of CF generation models as model-agnostic explainers. Moreover, our matching approach, which requires far less test-time resources, also provides effective explanations, surpassing many baselines. We also find that Top-K techniques universally improve every tested method. Finally, we showcase the potential of LLMs in constructing new benchmarks for model explanation and subsequently validate our conclusions. Our work illuminates new pathways for efficient and accurate approaches to interpreting NLP systems.","Yair Ori Gat, Nitay Calderon, Amir Feder, Alexander Chapanin, Amit Sharma, Roi Reichart","~Yair_Ori_Gat1, ~Nitay_Calderon1, ~Amir_Feder1, ~Alexander_Chapanin1, ~Amit_Sharma3, ~Roi_Reichart1","NLP, LLMs, Interpretability, Explanation, Causal Inference, Matching",visualization or interpretation of learned representations,ICLR 2024 poster,2024,https://openreview.net/pdf?id=UMfcdRIotC,https://openreview.net/forum?id=UMfcdRIotC
TgeVptDYAt,Towards Causal Foundation Model: on Duality between Causal Inference and Attention,"Foundation models have brought changes to the landscape of machine learning, demonstrating sparks of human-level intelligence across a diverse array of tasks. However, a gap persists in complex tasks such as causal inference, primarily due to challenges associated with intricate reasoning steps and high numerical precision requirements. In this work, we take a first step towards building causally-aware foundation models for complex tasks. We propose a novel, theoretically sound method called Causal Inference with Attention (CInA), which utilizes multiple unlabeled datasets to perform self-supervised causal learning, and subsequently enables zero-shot causal inference on unseen tasks with new data. This is based on our theoretical results that demonstrate the primal-dual connection between optimal covariate balancing and self-attention, facilitating zero-shot causal inference through the final layer of a trained transformer-type architecture. We demonstrate empirically that our approach CInA effectively generalizes to out-of-distribution datasets and various real-world datasets, matching or even surpassing traditional per-dataset causal inference methodologies.","Jiaqi Zhang, Joel Jennings, Cheng Zhang, Chao Ma","~Jiaqi_Zhang2, ~Joel_Jennings1, ~Cheng_Zhang1, ~Chao_Ma2","foundation model, causal inference, zero-shot learning, attention",causal reasoning,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=TgeVptDYAt,https://openreview.net/forum?id=TgeVptDYAt
ff5srKUefm,Entropy Voting Between Capsules,"Capsule networks offer a promising solution in computer vision by addressing the limitations of convolutional neural networks (CNNs), such as data dependency and viewpoint challenges. Unlike CNNs, capsules reduce the need for data augmentation by enhancing generalization from limited training data. We explore capsules from the perspective of information theory, viewing them as Monte Carlo sampled continuous random variables. We use marginal differential entropy to measure the information content of capsules, and relative entropy to model the agreement between lower-level and higher-level capsules. The proposed entropy voting method aims to maximize capsule marginal entropies and to minimize their relative entropy. We show that our approach performs better or comparably against state-of-the-art capsule networks while significantly improving inference time. This research highlights the synergy between capsules and information theory, providing insights into their combined potential.","Miika Kolu, Peer Stelldinger, Hashem Haghbayan, Juha Plosila","~Miika_Kolu1, ~Peer_Stelldinger1, ~Hashem_Haghbayan1, ~Juha_Plosila1","capsule networks, information theory, computer vision, deep learning","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=ff5srKUefm,https://openreview.net/forum?id=ff5srKUefm
HodMKbJkl3,SGD batch saturation for training wide neural networks,"The performance of the mini-batch stochastic gradient method strongly depends on the batch-size that is used. In the classical convex setting with interpolation, prior work showed that increasing the batch size linearly increases the convergence speed, but only up to a point; when the batch size is larger than a certain threshold (the critical batchsize), further increasing the batch size only leads to negligible improvement. 
The goal of this work is to investigate the relationship between the batchsize and convergence speed for a broader class of nonconvex problems. Building on recent improved convergence guarantees for SGD, we prove that a similar linear scaling and batch-size saturation phenomenon occurs for training  sufficiently wide neural networks. We conduct a number of numerical experiments on benchmark datasets, which corroborate our findings.","Chaoyue Liu, Dmitriy Drusvyatskiy, Mikhail Belkin, Damek Davis, Yian Ma","~Chaoyue_Liu2, ~Dmitriy_Drusvyatskiy3, ~Mikhail_Belkin1, ~Damek_Davis1, ~Yian_Ma1","mini-batch SGD, batch size, Polyak-Lojasiewicz, PL condition, convergence",optimization,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=HodMKbJkl3,https://openreview.net/forum?id=HodMKbJkl3
Bo6GpQ3B9a,Out-Of-Domain Unlabeled Data Improves Generalization,"We propose a novel framework for incorporating unlabeled data into semi-supervised classification problems, where scenarios involving the minimization of either i) adversarially robust or ii) non-robust loss functions have been considered. Notably, we allow the unlabeled samples to deviate slightly (in total variation sense) from the in-domain distribution. The core idea behind our framework is to combine Distributionally Robust Optimization (DRO) with self-supervised training. As a result, we also leverage efficient polynomial-time algorithms for the training stage. From a theoretical standpoint, we apply our framework on the classification problem of a mixture of two Gaussians in $\mathbb{R}^d$, where in addition to the $m$ independent and labeled samples from the true distribution, a set of $n$ (usually with $n\gg m$) out of domain and unlabeled samples are gievn as well. Using only the labeled data, it is known that the generalization error can be bounded by $\propto\left(d/m\right)^{1/2}$. However, using our method on both isotropic and non-isotropic Gaussian mixture models, one can derive a new set of analytically explicit and non-asymptotic bounds which show substantial improvement on the generalization error compared ERM. Our results underscore two significant insights: 1) out-of-domain samples, even when unlabeled, can be harnessed to narrow the generalization gap, provided that the true data distribution adheres to a form of the ""cluster assumption"", and 2) the semi-supervised learning paradigm can be regarded as a special case of our framework when there are no distributional shifts. We validate our claims through experiments conducted on a variety of synthetic and real-world datasets.","seyed amir hossein saberi, Amir Najafi, Alireza Heidari, Mohammad Hosein Movasaghinia, Abolfazl Motahari, Babak Khalaj","~seyed_amir_hossein_saberi1, ~Amir_Najafi1, ~Alireza_Heidari2, ~Mohammad_Hosein_Movasaghinia1, ~Abolfazl_Motahari1, ~Babak_Khalaj1","Out-of-domain data, Semi-supervised learing, learning theory, generalization bound, adversarial robustness",learning theory,ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=Bo6GpQ3B9a,https://openreview.net/forum?id=Bo6GpQ3B9a
QL3Zuth6E7,Prompt-Free Diffusion: Taking “Text” out of Text-to-Image Diffusion Models,"Text-to-image (T2I) research has grown explosively in the past year, owing to the large-scale pre-trained diffusion models and many emerging personalization and editing approaches. Yet, \textbf{one pain point persists: the text prompt engineering}, and searching high-quality text prompts for customized results is more art than science. Moreover, as commonly argued: ``an image is worth a thousand words"" - the attempt to describe a desired image with texts often ends up being ambiguous and cannot comprehensively cover delicate visual details, hence necessitating more additional controls from the visual domain. In this paper, we take a bold step forward: taking “Text” out of a pre-trained T2I diffusion model, to reduce the burdensome prompt engineering efforts for users. Our proposed framework, \textbf{Prompt-Free Diffusion}, relies on \textbf{only visual inputs to generate new images}: it takes a reference image as ``context”, an optional image structural conditioning, and an initial noise, with absolutely no text prompt. The core architecture behind the scene is \textbf{Se}mantic Context \textbf{E}n\textbf{coder} (\textbf{SeeCoder}), substituting the commonly used CLIP-based or LLM-based text encoder.  The reusability of SeeCoder also makes it a convenient drop-in component: one can also pre-train a SeeCoder in one T2I model and reuse it for another. Through extensive experiments, Prompt-Free Diffusion is experimentally found to (i) outperform prior exemplar-based image synthesis approaches; (ii) perform on par with state-of-the-art T2I models using prompts following the best practice; and (iii) be naturally extensible to other downstream applications such as anime figure generation and virtual try-on, with promising quality. Our code and models will be open-sourced.","Xingqian Xu, Jiayi Guo, Zhangyang Wang, Gao Huang, Irfan Essa, Humphrey Shi","~Xingqian_Xu2, ~Jiayi_Guo2, ~Zhangyang_Wang1, ~Gao_Huang1, ~Irfan_Essa1, ~Humphrey_Shi1","Text-to-Image, Diffusion Models, Image-Variation, Generative Models, High-Quality Image Generation, Representation Learning",generative models,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=QL3Zuth6E7,https://openreview.net/forum?id=QL3Zuth6E7
OKOjkFrhSs,Prompt-Guided Dynamic Network for Image Super Resolution,"Existing single image super-resolution (SISR) methods learn the convolutional kernel solely from a single image modality. However, the SR performance is limited by the diversity of input modality and the insufficient image-level information in low-resolution images. In this paper, we seek to use multi-modal prompts (texts or images) to assist existing SR networks to learn more discriminative features, leading to superior SR performance. To this end, we develop the Dynamic Correlation Module in a plug-and-play form for existing SR networks, which learns meaningful semantic and textural information from multi-modal prompt embeddings extracted from a large-scale vision-language model (such as CLIP). Specifically, Spatially Multi-Modal Attention Module is proposed to generate the pixel-wise cross-modal attention mask which would highlight the interest regions given certain prompts. Moreover, to the best of our knowledge, we are the first ones that introduce multi-modal prompts into convolutional kernel estimation which can better handle spatial variants and retain cross-modal relevance. Extensive experiments and ablation studies demonstrate the effectiveness of the proposed Dynamic Correlation Module which exploits the discriminative prompt features to recover realistic high-resolution images, elevating existing SR performance by a notable gap.","Cheng Cheng, Lin Song, Xiaohan Ding, Hang Wang, Hongbin Sun","~Cheng_Cheng5, ~Lin_Song2, ~Xiaohan_Ding1, ~Hang_Wang7, ~Hongbin_Sun2",single image super resolution,"representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=OKOjkFrhSs,https://openreview.net/forum?id=OKOjkFrhSs
vzvCaYFTLq,Sapling: $\underline{S}$uccessive $\underline{A}$daptation and Com$\underline{p}$ression with $\underline{L}$ayer Dropp$\underline{ing}$ for LLMs,"Specializing Large language models (LLMs) for local deployment and domain-specific use can deliver state-of-the-art performance while meeting latency and privacy requirements. However, conventional task-specific adaptation does not show both memory saving and inference speedup at deployment time. Practical compression techniques like quantization and pruning require hardware support or system optimization to achieve measured inference speedup. We propose Sapling, which can retain LLMs' capacity in a specific knowledge domain and achieve inference speedup on any hardware and deep learning systems by reducing the model depth. Sapling is based on the knowledge localization phenomenon we empirically observed and verified on LLMs, and achieves model compression via successive layer dropping. We evaluated Sapling on LLaMA-7B. At inference time, the models adapted on medical, legal, and financial datasets have all demonstrated reliable performance, comparable memory saving, $1.2$ to $8.5\times$ inference speedup on consumer-level hardware compared to state-of-the-art quantization algorithms, depending on how well the algorithms are supported by efficient accelerator kernels.","Lanxiang Hu, Hao Zhang","~Lanxiang_Hu1, ~Hao_Zhang2","Efficient Deep Learning, Layer Dropping, LLM Fine-tuning, Specialized LLMs",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=vzvCaYFTLq,https://openreview.net/forum?id=vzvCaYFTLq
SMZnJtkNX5,Temporal Parallelization for GPU Acceleration of Spiking Neural Networks,"Inspired by neurobiological structures, Spiking Neural Networks (SNNs) are heralded as a significant advancement in deep learning, given their potential for superior computational efficiency. However, this potential often remains untapped on contemporary hardware platforms. Specifically, when deployed on standard GPUs, SNNs tend to require extended computation times, placing them at a disadvantage compared to traditional Artificial Neural Networks (ANNs). Such inefficiencies have somehow diminished enthusiasm for SNN research and presented the tangible challenge to achieving scalability. To address such a challenge, this study introduces a temporal parallelization method specifically tailored for accelerating the propagation dynamics of SNNs on GPUs. Furthermore, we furnish two distinct implementations\footnote{The source code will be made publicly available.} based on the CUDA and JAX frameworks respectively, ensuring adaptability across both single and multi-GPU setups. When benchmarked against several established SNN implementations, the empirical analysis confirmed the efficacy of our proposed method. Notably, with the Leaky Integrate-and-Fire model as a test case, the CUDA-based implementation achieved $5\times$ to $40\times$ acceleration on the A100 GPU.","Jiachun Li, Yanchen Li, Kebin Sun, Ran Cheng","~Jiachun_Li2, ~Yanchen_Li1, ~Kebin_Sun1, ~Ran_Cheng1","Spiking neural networks, High-performance computing, GPU acceleration","infrastructure, software libraries, hardware, etc.",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=SMZnJtkNX5,https://openreview.net/forum?id=SMZnJtkNX5
gJRrG43BYC,State-drive Implicit Modeling,"Implicit models are a general class of learning models that forgo the hierarchical layer structure typical in neural networks and instead define the internal states based on an ""equilibrium"" equation, offering competitive performance and reduced memory consumption. However, training such models usually relies on expensive implicit differentiation for backward propagation. In this work, we present a new approach to training implicit models, called State-driven Implicit Modeling (SIM), where we constrain the internal states and outputs to match that of a baseline model, circumventing costly backward computations. The training problem becomes convex by construction and can be solved in a parallel fashion, thanks to its decomposable structure. We demonstrate how the SIM approach can be further applied to parameter reduction and robust training by combining it with custom objective functions.","Alicia Y. Tsai, Juliette Decugis, Laurent El Ghaoui, Alper Atamturk","~Alicia_Y._Tsai1, ~Juliette_Decugis1, ~Laurent_El_Ghaoui1, ~Alper_Atamturk2","implicit models, learning algorithm, convex optimization","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=gJRrG43BYC,https://openreview.net/forum?id=gJRrG43BYC
f3g5XpL9Kb,LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures,"Joint embedding (JE) architectures have emerged as a promising avenue for ac-
quiring transferable data representations. A key obstacle to using JE methods,
however, is the inherent challenge of evaluating learned representations without
access to a downstream task, and an annotated dataset. Without efficient and re-
liable evaluation, it is difficult to iterate on architectural and training choices for
JE methods. In this paper, we introduce LiDAR (Linear Discriminant Analysis
Rank), a metric designed to measure the quality of representations within JE archi-
tectures. Our metric addresses several shortcomings of recent approaches based
on feature covariance rank by discriminating between informative and uninforma-
tive features. In essence, LiDAR quantifies the rank of the Linear Discriminant
Analysis (LDA) matrix associated with the surrogate SSL task—a measure that
intuitively captures the information content as it pertains to solving the SSL task.
We empirically demonstrate that LiDAR significantly surpasses naive rank based
approaches in its predictive power of optimal hyperparameters. Our proposed cri-
terion presents a more robust and intuitive means of assessing the quality of rep-
resentations within JE architectures, which we hope facilitates broader adoption
of these powerful techniques in various domains.","Vimal Thilak, Chen Huang, Omid Saremi, Laurent Dinh, Hanlin Goh, Preetum Nakkiran, Joshua M. Susskind, Etai Littwin","~Vimal_Thilak2, ~Chen_Huang6, ~Omid_Saremi1, ~Laurent_Dinh1, ~Hanlin_Goh2, ~Preetum_Nakkiran1, ~Joshua_M._Susskind1, ~Etai_Littwin1","Self Supervised Learning, Joint Embedding Architectures","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=f3g5XpL9Kb,https://openreview.net/forum?id=f3g5XpL9Kb
LVp217SAtb,ADAPTER-RL: Adaptation of Any Agent using Reinforcement Learning,"Deep Reinforcement Learning (DRL) agents frequently face challenges in adapting to tasks outside their training distribution, facing issues with over-fitting, catastrophic forgetting and sample inefficiency. Although the application of adapters has proven effective in supervised learning contexts such as natural language processing and computer vision, their potential within the DRL domain remains largely unexplored. This paper delves into the integration of adapters in reinforcement learning, presenting an innovative adaptation strategy that demonstrates enhanced training efficiency and imporvement of the base-agent, experimentally in the nanoRTS environment, a real-time strategy game simulation. Our proposed universal approach is not only compatible with pre-trained neural networks but also with rule-based agents, offering a means to integrate human expertise.","Yizhao Jin, Gregory Slabaugh, Simon Lucas","~Yizhao_Jin1, ~Gregory_Slabaugh2, ~Simon_Lucas1","adapter, reinforcement learning, human expertise",reinforcement learning,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=LVp217SAtb,https://openreview.net/forum?id=LVp217SAtb
HwQ8NVvdmm,Hadamard Domain Training with Integers for Class  Incremental Quantized Learning,"Continual learning is a desirable feature in many modern machine learning applications, which allows in-field adaptation and updating, ranging from accommodating distribution shift, to fine-tuning, and to learning new tasks. For applications with privacy and low latency requirements, the compute and memory demands imposed by continual learning can be cost-prohibitive for resource-constraint edge platforms. Reducing computational precision through fully quantized training (FQT) simultaneously reduces memory footprint and increases compute efficiency for both training and inference. However, aggressive quantization especially integer FQT typically degrades model accuracy to unacceptable levels. In this paper, we propose a technique that leverages inexpensive Hadamard transforms to enable low-precision training with only integer matrix multiplications. We further determine which tensors need stochastic rounding and propose tiled matrix multiplication to enable low-bit width accumulators. We demonstrate the effectiveness of our technique on several human activity recognition datasets and CIFAR100 in a class incremental learning setting. We achieve less than 0.5% and 3% accuracy degradation while we quantize all matrix multiplications inputs down to 4-bits with 8-bit accumulators.","Martin Schiemer, Clemens JS Schaefer, Jayden Parker Vap, Mark James Horeni, Yu Emma Wang, Juan Ye, Siddharth Joshi","~Martin_Schiemer1, ~Clemens_JS_Schaefer1, ~Jayden_Parker_Vap2, ~Mark_James_Horeni1, ~Yu_Emma_Wang1, ~Juan_Ye1, ~Siddharth_Joshi2","Quantization, Continual Learning, Class Incremental Learning, Fully Quantized Learning, Human Activity Recognition, Hadamard, Accumulator Quantization, Edge Computation","transfer learning, meta learning, and lifelong learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=HwQ8NVvdmm,https://openreview.net/forum?id=HwQ8NVvdmm
BC4AUywMow,Zero-Level-Set Encoder for Neural Distance Fields,"Neural shape representation generally refers to representing 3D geometry using neural networks, e.g., to compute a signed distance or occupancy value at a specific spatial position. Previous methods tend to rely on the auto-decoder paradigm, which often requires densely-sampled and accurate signed distances to be known during training and testing, as well as an additional optimization loop during inference. This introduces a lot of computational overhead, in addition to having to compute signed distances analytically, even during testing. In this paper, we present a novel encoder-decoder neural network for embedding 3D shapes in a single forward pass. Our architecture is based on a multi-scale hybrid system incorporating graph-based and voxel-based components, as well as a continuously differentiable decoder. Furthermore, the network is trained to solve the Eikonal equation and only requires knowledge of the zero-level set for training and inference. Additional volumetric samples can be generated on-the-fly, and incorporated in an unsupervised manner. This means that in contrast to most previous work, our network is able to output valid signed distance fields without explicit prior knowledge of non-zero distance values or shape occupancy. In other words, our network computes approximate solutions to the boundary-valued Eikonal equation. It also requires only a single forward pass during inference, instead of the common latent code optimization. We further propose a modification of the loss function in case that surface normals are not well defined, e.g., in the context of non-watertight surface-meshes and non-manifold geometry. Overall, this can help reduce the computational overhead of training and evaluating neural distance fields, as well as enabling the application to difficult shapes. We finally demonstrate the efficacy, generalizability and scalability of our method on datasets consisting of deforming 3D shapes, single class encoding and multiclass encoding, showcasing a wide range of possible applications.","Stefan Rhys Jeske, Jonathan Klein, Dominik Michels, Jan Bender","~Stefan_Rhys_Jeske1, ~Jonathan_Klein2, ~Dominik_Michels1, ~Jan_Bender1","neural shape representation, neural distance fields, eikonal equation, surface mesh, encoder-decoder","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=BC4AUywMow,https://openreview.net/forum?id=BC4AUywMow
kunueR6cZU,Universal Algorithm for Extreme Bandits with the Minimal Complexities,"The Multi-Armed Bandit is a classic reinforcement learning problem that exemplifies the exploration–exploitation trade-off dilemma. When extreme values rather than expected values are of interest, the Extreme Bandit is introduced. The motivation for this work comes from black-box optimization problems and meta learning, where the goal is to find the best value for a target function from different search spaces or using multiple search heuristics. Previous work on the extreme bandit problem has assumed that rewards are drawn from an i.i.d manner, which severely limits the applicability of this class of algorithm. In this paper, with minimal temporal and spatial cost and minimal assumptions about the reward distribution, we present an novel algorithm and provide its analysis. Numerical experiments highlight the performance of the proposed algorithm to the existing approaches.","Zongyuan He, Yifeng Chen","~Zongyuan_He1, ~Yifeng_Chen1","extreme bandits, online optimization, heavy-tails, non-iid data, non-parametric",reinforcement learning,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=kunueR6cZU,https://openreview.net/forum?id=kunueR6cZU
o0oroLuPLZ,Sp-R-IP: A Decision-Focused Learning Strategy for Linear Programs that Avoids Overfitting,"For forecast-informed linear optimization problems, neural networks have shown to be effective tools for achieving robust out-of-sample performance. Various decision-focused learning paradigms have further refined those outcomes by integrating the downstream decision problem in the training pipeline. One of these strategies involves using a convex surrogate of the regret loss function to train the forecaster, called the SPO+ loss function. It allows for the training problem to be reformulated as a linear optimization program. However, this strategy has only been applied to linear forecasters, and is prone to overfitting. In this paper, we propose an extension of the SPO+ reformulation framework that solves the forecaster training procedure using an interior-point optimization method, and tracks the validation regret of intermediate results obtained for different weights of the barrier term. Additionally, we extend the reformulation framework to include the possibility of neural network forecasters with non-linear activation functions. On a real-life experiment of maximizing storage profits in a day-ahead electricity market using actual price data, we show that the proposed methodology effectively solves the problem of overfitting, and that it can outperform other decision-focused benchmarks including training the forecaster with implicit differentiation.","Ruben Smets, Mihaly Dolanyi, Jean-François Toubeau, Kenneth Bruninx, Erik Delarue","~Ruben_Smets1, ~Mihaly_Dolanyi1, ~Jean-François_Toubeau1, ~Kenneth_Bruninx1, ~Erik_Delarue1","Decision-focused learning, interior point optimization, neural networks, linear programs",optimization,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=o0oroLuPLZ,https://openreview.net/forum?id=o0oroLuPLZ
LixtB4TYY2,REVO-LION: Evaluating and Refining Vision-Language Instruction Tuning Datasets,"There is an emerging line of research on multimodal instruction tuning, and various benchmarks have been proposed for evaluating these models correspondingly. Instead of evaluating the models directly, in this paper we try to evaluate the Vision-Language Instruction-Tuning (VLIT) datasets themselves and even seek the way of building a dataset for developing an all-powerful VLIT model, which we believe could be fundamental for establishing a grounded protocol for benchmarking VLIT models. To achieve effective analysis of VLIT datasets, which remains an open question, we propose a tune-cross-evaluation paradigm: tuning on one dataset and evaluating on others in turn. For each tune-evaluation set, we define the Meta Quality (MQ) as the mean score measured by BLEU, METEOR, and ROUGE-L to quantify the quality of a dataset or a sample. On this basis, to evaluate the comprehensiveness of a dataset, we develop the Dataset Quality (DQ) covering all tune-evaluation sets. To lay the foundation for building a comprehensive dataset and developing an all-powerful model, we further create the Sample Quality (SQ) quantifying the all-sided quality of each sample. Extensive experiments validate the rationality of the proposed evaluation paradigm. According to the holistic evaluation, we build a new dataset, REVO-LION (REfining VisiOn-Language InstructiOn tuNing), by collecting samples with higher SQ from each dataset. With only half of the full data, the model trained on REVO-LION can achieve performance comparable to simply adding all VLIT datasets up. In addition to developing an all-powerful model, REVO-LION also includes an evaluation set, which is expected to serve as a convenient evaluation benchmark for future research.","Ning Liao, Shaofeng Zhang, Renqiu Xia, Bo Zhang, Min Cao, Yu Qiao, Junchi Yan","~Ning_Liao1, ~Shaofeng_Zhang1, ~Renqiu_Xia2, ~Bo_Zhang17, ~Min_Cao2, ~Yu_Qiao1, ~Junchi_Yan2","Evaluation, Refine, Vision-Language, Instruction Tuning.",datasets and benchmarks,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=LixtB4TYY2,https://openreview.net/forum?id=LixtB4TYY2
nFMS6wF2xq,Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing,"Conditional diffusion models have exhibited superior performance in high-fidelity text-guided visual generation and editing. Nevertheless, prevailing text-guided visual diffusion models primarily focus on incorporating text-visual relationships exclusively into the reverse process, often disregarding their relevance in the forward process. This inconsistency between forward and reverse processes may
limit the precise conveyance of textual semantics in visual synthesis results. To address this issue, we propose a novel and general contextualized diffusion model (ContextDiff) by incorporating the cross-modal context encompassing interactions and alignments between text condition and visual sample into forward and reverse processes. We propagate this context to all timesteps in the two processes to adapt their trajectories, thereby facilitating cross-modal conditional modeling. We generalize our contextualized diffusion to both DDPMs and DDIMs with theoretical derivations, and demonstrate the effectiveness of our model in evaluations with two challenging tasks: text-to-image generation, and text-to-video editing. In each task, our ContextDiff achieves new state-of-the-art performance, significantly enhancing the semantic alignment between text condition and generated samples, as evidenced by quantitative and qualitative evaluations. Our code is available at https://github.com/YangLing0818/ContextDiff","Ling Yang, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin CUI","~Ling_Yang1, ~Zhilong_Zhang1, ~Zhaochen_Yu2, ~Jingwei_Liu4, ~Minkai_Xu1, ~Stefano_Ermon1, ~Bin_CUI2","Diffusion Model, Text-to-Image Generation, Text-to-Video Editing",generative models,ICLR 2024 poster,2024,https://openreview.net/pdf?id=nFMS6wF2xq,https://openreview.net/forum?id=nFMS6wF2xq
EUywF11YVi,SimPLR: A Simple and Plain Transformer for Object Detection and Segmentation,"The ability to detect objects in images at varying scales has played a pivotal role in the design of modern object detectors. Despite considerable progress in removing handcrafted components using transformers, multi-scale feature maps remain a key factor for their empirical success, even with a plain backbone like the Vision Transformer (ViT). In this paper, we show that this reliance on feature pyramids is unnecessary and a transformer-based detector with scale-aware attention enables the plain detector `SimPLR' whose backbone and detection head both operate on single-scale features. The plain architecture allows SimPLR to effectively take advantages of self-supervised learning and scaling approaches with ViTs, yielding strong performance compared to multi-scale counterparts. We demonstrate through our experiments that when scaling to larger backbones, SimPLR indicates better performance than end-to-end detectors (Mask2Former) and plain-backbone detectors (ViTDet), while consistently being faster. The code will be released.","Duy Kien Nguyen, Martin R. Oswald, Cees G. M. Snoek","~Duy_Kien_Nguyen1, ~Martin_R._Oswald1, ~Cees_G._M._Snoek1","Plain Detection, Single-scale Segmentation","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=EUywF11YVi,https://openreview.net/forum?id=EUywF11YVi
rtx8B94JMS,Variational Inference for SDEs Driven by Fractional Noise,"We present a novel variational framework for performing inference in (neural) stochastic differential equations (SDEs) driven by Markov-approximate fractional Brownian motion (fBM). SDEs offer a versatile tool for modeling real-world continuous-time dynamic systems with inherent noise and randomness. Combining SDEs with the powerful inference capabilities of variational methods, enables the learning of representative distributions through stochastic gradient descent. However, conventional SDEs typically assume  the underlying noise to follow a Brownian motion (BM), which hinders their ability to capture long-term dependencies. In contrast, fractional Brownian motion (fBM) extends BM to encompass non-Markovian dynamics, but existing methods for inferring fBM parameters are either computationally demanding or statistically inefficient. 

In this paper, building upon the Markov approximation of fBM, we derive the evidence lower bound essential for efficient variational inference of posterior path measures, drawing from the well-established field of stochastic analysis. Additionally, we provide a closed-form expression for optimal approximation coefficients and propose to use neural networks to learn the drift, diffusion and control terms within our variational posterior, leading to the variational training of neural-SDEs. In this framework, we also optimize the Hurst index, governing the nature of our fractional noise. Beyond validation on synthetic data, we contribute a novel architecture for variational latent video prediction,—an approach that, to the best of our knowledge, enables the first variational neural-SDE application to video perception.","Rembert Daems, Manfred Opper, Guillaume Crevecoeur, Tolga Birdal","~Rembert_Daems1, ~Manfred_Opper1, ~Guillaume_Crevecoeur1, ~Tolga_Birdal3","variational inference, neural sdes, stochastic differential equations, brownian motion, fractional noise, fractional brownian motion, markov approximation, markov representation","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=rtx8B94JMS,https://openreview.net/forum?id=rtx8B94JMS
zeobgjmUCc,Using Machine Learning Models to Predict Genitourinary Involvement Among Gastrointestinal Stromal Tumour Patients,"Gastrointestinal stromal tumors (GISTs) can lead to involvement of other organs, including the genitourinary (GU) system. Machine learning may be a valuable tool in predicting GU involvement in GIST patients, and thus improving prognosis. This study aims to evaluate the use of machine learning algorithms to predict GU involvement among GIST patients in a specialist research center in Saudi Arabia. We analyzed data from all patients with histopathologically confirmed GIST at our facility from 2003 to 2020. Patient files were reviewed for the presence of renal cell carcinoma, adrenal tumors, or other genitourinary cancers. Three supervised machine learning algorithms were used: Logistic Regression, XGBoost Regressor, and Random Forests. A set of variables, including independent attributes, was entered into the models. A total of 170 patients were included in the study, with 58.8% (n=100) being male. The median age was 57 (range 9-91) years. The majority of GISTs were gastric (60%, n=102) with a spindle cell histology. The most common stage at diagnosis was T2 (27.6%, n=47) and N0 (20%, n=34). Six patients (3.5%) had GU involvement. The Random Forest model achieved the highest accuracy with 97.1%. Our study suggests that the Random Forest model is an effective tool for predicting GU involvement in GIST patients. Larger multicenter studies, utilizing more powerful algorithms such as deep learning and other artificial intelligence subsets, are necessary to further refine and improve these predictions.","Abdulhameed Abiola Dere, Muhammad Alghafees","~Abdulhameed_Abiola_Dere1, alghafees687@gmail.com","Artificial intelligence, Gastrointestinal stromal tumors, Genitourinary oncology, Gastrointestinal oncology, Urology, Urologic oncology","applications to physical sciences (physics, chemistry, biology, etc.)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=zeobgjmUCc,https://openreview.net/forum?id=zeobgjmUCc
zOjW6yVYkE,Zero-Shot Video Sampling from Image,"Incorporating a temporal dimension into pretrained image diffusion models for video generation is a prevalent approach. However, this method is computationally demanding and necessitates large-scale video datasets. More critically, the heterogeneity between image and video datasets often results in catastrophic forgetting of the image expertise. Recent attempts to directly extract video snippets from image diffusion models have somewhat mitigated these problems. Nevertheless, these methods can only generate brief video clips with simple movements and fail to capture fine-grained motion or non-grid deformation.
In this paper, we propose a novel Zero-Shot video Sampling algorithm, denoted as $\mathcal{ZS}^2$, capable of directly sampling high-quality video clips from existing image synthesis methods, such as Stable Diffusion, without any training or optimization. Specifically, $\mathcal{ZS}^2$ utilizes the dependency noise model and temporal momentum attention to ensure content consistency and animation coherence, respectively. This ability enables it to excel in related tasks, such as conditional and context-specialized video generation and instruction-guided video editing. Experimental results demonstrate that $\mathcal{ZS}^2$ achieves state-of-the-art performance in zero-shot video generation, occasionally outperforming recent supervised methods.","Dengsheng Chen, Jie Hu, Xiaoming Wei","~Dengsheng_Chen1, ~Jie_Hu4, ~Xiaoming_Wei1","AIGC, diffusion model, zero shot, video sampling",generative models,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=zOjW6yVYkE,https://openreview.net/forum?id=zOjW6yVYkE
vxzRcFd837,Rethinking One-vs-the-Rest Loss for Instance-dependent Complementary Label Learning,"Complementary Label Learning (CLL) is a typical weakly supervised learning protocol, where each instance is associated with one complementary label, which specifies the class that the instance does not belong to. Existing CLL methods assume that the complementary label is sampled uniformly from all non-ground-truth labels, or from a biased probability depending on the ground-truth label. However, these assumptions are normally unrealistic, for example, an annotator tends to choose a label that is largely irrelevant to the instance to avoid mistaking the ground-truth label as the complementary one. Therefore, in this paper, we introduce instance-dependent CLL (IDCLL), where non-ground-truth labels that are less relevant to the instances are more likely to be selected as the complementary ones. Accordingly, we present our generation process for instance-dependent complementary label and observe that directly applying existing CLL methods to IDCLL results in poor performance. We further empirically analyze this phenomenon and identify: Existing methods exhibit a decline in their capacity to share complementary labels under the instance-dependent setting, resulting in small logit margins, thus difficult to identify ground-truth labels. To address this problem, we introduce complementary logit margin loss (CLML) and demonstrate CLML can enhance the capacity to share complementary labels. Additionally, we propose a novel form of the complementary one-vs-the-rest loss (COVR) as the surrogate loss for CLML, and provide theoretical proof that COVR can decrease CLML to a greater extent compared to existing CLL methods. The estimation error bound of COVR is also theoretically characterized. Extensive experiments conducted on benchmark datasets demonstrate the superiority of the proposed method compared to the existing CLL methods under our instance-dependent setting.","Yiwei You, Jinlong Huang, Bo Wang, Qiang Tong","~Yiwei_You1, ~Jinlong_Huang2, ~Bo_Wang14, ~Qiang_Tong1","Complementary Label Learning, Weakly Supervised Learning, Generalization Error Estimation, Instance Dependent, One-vs-the-Rest Loss, Logit Margin","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=vxzRcFd837,https://openreview.net/forum?id=vxzRcFd837
z282NEQDbF,Comparative Knowledge Distillation,"In the era of large-scale pretrained models, Knowledge Distillation (KD) serves an important role in transferring the wisdom of computationally-heavy teacher models to lightweight, efficient student models while preserving performance. Traditional KD paradigms, however, assume readily available access to teacher models for frequent inference—a notion increasingly at odds with the realities of costly, often proprietary, large-scale models. Addressing this gap, our paper considers how to minimize the dependency on teacher model inferences in KD in a setting we term Few-Teacher-Inference Knowledge Distillation (FTI-KD). We observe that prevalent KD techniques and state-of-the-art data augmentation strategies fall short in this constrained setting. Drawing inspiration from educational principles that emphasize learning through comparison, we propose Comparative Knowledge Distillation (CKD), which encourages student models to understand the nuanced differences in a teacher model’s interpretations of samples. Critically, CKD provides additional learning signals to the student without making additional teacher calls. We also extend the principle of CKD to groups of samples, enabling even more efficient learning from limited teacher calls. Empirical evaluation across varied experimental settings indicates that CKD consistently outperforms state-of-the-art data augmentation and KD techniques.","Alex Wilf, Alex Tianyi Xu, Paul Pu Liang, Alexander Obolenskiy, Daniel Fried, Louis-Philippe Morency","~Alex_Wilf1, ~Alex_Tianyi_Xu1, ~Paul_Pu_Liang1, ~Alexander_Obolenskiy1, ~Daniel_Fried1, ~Louis-Philippe_Morency1","knowledge distillation, low-resource, data augmentation","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=z282NEQDbF,https://openreview.net/forum?id=z282NEQDbF
rUH2EDpToF,Generative Marginalization Models,"We introduce *marginalization models* (MAMs), a new family of generative models
for high-dimensional discrete data. They offer scalable and flexible generative modeling with tractable likelihoods 
by explicitly modeling all induced marginal distributions. Marginalization models enable fast evaluation of arbitrary marginal probabilities with a single forward pass of the neural network, which overcomes a major limitation of methods with exact marginal inference, such as autoregressive models (ARMs). We propose scalable methods for learning the marginals, grounded in the concept of “*marginalization self-consistency*”. Unlike previous methods, MAMs support scalable training of any-order generative models for high-dimensional problems under the setting of *energy-based training*, where the goal is to match the learned distribution to a given desired probability (specified
by an unnormalized (log) probability function such as energy function or reward function). We demonstrate the effectiveness of the proposed model on a variety of discrete data distributions, including binary images, language, physical systems, and molecules, for *maximum likelihood* and *energy-based training* settings. MAMs achieve orders of magnitude speedup in evaluating the marginal probabilities on both settings. For energy-based training tasks, MAMs enable any-order generative modeling of high-dimensional problems beyond the capability of previous methods.","Sulin Liu, Peter Ramadge, Ryan P Adams","~Sulin_Liu1, ~Peter_Ramadge1, ~Ryan_P_Adams1","discrete generative models, marginalization, probabilistic models",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=rUH2EDpToF,https://openreview.net/forum?id=rUH2EDpToF
RIu5lyNXjT,Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting,"As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FormatSpread, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.","Melanie Sclar, Yejin Choi, Yulia Tsvetkov, Alane Suhr","~Melanie_Sclar1, ~Yejin_Choi1, ~Yulia_Tsvetkov1, ~Alane_Suhr1","large language models, sensitivity analysis, prompt engineering, evaluation, prompting, robustness, in-context learning, spurious features",generative models,ICLR 2024 poster,2024,https://openreview.net/pdf?id=RIu5lyNXjT,https://openreview.net/forum?id=RIu5lyNXjT
iWi2mL8qoc,Multi-Scale Window based Transformer Network for High Quality Image Inpainting,"To achieve effective image inpainting, it is crucial for the model to understand contextual information. Previous studies using CNN-based algorithms have encountered limitations due to the absence of long-range dependencies, which resulted in the model's inability to capture contextual information. In this paper, we propose a Multi-Scale Window-based Transformer model for high-quality image inpainting. We introduce a transformer network with multi-scale windows to capture the influence of different window sizes and gather significant contextual information. To effectively integrate features processed through self-attention, we modified the polarized self-attention network to align with the dimensions of the multi-window scale. We also propose the Selective Mask Update method, which captures vital information from features processed by self-attention, enabling the generation of higher-quality results. Experiments show that it effectively fills in missing areas and demonstrates superior performance on the benchmark dataset compared to other models.","SeongJoo Kim, Jaeyoung Choi","~SeongJoo_Kim1, ~Jaeyoung_Choi2","Image inpainting, Image completion, Transformer, Multi-scale window, Polarized self-attention, Mask updating",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=iWi2mL8qoc,https://openreview.net/forum?id=iWi2mL8qoc
W478nWXfwO,What Makes Pre-Trained Visual Representations Successful for Robust Manipulation?,"Inspired by the success of transfer learning in computer vision, roboticists have investigated visual pre-training as a means to improve the learning efficiency and generalization ability of policies learned from pixels. To that end, past work has favored large object interaction datasets, such as first-person videos of humans completing diverse tasks, in pursuit of manipulation-relevant features. Although this approach improves the efficiency of policy learning, it remains unclear how reliable these representations are in the presence of distribution shifts that arise commonly in robotic applications. Surprisingly, we find that visual representations designed for manipulation and control tasks do not necessarily generalize under subtle changes in lighting and scene texture or the introduction of distractor objects. To understand what properties \textit{do} lead to robust representations, we compare the performance of 15 pre-trained vision models under different visual appearances. We find that emergent segmentation ability is a strong predictor of out-of-distribution generalization among ViT models. The rank order induced by this metric is more predictive than metrics that have previously guided generalization research within computer vision and machine learning, such as downstream ImageNet accuracy, in-domain accuracy, or shape-bias as evaluated by cue-conflict performance. We test this finding extensively on a suite of distribution shifts in ten tasks across two simulated manipulation environments. On the ALOHA setup, segmentation score predicts real-world performance after offline training with 50 demonstrations.","Kaylee Burns, Zach Witzel, Jubayer Ibn Hamid, Tianhe Yu, Chelsea Finn, Karol Hausman","~Kaylee_Burns2, ~Zach_Witzel1, ~Jubayer_Ibn_Hamid1, ~Tianhe_Yu1, ~Chelsea_Finn1, ~Karol_Hausman2","pre-trained visual representations, robot learning, robustness","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=W478nWXfwO,https://openreview.net/forum?id=W478nWXfwO
V2cBKtdC3a,Exploring the Promise and Limits of Real-Time Recurrent Learning,"Real-time recurrent learning (RTRL) for sequence-processing recurrent neural networks (RNNs) offers certain conceptual advantages over backpropagation through time (BPTT). RTRL requires neither caching past activations nor truncating context, and enables online learning. However, RTRL's time and space complexity make it impractical. To overcome this problem, most recent work on RTRL focuses on approximation theories, while experiments are often limited to diagnostic settings. Here we explore the practical promise of RTRL in more realistic settings. We study actor-critic methods that combine RTRL and policy gradients, and test them in several subsets of DMLab-30, ProcGen, and Atari-2600 environments. On DMLab memory tasks, our system trained on fewer than 1.2B environmental frames is competitive with or outperforms well-known IMPALA and R2D2 baselines trained on 10B frames. To scale to such challenging tasks, we focus on certain well-known neural architectures with element-wise recurrence, allowing for tractable RTRL without approximation. Importantly, we also discuss rarely addressed limitations of RTRL in real-world applications, such as its complexity in the multi-layer case.","Kazuki Irie, Anand Gopalakrishnan, Jürgen Schmidhuber","~Kazuki_Irie1, ~Anand_Gopalakrishnan1, ~Jürgen_Schmidhuber1","recurrent neural networks, real-time recurrent learning, online recurrent learning, reinforcement learning, actor-critic, policy gradients","general machine learning (i.e., none of the above)",ICLR 2024 poster,2024,https://openreview.net/pdf?id=V2cBKtdC3a,https://openreview.net/forum?id=V2cBKtdC3a
b8hRudcKQ3,Performance Adjustment for Federated Learning Marketplace,"In federated learning, client participation is mainly motivated by performance-gain rewards or monetary rewards. In practice, different clients may have varying preferences over these two types of rewards. However, optimizing the training process to align model performance and monetary rewards with client expectations remains an open challenge. To accommodate diverse reward preferences, we propose Alpha-Tuning, an FL performance adjustment framework guided by dynamic validation loss composition. The core of our framework is a mechanism to decide the weights assigned to clients' local validation loss, each of which is determined by the corresponding client's performance contribution in the given training round and its monetary quotation for biasing this FL course towards its favor. The training hyper-parameters and model aggregation weights are adjusted together with model parameters to minimize the weighted sums of clients' local validation losses in our framework. Paired with a payment rule designed to compensate the clients according to their data contribution, Alpha-Tuning balances the clients' preferences between the performance gain and monetary reward. We demonstrate the effectiveness of our framework by conducting experiments on the federated learning tasks under various client quotation settings.","Liuyi Yao, Zitao Li, Weirui Kuang, Yaliang Li, Bolin Ding","~Liuyi_Yao1, ~Zitao_Li1, ~Weirui_Kuang2, ~Yaliang_Li1, ~Bolin_Ding3","Federated Learning, Incentive Mechanism","general machine learning (i.e., none of the above)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=b8hRudcKQ3,https://openreview.net/forum?id=b8hRudcKQ3
gnWk0ZF22j,Customized Procedure Planning in Instructional Videos,"Generating customized procedures for task planning in instructional videos poses a unique challenge for vision-language models. In this paper, we introduce Customized Procedure Planning in Instructional Videos, a novel task that focuses on generating a sequence of detailed action steps for task completion based on user requirements and the task's initial visual state. Existing methods often neglect customization and user directions, limiting their real-world applicability. The absence of instructional video datasets with step-level state and video-specific action plan annotations has hindered progress in this domain. To address these challenges, we introduce the Customized Procedure Planner (CPP) framework, a causal, open-vocabulary model that leverages a LlaVA-based approach to predict procedural plans based on a task's initial visual state and user directions. To overcome the data limitation, we employ a weakly-supervised approach, using the strong vision-language model GEMINI and the large language model (LLM) GPT-4 to create detailed  video-specific action plans from the benchmark instructional video datasets (COIN, CrossTask), producing pseudo-labels for training. Discussing the limitations of the existing procedure planning evaluation metrics in an open-vocabulary setting, we propose novel automatic LLM-based metrics with few-shot in-context learning to evaluate the customization and planning capabilities of our model, setting a strong baseline. Additionally, we implement an LLM-based objective function to enhance model training for improved customization. Extensive experiments, including human evaluations, demonstrate the effectiveness of our approach, establishing a strong baseline for future research in customized procedure planning.","Ali Zare, Constantine Tsibouris, Xudong Lin, Li Zhang, Ming-Hsuan Yang, Shih-Fu Chang","~Ali_Zare1, ~Constantine_Tsibouris1, ~Xudong_Lin1, ~Li_Zhang1, ~Ming-Hsuan_Yang1, ~Shih-Fu_Chang3","Customized Procedure Planning, multi-modal models, vision-language models","applications to robotics, autonomy, planning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=gnWk0ZF22j,https://openreview.net/forum?id=gnWk0ZF22j
gJG4IPwg6l,Safety Representations for Safer Policy Learning,"Reinforcement learning algorithms typically necessitate extensive exploration of the state space to find optimal policies. However, in safety-critical applications, the risks associated with such exploration can lead to catastrophic consequences. Existing safe exploration methods attempt to mitigate this by imposing constraints, which often result in overly conservative behaviours and inefficient learning. Heavy penalties for early constraint violations can trap agents in local optima, deterring exploration of risky yet high-reward regions of the state space. To address this, we introduce a method that explicitly learns state-conditioned safety representations. By augmenting the state features with these safety representations, our approach naturally encourages safer exploration without being excessively cautious, resulting in more efficient and safer policy learning in safety-critical scenarios. Empirical evaluations across diverse environments show that our method significantly improves task performance while reducing constraint violations during training, underscoring its effectiveness in balancing exploration with safety.","Kaustubh Mani, Vincent Mai, Charlie Gauthier, Annie S Chen, Samer B. Nashed, Liam Paull","~Kaustubh_Mani1, ~Vincent_Mai1, ~Charlie_Gauthier1, ~Annie_S_Chen1, ~Samer_B._Nashed1, ~Liam_Paull1","Reinforcement Learning, Safe Exploration, Representation Learning",reinforcement learning,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=gJG4IPwg6l,https://openreview.net/forum?id=gJG4IPwg6l
RQ9fQLEajC,Routoo: Learning to Route to Large Language Models Effectively,"LLMs with superior response quality—particularly larger or closed-source models—often come with higher inference costs, making their deployment inefficient and costly. Meanwhile, developing foundational LLMs from scratch is becoming increasingly resource-intensive and impractical for many applications. To address the challenge of balancing quality and cost, we introduce Routoo, an architecture designed to optimize the selection of LLMs for specific prompts based on performance, cost, and efficiency. Routoo provides controllability over the trade-off between inference cost and quality, enabling significant reductions in inference costs for a given quality requirement.
Routoo comprises two key components: a performance predictor and cost-aware selector. The performance predictor is a lightweight LLM that estimates the expected performance of various underlying LLMs on a given prompt without executing them. The cost-aware selector module then selects the most suitable model based on these predictions and constraints such as cost and latency, significantly reducing inference costs for the same quality. 
We evaluated Routoo using the MMLU benchmark across 57 domains employing open-source models. Our results show that Routoo matches the performance of the Mixtral 8x7b model while reducing inference costs by one-third. Additionally, by allowing increased costs, Routoo surpasses Mixtral's accuracy by over 5\% at equivalent costs, achieving an accuracy of 75.9\%. When integrating GPT4 into our model pool, Routoo nearly matches GPT4's performance at half the cost and exceeds it with a 25\% cost reduction. 
These outcomes highlight Routoo's potential to significantly reduce inference costs without compromising quality, and even to establish new state-of-the-art results by leveraging the collective capabilities of multiple LLMs.","Alireza Mohammadshahi, Arshad Rafiq Shaikh, Majid Yazdani","~Alireza_Mohammadshahi1, ~Arshad_Rafiq_Shaikh1, ~Majid_Yazdani1","LLM, efficiency, knowledge integration, generation",generative models,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=RQ9fQLEajC,https://openreview.net/forum?id=RQ9fQLEajC
SDV7Y6Dhx9,Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios,"Dataset distillation has demonstrated strong performance on simple datasets like CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in more complex scenarios. 
In this paper, we propose a novel approach that \textbf{e}mphasizes the \textbf{d}iscriminative \textbf{f}eatures (obtained by Grad-CAM) for dataset distillation, called \textbf{EDF}.
Our approach is inspired by a key observation: in simple datasets, high-activation areas typically occupy most of the image, whereas in complex scenarios, the size of these areas is much smaller.
Unlike previous methods that treat all pixels equally when synthesizing images, EDF uses Grad-CAM activation maps to enhance high-activation areas.
From a supervision perspective, we downplay supervision signals that have lower losses, as they contain common patterns.
Additionally, to help the DD community better explore complex scenarios, we build the Complex Dataset Distillation (Comp-DD) benchmark by meticulously selecting sixteen subsets, eight easy and eight hard, from ImageNet-1K.
Notably, EDF consistently outperforms SOTA results in complex scenarios, such as ImageNet-1K subsets.
Hopefully, more researchers will be inspired and encouraged to enhance the practicality and efficacy of DD. 
Our code and benchmark will be made public.","Kai Wang, Zekai Li, Zhi-Qi Cheng, Samir Khaki, Ahmad Sajedi, Shanmukha Ramakrishna Vedantam, Konstantinos N Plataniotis, Alexander G Hauptmann, Yang You","~Kai_Wang8, ~Zekai_Li2, ~Zhi-Qi_Cheng1, ~Samir_Khaki1, ~Ahmad_Sajedi2, ~Shanmukha_Ramakrishna_Vedantam1, ~Konstantinos_N_Plataniotis1, ~Alexander_G_Hauptmann1, ~Yang_You1",dataset distillation,"applications to computer vision, audio, language, and other modalities",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=SDV7Y6Dhx9,https://openreview.net/forum?id=SDV7Y6Dhx9
7rq2OzkJg3,Personalized Federated Learning With Similarity Information Supervisor,"A crucial issue in federated learning is the heterogeneity of data between clients, which can lead to model weight divergence, eventually deteriorating the model performance. Personalized federated learning (pFL) has been proven to be an effective approach to addressing data heterogeneity in federated learning. However, existing pFL studies seldom verify whether the broadcast global model is beneficial for the local model performance. To address this, we propose a novel pFL method, called federated learning with similarity information supervision (FedSimSup). Specifically, FedSimSup incorporates a local supervisor to assist the model training and a personalized model for global information aggregation. The role of the supervisor is to refine the personalized model when it is not beneficial for the local model performance, ensuring the effective global information aggregation while aligning with the local heterogeneous data. Additionally, the similarity relationships between the clients are measured using label distribution differences of the local raw data to weight the personalized models, promoting information usage among similar clients. Experimental results demonstrate three advantages of FedSimSup: (1) It shows better performance over heterogeneous data compared with seven state-of-the-art federated learning methods; (2) It can allow for different model architectures across different clients; (3) It offers a certain degree of interpretability.","Jiaqiang Li, Qiqi Liu, Yaochu Jin, Xiaohu Wu, Zhilong Li, Han Yu","~Jiaqiang_Li1, ~Qiqi_Liu2, ~Yaochu_Jin1, ~Xiaohu_Wu2, ~Zhilong_Li3, ~Han_Yu1","Personalized Federated Learning, Heterogeneous Data","transfer learning, meta learning, and lifelong learning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=7rq2OzkJg3,https://openreview.net/forum?id=7rq2OzkJg3
mqKVe6F3Up,Subtask-Aware Visual Reward Learning from Segmented Demonstrations,"Reinforcement Learning (RL) agents have demonstrated their potential across various robotic tasks. However, they still heavily rely on human-engineered reward functions, requiring extensive trial-and-error and access to target behavior information, often unavailable in real-world settings. This paper introduces REDS: REward learning from Demonstration with Segmentations, a novel reward learning framework that leverages action-free videos with minimal supervision. Specifically, REDS employs video demonstrations segmented into subtasks from diverse sources and treats these segments as ground-truth rewards. We train a dense reward function conditioned on video segments and their corresponding subtasks to ensure alignment with ground-truth reward signals by minimizing the Equivalent-Policy Invariant Comparison distance. Additionally, we employ contrastive learning objectives to align video representations with subtasks, ensuring precise subtask inference during online interactions. Our experiments show that REDS significantly outperforms baseline methods on complex robotic manipulation tasks in Meta-World and more challenging real-world tasks, such as furniture assembly in FurnitureBench, with minimal human intervention. Moreover, REDS facilitates generalization to unseen tasks and robot embodiments, highlighting its potential for scalable deployment in diverse environments.","Changyeon Kim, Minho Heo, Doohyun Lee, Honglak Lee, Jinwoo Shin, Joseph J Lim, Kimin Lee","~Changyeon_Kim1, ~Minho_Heo1, ~Doohyun_Lee2, ~Honglak_Lee2, ~Jinwoo_Shin1, ~Joseph_J_Lim1, ~Kimin_Lee1","Reinforcement Learning, Reward Learning, Robotic Manipulation","applications to robotics, autonomy, planning",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=mqKVe6F3Up,https://openreview.net/forum?id=mqKVe6F3Up
OATPSB5JK1,Model-based Offline Reinforcement Learning with Lower Expectile Q-Learning,"Model-based offline reinforcement learning (RL) is a compelling approach that addresses the challenge of learning from limited, static data by generating imaginary trajectories using learned models. However, these approaches often struggle with inaccurate value estimation from model rollouts. In this paper, we introduce a novel model-based offline RL method, Lower Expectile Q-learning (LEQ), which provides a low-bias model-based value estimation via lower expectile regression of $\lambda$-returns. Our empirical results show that LEQ significantly outperforms previous model-based offline RL methods on long-horizon tasks, such as the D4RL AntMaze tasks, matching or surpassing the performance of model-free approaches and sequence modeling approaches. Furthermore, LEQ matches the performance of state-of-the-art model-based and model-free methods in dense-reward environments across both state-based tasks (NeoRL and D4RL) and pixel-based tasks (V-D4RL), showing that LEQ works robustly across diverse domains. Our ablation studies demonstrate that lower expectile regression, $\lambda$-returns, and critic training on offline data are all crucial for LEQ.","Kwanyoung Park, Youngwoon Lee","~Kwanyoung_Park1, ~Youngwoon_Lee1","model-based offline reinforcement learning, offline reinforcement learning, lower expectile return",reinforcement learning,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=OATPSB5JK1,https://openreview.net/forum?id=OATPSB5JK1
zUlK1qMIcE,Active partitioning: inverting the paradigm of active learning,"Datasets often incorporate various functional patterns related to different aspects or regimes, which are typically not equally present throughout the dataset. We propose a novel, general-purpose partitioning algorithm that utilizes competition between models to detect and separate these functional patterns. This competition is induced by multiple models iteratively submitting their predictions for the dataset, with the best prediction for each data point being rewarded with training on that data point. This reward mechanism amplifies each model’s strengths and encourages specialization in different patterns. The specializations can then be translated into a partitioning scheme. The amplification of each model’s strengths inverts the active learning paradigm: while active learning typically focuses the training of models on their weaknesses to minimize the number of required training data points, our concept reinforces the strengths of each model, thus specializing them. We validate our concept -- called active partitioning -- with various datasets with clearly distinct functional patterns, such as mechanical stress and strain data in a porous structure. The active partitioning algorithm produces valuable insights into the datasets’ structure, which can serve various further applications. As a demonstration of one exemplary usage, we set up modular models consisting of multiple expert models, each learning a single partition, and compare their performance on more than twenty popular regression problems with single models learning all partitions simultaneously. Our results show significant improvements, with up to 54% loss reduction, confirming our partitioning algorithm’s utility.","Marius Tacke, Matthias Busch, Kevin Linka, Christian J Cyron, Roland Aydin","~Marius_Tacke1, ~Matthias_Busch1, ~Kevin_Linka1, ~Christian_J_Cyron1, ~Roland_Aydin1","Partitioning, Pattern-recognition, Clustering, Active learning, Modular networks","transfer learning, meta learning, and lifelong learning",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=zUlK1qMIcE,https://openreview.net/forum?id=zUlK1qMIcE
5IkDAfabuo,Prioritized Generative Replay,"Sample-efficient online reinforcement learning often uses replay buffers to store experience for reuse when updating the value function. 
However, uniform replay is inefficient, since certain classes of transitions can be more relevant to learning. While prioritization of more useful samples is helpful, this strategy can also lead to overfitting, as useful samples are likely to be more rare. In this work, we instead propose a prioritized, parametric version of an agent's memory, using generative models to capture online experience. This paradigm enables (1) densification of past experience, with new generations that benefit from the generative model's generalization capacity and (2) guidance via a family of ""relevance functions"" that push these generations towards more useful parts of an agent's acquired history. We show this recipe can be instantiated using conditional diffusion models and simple relevance functions such as curiosity- or value-based metrics. Our approach consistently improves performance and sample efficiency in both state- and pixel-based domains. We expose the mechanisms underlying these gains, showing how guidance promotes diversity in our generated transitions and reduces overfitting. We also showcase how our approach can train policies with even higher update-to-data ratios than before, opening up avenues to better scale online RL agents. Project page available at: https://pgenreplay.github.io","Renhao Wang, Kevin Frans, Pieter Abbeel, Sergey Levine, Alexei A Efros","~Renhao_Wang1, ~Kevin_Frans1, ~Pieter_Abbeel2, ~Sergey_Levine1, ~Alexei_A_Efros1","online learning, model-based reinforcement learning, generative modeling, synthetic data, continual learning",reinforcement learning,ICLR 2025 Oral,2025,https://openreview.net/pdf?id=5IkDAfabuo,https://openreview.net/forum?id=5IkDAfabuo
JDiER86r8v,MMAD: A Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection,"In the field of industrial inspection, Multimodal Large Language Models (MLLMs) have a high potential to renew the paradigms in practical applications due to their robust language capabilities and generalization abilities. However, despite their impressive problem-solving skills in many domains, MLLMs' ability in industrial anomaly detection has not been systematically studied. To bridge this gap, we present MMAD, a full-spectrum MLLM benchmark in industrial Anomaly Detection. We defined seven key subtasks of MLLMs in industrial inspection and designed a novel pipeline to generate the MMAD dataset with 39,672 questions for 8,366 industrial images. With MMAD, we have conducted a comprehensive, quantitative evaluation of various state-of-the-art MLLMs. The commercial models performed the best, with the average accuracy of GPT-4o models reaching 74.9\%. However, this result falls far short of industrial requirements. Our analysis reveals that current MLLMs still have significant room for improvement in answering questions related to industrial anomalies and defects. We further explore two training-free performance enhancement strategies to help models improve in industrial scenarios, highlighting their promising potential for future research. 
The code and data are available at https://github.com/jam-cc/MMAD.","Xi Jiang, Jian Li, Hanqiu Deng, Yong Liu, Bin-Bin Gao, Yifeng Zhou, Jialin Li, Chengjie Wang, Feng Zheng","~Xi_Jiang3, ~Jian_Li12, ~Hanqiu_Deng1, ~Yong_Liu12, ~Bin-Bin_Gao1, ~Yifeng_Zhou1, ~Jialin_Li3, ~Chengjie_Wang1, ~Feng_Zheng1","Anomaly Detection, Multimodal Large Language Model, Industrial Inspection",datasets and benchmarks,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=JDiER86r8v,https://openreview.net/forum?id=JDiER86r8v
hgvERMkXOx,"Watch Less, Do More: Implicit Skill Discovery for Video-Conditioned Policy","In this paper, we study the problem of video-conditioned policy learning. While previous works mostly focus on learning policies that perform a single skill specified by the given video, we take a step further and aim to learn a policy that can perform multiple skills according to the given video, and generalize to unseen videos by recombining these skills. To solve this problem, we propose our algorithm, Watch-Less-Do-More, an information bottleneck-based imitation learning framework for implicit skill discovery and video-conditioned policy learning. In our method, an information bottleneck objective is employed to control the information contained in the video representation, ensuring that it only encodes information relevant to the current skill (Watch-Less). By discovering potential skills from training videos, the learned policy is able to recombine them and generalize to unseen videos to achieve compositional generalization (Do-More). To evaluate our method, we perform extensive experiments in various environments and show that our algorithm substantially outperforms baselines (up to 2x) in terms of compositional generalization ability.","Jiangxing Wang, Zongqing Lu","~Jiangxing_Wang2, ~Zongqing_Lu2","video-conditioned policy, compositional generalization","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=hgvERMkXOx,https://openreview.net/forum?id=hgvERMkXOx
VEqPDZIDAh,Language Model Alignment in Multilingual Trolley Problems,"We evaluate the moral alignment of large language models (LLMs) with human preferences in multilingual trolley problems. Building on the Moral Machine experiment, which captures over 40 million human judgments across 200+ countries, we develop a cross-lingual corpus of moral dilemma vignettes in over 100 languages called MultiTP. This dataset enables the assessment of LLMs' decision-making processes in diverse linguistic contexts. Our analysis explores the alignment of 19 different LLMs with human judgments, capturing preferences across six moral dimensions: species, gender, fitness, status, age, and the number of lives involved. By correlating these preferences with the demographic distribution of language speakers and examining the consistency of LLM responses to various prompt paraphrasings, our findings provide insights into cross-lingual and ethical biases of LLMs and their intersection. We discover significant variance in alignment across languages, challenging the assumption of uniform moral reasoning in AI systems and highlighting the importance of incorporating diverse perspectives in AI ethics. The results underscore the need for further research on the integration of multilingual dimensions in responsible AI research to ensure fair and equitable AI interactions worldwide.","Zhijing Jin, Max Kleiman-Weiner, Giorgio Piatti, Sydney Levine, Jiarui Liu, Fernando Gonzalez Adauto, Francesco Ortu, András Strausz, Mrinmaya Sachan, Rada Mihalcea, Yejin Choi, Bernhard Schölkopf","~Zhijing_Jin1, ~Max_Kleiman-Weiner1, ~Giorgio_Piatti1, ~Sydney_Levine1, ~Jiarui_Liu1, ~Fernando_Gonzalez_Adauto1, ~Francesco_Ortu1, ~András_Strausz1, ~Mrinmaya_Sachan3, ~Rada_Mihalcea1, ~Yejin_Choi1, ~Bernhard_Schölkopf1","LLM alignment, moral evaluation, trolley problems, language model evaluation, AI alignment","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Spotlight,2025,https://openreview.net/pdf?id=VEqPDZIDAh,https://openreview.net/forum?id=VEqPDZIDAh
zNVefjN3EP,OpenCarbonEval: How much $CO_2$  will your large model exhale in training process?,"Data, model and hardware are crucial components in the development of large scale machine learning models. The training of such models necessitates substantial computational resources, energy consumption, and raw materials, resulting in significant environmental implications. However, the environmental impact of these models has been largely overlooked due to a lack of assessment and analysis of their carbon footprint. In this paper, we present OpenCarbonEval, a carbon emission estimation framework to quantify the environmental implications of large scale machine learning models given their total training computations and hardware configurations.
In OpenCarbonEval, we conducted a comprehensive dynamic analysis of the interrelationships among data, models, and hardware throughout the model training process, aiming to forecast the carbon emission of large scale models more accurately. We validated our approach on real-world dataset, and experimental results demonstrate that OpenCarbonEval can predict energy costs and carbon emissions more accurately than previous methods. Furthermore, it can be seamlessly applied to various machine learning tasks without a precision decline. By quantifying the environmental impact of large-scale models, OpenCarbonEval promotes sustainable AI development and deployment, contributing to a more environmentally responsible future for the AI community.","Zhaojian Yu, Yinghao Wu, Zhuotao Deng, Xinchun Yu, Yansong Tang, Xiao-Ping Zhang","~Zhaojian_Yu1, ~Yinghao_Wu4, ~Zhuotao_Deng1, ~Xinchun_Yu1, ~Yansong_Tang1, ~Xiao-Ping_Zhang1","Large-scale model, Carbon footprint, Sustainable AI","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=zNVefjN3EP,https://openreview.net/forum?id=zNVefjN3EP
IBOeJJUYaC,A Neural Material Point Method for Particle-based Simulations,"Mesh-free Lagrangian methods are widely used for simulating fluids, solids, and their complex interactions due to their ability to handle large deformations and topological changes.
    These physics simulators, however, require substantial computational resources for accurate simulations.
    To address these issues, deep learning emulators promise faster and scalable simulations, yet they often remain expensive and difficult to train, limiting their practical use.
    Inspired by the Material Point Method (MPM), we present NeuralMPM, a neural emulation framework for particle-based simulations.
    NeuralMPM interpolates Lagrangian particles onto a fixed-size grid, computes updates on grid nodes using image-to-image neural networks, and interpolates back to the particles.
    Similarly to MPM, NeuralMPM benefits from the regular voxelized representation to simplify the computation of the state dynamics, while avoiding the drawbacks of mesh-based Eulerian methods.
    We demonstrate the advantages of NeuralMPM on 6 datasets, including fluid dynamics and fluid-solid interactions simulated with MPM and Smoothed Particles Hydrodynamics (SPH).
    Compared to GNS and DMCF, NeuralMPM reduces training time from 10 days to 15 hours, memory consumption by 10x-100x, and increases inference speed by 5x-10x, while achieving comparable or superior long-term accuracy, making it a promising approach for practical forward and inverse problems. A project page is available at [URL].","Omer Rochman-Sharabi, Sacha Lewin, Gilles Louppe","~Omer_Rochman-Sharabi1, ~Sacha_Lewin1, ~Gilles_Louppe1","Neural emulation, simulation, SciML, particle-based simulators","applications to physical sciences (physics, chemistry, biology, etc.)",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=IBOeJJUYaC,https://openreview.net/forum?id=IBOeJJUYaC
sTllbUNLz0,Incorporating Human Preferences into Interpretable Reinforcement Learning with Tree Policies,"Interpretable reinforcement learning (RL) seeks to create agents that are efficient, transparent, and understandable to the populations that they impact. A significant gap in current approaches is the underutilization of human feedback, which is typically employed only for post-hoc evaluation. We propose to center the needs of end users by incorporating the feedback that would be obtained in a user study directly into the training of interpretable RL algorithms.  Our approach involves preference learning, where we learn preferences over high-level features that are not directly optimizable during the RL training process. We introduce an evolutionary algorithm that leverages user feedback to guide training toward interpretable decision-tree policies that are better-aligned with human preferences. We demonstrate the effectiveness of our method through experiments using synthetic preference data. Our results show an improvement in preference alignment compared to baselines, yielding policies that are more aligned with underlying user preferences but does so with sample efficiency in the number of user queries, thereby decreasing the burden on the user in providing such data.","Stephanie Milani, Zhicheng Zhang, Nicholay Topin, Lirong Xia, Fei Fang","~Stephanie_Milani1, ~Zhicheng_Zhang2, ~Nicholay_Topin2, ~Lirong_Xia2, ~Fei_Fang1","interpretable reinforcement learning, explainable reinforcement learning, preference learning, alignment",interpretability and explainable AI,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=sTllbUNLz0,https://openreview.net/forum?id=sTllbUNLz0
BVsFp5rQxd,VoiceNoNG: High-Quality Speech Editing Model without Hallucinations,"Currently, most advanced speech editing models are based on either neural codec
language models (NCLM) (e.g., VoiceCraft) or diffusion models (e.g., Voicebox).
Although NCLM can generate higher quality speech compared to diffusion models,
it suffers from a higher word error rate (WER) (Peng et al., 2024), calculated by
comparing the transcribed text to the input text. We identify that this higher WER
is due to attention errors (hallucinations), which make it difficult for NCLM to
accurately follow the target transcription. To maintain speech quality and address
the hallucination issue, we introduce VoiceNoNG, which combines the strengths of
both model frameworks. VoiceNoNG utilizes a latent flow-matching framework to
model the pre-quantization features of a neural codec. The vector quantizer in the
neural codec implicitly converts the regression problem into a token classification
task similar to NCLM. We empirically verified that this transformation is crucial
for enhancing the performance and robustness of the speech generative model. This
simple modification enables VoiceNoNG to achieve state-of-the-art performance
in both objective and subjective evaluations. Lastly, to mitigate the potential
risks posed by the speech editing model, we examine the performance of the
Deepfake detector in a new and challenging practical scenario. Audio examples
can be found on the demo page: https://anonymous.4open.science/w/NoNG-8004/","Sung-Feng Huang, Heng-Cheng Kuo, Zhehuai Chen, Xuesong Yang, Pin-Jui Ku, Ante Jukić, Chao-Han Huck Yang, Yu Tsao, Yu-Chiang Frank Wang, Hung-yi Lee, Szu-Wei Fu","~Sung-Feng_Huang1, ~Heng-Cheng_Kuo1, ~Zhehuai_Chen1, ~Xuesong_Yang1, ~Pin-Jui_Ku1, ~Ante_Jukić1, ~Chao-Han_Huck_Yang1, ~Yu_Tsao1, ~Yu-Chiang_Frank_Wang2, ~Hung-yi_Lee2, ~Szu-Wei_Fu1","speech generative model, speech editing, neural codec, vector quantizer, deepfake detection","applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=BVsFp5rQxd,https://openreview.net/forum?id=BVsFp5rQxd
rEnPEIwXrB,One-Hot Multi-Level LIF Spiking Neural Networks for Enhanced Accuracy-Latency Tradeoff,"Spiking neural networks (SNNs) hold significant promise as energy-efficient alternatives to conventional artificial neural networks (ANNs). However, SNNs require computations across multiple timesteps, resulting in increased latency, heightened energy consumption, and additional memory access overhead. Techniques to reduce SNN latency down to a unit timestep have emerged to realize true superior energy efficiency over ANNs. Nonetheless, this latency reduction often comes at the expense of noticeable accuracy degradation. Therefore, achieving an optimal balance in the tradeoff between accuracy and energy consumption by adjusting the latency of multiple timesteps remains a significant challenge. In this paper, we introduce a new dimension to the accuracy-energy tradeoff space using a novel one-hot multi-level leaky integrate-and-fire (M-LIF) neuron model. The proposed M-LIF model represents the inputs and outputs of hidden layers as a set of one-hot binary-weighted spike lanes to find better tradeoff points while still being able to model conventional SNNs. For image classification on static datasets, we demonstrate M-LIF SNNs outperform iso-architecture conventional LIF SNNs in terms of accuracy ($2$% higher than VGG16 SNN on ImageNet) while still being energy-efficient ($20\times$ lower energy than VGG16 ANN on ImageNet). For dynamic vision datasets, we demonstrate the ability of M-LIF SNNs to reduce latency by $3\times$ compared to conventional LIF SNNs while limiting accuracy degradation ($<1$%).","Pierre Abillama, Changwoo Lee, Andrea Bejarano-Carbo, Qirui Zhang, Dennis Sylvester, David Blaauw, Hun-Seok Kim","~Pierre_Abillama1, ~Changwoo_Lee2, ~Andrea_Bejarano-Carbo1, ~Qirui_Zhang1, ~Dennis_Sylvester2, ~David_Blaauw1, ~Hun-Seok_Kim1","spiking neural networks, leaky integrate-and-fire, energy-efficient, low latency","other topics in machine learning (i.e., none of the above)",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=rEnPEIwXrB,https://openreview.net/forum?id=rEnPEIwXrB
PqeMnyGU1B,Understanding Learning with Sliced-Wasserstein Requires Re-thinking Informative Slices,"The practical applications of Wasserstein distances (WDs) are constrained by their sample and computational complexities. Sliced-Wasserstein distances (SWDs) provide a workaround by projecting distributions onto one-dimensional subspaces, leveraging the more efficient, closed-form WDs for one-dimensional distributions. However, in high dimensions, most random projections become uninformative due to the concentration of measure phenomenon. Although several SWD variants have been proposed to focus on \textit{informative} slices, they often introduce additional complexity, numerical instability, and compromise desirable theoretical (metric) properties of SWD. Amidst the growing literature that focuses on directly modifying the slicing distribution, which often face challenges, we revisit the classic Sliced-Wasserstein and propose instead to rescale the 1D Wasserstein to make all slices equally informative. Importantly, we show that with an appropriate notion of \textit{slice informativeness}, rescaling for all individual slices simplifies to \textbf{a single global scaling factor} on the SWD. This, in turn, translates to the standard learning rate search for gradient-based learning in common ML workflows. We perform extensive experiments across various machine learning tasks showing that the classic SWD, when properly configured, can often match or surpass the performance of more complex variants. We then answer the following question: Is Sliced-Wasserstein all you need for common learning tasks?","Huy Tran, Ashkan Shahbazi, Yikun Bai, John R. Hershey, Soheil Kolouri","~Huy_Tran3, ~Ashkan_Shahbazi1, ~Yikun_Bai2, ~John_R._Hershey1, ~Soheil_Kolouri1","Optimal Transport, Sliced Wasserstein, Concentration of Measure","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=PqeMnyGU1B,https://openreview.net/forum?id=PqeMnyGU1B
PpYy0dR3Qw,LoCoDL: Communication-Efficient Distributed Learning with Local Training and Compression,"In $D$istributed optimization and $L$earning, and even more in the modern framework of federated learning, communication, which is slow and costly, is critical. We introduce LoCoDL, a communication-efficient algorithm that leverages the two popular and effective techniques of $Lo$cal training, which reduces the communication frequency, and $Co$mpression, in which short bitstreams are sent instead of full-dimensional vectors of floats. LoCoDL works with a large class of unbiased compressors that includes widely-used sparsification and quantization methods. LoCoDL provably benefits from local training and compression and enjoys a doubly-accelerated communication complexity, with respect to the condition number of the functions and the model dimension, in the general heterogeneous regime with strongly convex functions. This is confirmed in practice, with LoCoDL outperforming existing algorithms.","Laurent Condat, Arto Maranjyan, Peter Richtárik","~Laurent_Condat1, ~Arto_Maranjyan1, ~Peter_Richtárik1","distributed optimization, local training, compression, communication-efficient algorithm, federated learning",optimization,ICLR 2025 Spotlight,2025,https://openreview.net/pdf?id=PpYy0dR3Qw,https://openreview.net/forum?id=PpYy0dR3Qw
EJTeOf8iG0,EEEC: Emotion-Experiencer-Event-Cause multi-step chain reasoning for Emotion-Cause Pair Extraction,"Emotion-cause pair extraction (ECPE) aims to identify all emotion and cause clauses in documents, forming the ECPs. Although existing methods have achieved some success, they face issues such as overlooking the impact of emotion experiencers, failing to leverage specific domain knowledge, and tending to spurious correlations. To address these issues, we transform the ECPE task into a multi-step reasoning problem and propose the Emotion-Experience-Event-Cause (EEEC) framework. We introduce an experiencer identification task to understand the source of emotions and enhance the association between emotion and cause clauses. In addition, by combining both prior knowledge and induced reasoning, EEEC guides a large-scale language model (LLM) to perform the emotion-reason pair extraction task efficiently. Experimental results demonstrate that EEEC achieves performance close to current state-of-the-art supervised fine-tuning methods. The data and code are released at https://anonymous.4open.science/r/EEEC-EB80/.","Xue Gu, Ziyao Meng, Tiago Gomes, Adriano Jose Tavares, Hao Xu","~Xue_Gu1, ~Ziyao_Meng1, ~Tiago_Gomes1, ~Adriano_Jose_Tavares1, ~Hao_Xu8",Experiencer; Event; Multi-step chain reasoning; Emotion-Cause Pair Extraction,"applications to computer vision, audio, language, and other modalities",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=EJTeOf8iG0,https://openreview.net/forum?id=EJTeOf8iG0
cMLtjP3Cym,TSGGuide: Recommendation Guide for Multivariate Time Series Generation,"Multivariate Time Series Generation (MTSG) plays a crucial role in time series analysis, supporting tasks such as data augmentation and anomaly detection. While several methods exist for MTSG, recommending the most suitable method for new scenarios remains a significant challenge. Although prior work by  (Ang et al., 2023a) provides guidance for selecting MTSG methods, it lacks coverage of recent diffusion-based methods and has limited exploration of channel-independent frameworks. We address these gaps by improving the recommendation guide, highlighting the effectiveness of a central discriminator within the channel-independent framework. Our revised guide makes three key recommendations: 1) VAE-based methods excel on small-scale datasets; 2) a channel-independent framework with the newly designed central discriminator is optimal in most cases; and 3) a diffusion-based method is preferable when ample data and computational resources are available.","Beining Zhang, Kai Wu, Xiaoyu Zhang, Handing Wang, Jing Liu, Bei Wang","~Beining_Zhang1, ~Kai_Wu3, ~Xiaoyu_Zhang6, ~Handing_Wang1, ~Jing_Liu20, ~Bei_Wang6","time series generation, diffusion model, Channel Independence",learning on time series and dynamical systems,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=cMLtjP3Cym,https://openreview.net/forum?id=cMLtjP3Cym
dxMffCAd4w,CLF: Curve Line Fitting Neural Network Based On Bezier Curve,"The Multilayer Perceptron (MLP) serves as a fundamental architecture in deep learning, leveraging the universal function approximation theorem through linear regression combined with activation functions. Despite its widespread use, the inclusion of activation functions contributes to the inherent nature of MLPs as ``black boxes,"" limiting their interpretability. In this paper, we propose a novel Curve Line Fitting (CLF) network, which introduces Bezier curve fitting to directly address nonlinear distributions. By replacing traditional linear regression with Bezier curve regression, the CLF network offers a more efficient means of fitting target distributions. Additionally, the removal of activation functions makes the CLF model fully interpretable, enabling clear insights into the relationships between input dimensions and target distributions, as well as the interdependencies across different dimensions. (Sample code for the CLF model will be made available on GitHub.)","Jianyi Yang, Guiling Wang","~Jianyi_Yang2, ~Guiling_Wang2","CLF, MLP, Interpretable Neural Networks",interpretability and explainable AI,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=dxMffCAd4w,https://openreview.net/forum?id=dxMffCAd4w
abRWxnjMIz,Reducing the Scope of Language Models with Circuit Breakers,"Language models are now deployed in a wide variety of user-facing applications, often for specific purposes like answering questions about documentation or acting as coding assistants. As these models are intended for particular purposes, they should not be able to answer irrelevant queries like requests for poetry or questions about physics, or even worse, queries that can only be answered by humans like sensitive company policies. Instead we would like them to only answer queries corresponding to desired behavior and refuse all other requests, which we refer to as scoping. We find that, despite the use of system prompts, two representative language models can be poorly scoped and respond to queries they should not be addressing. We then conduct a comprehensive empirical evaluation of methods which could be used for scoping the behavior of language models. Among many other results, we show that a recently-proposed method for general alignment, Circuit Breakers (CB), can be adapted to scope language models to very specific tasks like sentiment analysis or summarization or even tasks with finer-grained scoping (e.g. summarizing only news articles). When compared to standard methods like fine-tuning or preference learning, CB is more robust both for out of distribution tasks, and to adversarial prompting techniques. We also show that layering SFT and CB together often results in the best of both worlds: improved performance only on relevant queries, while rejecting irrelevant ones.","David Yunis, Siyu Huo, Chulaka Gunasekara, Danish Contractor","~David_Yunis1, ~Siyu_Huo3, ~Chulaka_Gunasekara2, ~Danish_Contractor2","large language models, alignment, refusal","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=abRWxnjMIz,https://openreview.net/forum?id=abRWxnjMIz
flgrH5nK4H,Representing Signs as Signs: One-Shot ISLR to Facilitate Functional Sign Language Technologies,"Isolated Sign Language Recognition (ISLR) is crucial for scalable sign language technology, yet language-specific approaches limit current models. To address this, we propose a one-shot learning approach that generalises across languages and evolving vocabularies. Our method involves pretraining a model to embed signs based on essential features and using a dense vector search for rapid, accurate recognition of unseen signs. We achieve state-of-the-art results, including 50.8% one-shot MRR on a large dictionary containing 10,235 unique signs from a different language than the training set. Our approach is robust across languages and support sets, offering a scalable, adaptable solution for ISLR. Co-created with the Deaf and Hard of Hearing (DHH) community, this method aligns with real-world needs, and advances scalable sign language recognition.","Toon Vandendriessche, Mathieu De Coster, Annelies Lejon, Joni Dambre","~Toon_Vandendriessche1, ~Mathieu_De_Coster1, ~Annelies_Lejon1, ~Joni_Dambre2","Sign Language, Deep Learning, Computer Vision","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=flgrH5nK4H,https://openreview.net/forum?id=flgrH5nK4H
tC1b9DBWww,Person Detection Through the Lens of Algorithmic Bias,"The rise of AI based person detection in safety critical applications such as driver-less cars or security monitoring has lead to an explosion of machine learning models and dataset research. At the same time, researchers have raised question of bias in these models and datasets. Popular benchmark datasets like More Inclusive Images for People (MIAP) and Berkeley DeepDrive (BDD) for person detection suffer from both sampling and labeling biases. This has serious implications for autonomous vehicles and other fields that use these datasets. We conduct an all-encompassing analysis to assess these datasets through the lens of algorithmic bias, looking at both dataset and model bias. To the best of our knowledge, no study has delved into the realm of person detection in low-quality or crowded pictures with this lens. The result is a novel analysis of bias in a real-world image dataset. We find that 1) image manipulations frequently found in real-world settings like image blurriness and 2) image detectors that are skewed to rely on features like contrast or brightness both have significant negative impacts on fairness for race, gender, and age demographics. These result can help guide future designs of robust models in the object detection field and beyond.","Kiana Alikhademi, Emma Drobina, Jean D Louis","~Kiana_Alikhademi1, ~Emma_Drobina1, ~Jean_D_Louis1","object detection, autonomous vehicles, algorithmic bias, algorithmic fairness, fairness in ML","alignment, fairness, safety, privacy, and societal considerations",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=tC1b9DBWww,https://openreview.net/forum?id=tC1b9DBWww
44hcrfzydU,FedTMOS: Efficient One-Shot Federated Learning with Tsetlin Machine,"One-Shot Federated Learning (OFL) is a promising approach that reduce communication to a single round, minimizing latency and resource consumption. However, existing OFL methods often rely on Knowledge Distillation, which introduce server-side training, increasing latency. While neuron matching and model fusion techniques bypass server-side training, they struggle with alignment when heterogeneous data is present. To address these challenges, we proposed One-Shot Federated Learning with Tsetlin Machine (FedTMOS), a novel data-free OFL framework built upon the low-complexity and class-adaptive properties of the Tsetlin Machine. FedTMOS first clusters then reassigns class-specific weights to form models using an inter-class maximization approach, efficiently generating balanced server models without requiring additional training. Our extensive experiments demonstrate that FedTMOS significantly outperforms its ensemble counterpart by an average of $6.16$%, and the leading state-of-the-art OFL baselines by $7.22$% across various OFL settings. Moreover, FedTMOS achieves at least a $2.3\times$ reduction in upload communication costs and a $75\times$ reduction in server latency compared to methods requiring server-side training. These results establish FedTMOS as a highly efficient and practical solution for OFL scenarios.","Shannon How Shi Qi, Jagmohan Chauhan, Geoff V. Merrett, Jonathon Hare","~Shannon_How_Shi_Qi1, ~Jagmohan_Chauhan1, ~Geoff_V._Merrett1, ~Jonathon_Hare1","Efficient Federated Learning, One Shot Federated Learning, Tsetlin Machine","other topics in machine learning (i.e., none of the above)",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=44hcrfzydU,https://openreview.net/forum?id=44hcrfzydU
gTwD366p5I,VisualCoder: Guiding Vision Language Models in Code Execution with Fine-grained Chain-of-Thought Reasoning,"Predicting program behavior and reasoning about code execution remain significant challenges in software engineering, particularly for large language models (LLMs) designed for code analysis. While these models excel at understanding static syntax, they often struggle with dynamic reasoning tasks. We introduce VisualCoder, a novel approach that enhances code reasoning by integrating multimodal Chain-of-Thought (CoT) reasoning with visual Control Flow Graphs (CFGs). By aligning code snippets with their corresponding CFGs, VisualCoder provides deeper insights into execution flow, enabling more accurate predictions of code behavior. Our experiments demonstrate that augmenting LLMs with visual CFGs significantly outperforms text-based CFG descriptions in code reasoning tasks. We address challenges in multimodal CoT integration through a reference mechanism, ensuring consistency between code and its execution path, thereby improving performance in program behavior prediction, error detection, and output generation.","Cuong Le Chi, Chau Truong Vinh Hoang, Phan Nhật Huy, Dung D. Le, Tien N Nguyen, Nghi D. Q. Bui","~Cuong_Le_Chi1, ~Chau_Truong_Vinh_Hoang1, ~Phan_Nhật_Huy1, ~Dung_D._Le2, ~Tien_N_Nguyen1, ~Nghi_D._Q._Bui1","Multimodal Large Language Models, Control Flow Graphs, Visualized Code Representation, Code Execution Reasoning, Fault Localization, Program Repair","foundation or frontier models, including LLMs",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=gTwD366p5I,https://openreview.net/forum?id=gTwD366p5I
5fRlsiNDZR,FARV: Leveraging Facial and Acoustic Representation in Vocoder For Video-to-Speech Synthesis,"In this paper, we introduce FARV, a vocoder specifically designed for Video-to-Speech (V2S) synthesis, which integrates both facial embeddings and acoustic units to generate speech waveforms. By sharing the acoustic unit vocabulary in our two-stage V2S pipeline, FARV effectively bridges the domain gap between the visual frontend and the vocoder without requiring finetuning. Furthermore, by embedding visual speaker images into the acoustic unit representations, FARV enhances its ability to preserve speaker identity. Experimental results demonstrate that FARV achieves leading scores in intelligibility and strikes a favorable balance between speaker characterisitcs preservation and acoustic quality, making it well-suited for practical V2S applications.","Yifan Liu, Yu Fang, Zhouhan Lin","~Yifan_Liu24, ~Yu_Fang4, ~Zhouhan_Lin1","Video-to-speech (V2S), vocoder, speech synthesis","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=5fRlsiNDZR,https://openreview.net/forum?id=5fRlsiNDZR
ZjuEPZJsa3,Decoding Reading Goals from Eye Movements,"Readers can have different goals with respect to the text they are reading. Can these goals be decoded from the pattern of their eye movements over the text? In this work, we examine for the first time whether it is possible to decode two types of reading goals that are common in daily life: information seeking and ordinary reading. Using large scale eye-tracking data, we apply to this task a wide range of state-of-the-art models for eye movements and text that cover different architectural and data representation strategies, and further introduce a new model ensemble. We systematically evaluate these models at three levels of generalization: new textual item, new participant, and the combination of both. We find that eye movements contain highly valuable signals for this task. We further perform an error analysis which builds on prior empirical findings on differences between ordinary reading and information seeking and leverages rich textual annotations. This analysis reveals key properties of textual items and participant eye movements that contribute to the difficulty of the task.","Omer Shubi, Cfir Avraham Hadar, Yevgeni Berzak","~Omer_Shubi1, ~Cfir_Avraham_Hadar1, ~Yevgeni_Berzak1","application of language models to cognitive science and psycholinguistic, eye movements in reading, reading goals, cognitive state decoding, multimodal models (eye movements and text)",applications to neuroscience & cognitive science,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=ZjuEPZJsa3,https://openreview.net/forum?id=ZjuEPZJsa3
UhKkWHkvfg,Analytic Continual Test-Time Adaptation for Multi-Modality Corruption,"Test-Time Adaptation (TTA) aims to help pre-trained model bridge the gap between source and target datasets using only the pre-trained model and unlabelled test data. A key objective of TTA is to address domain shifts in test data caused by corruption, such as weather changes, noise, or sensor malfunctions. Multi-Modal Continual Test-Time Adaptation (MM-CTTA), an extension of TTA with better real-world applications, further allows pre-trained models to handle multi-modal inputs and adapt to continuously-changing target domains. MM-CTTA typically faces challenges including $\textbf{error accumulation}$, $\textbf{catastrophic forgetting}$, and $\textbf{reliability bias}$, with few existing approaches effectively addressing these issues in multi-modal corruption scenarios. In this paper, we propose a novel approach, Multi-modality Dynamic Analytic Adapter (MDAA), for MM-CTTA tasks. We innovatively introduce analytic learning into TTA, using the Analytic Classifiers (ACs) to prevent model forgetting. Additionally, we develop Dynamic Selection Mechanism (DSM) and Soft Pseudo-label Strategy (SPS), which enable MDAA to dynamically filter reliable samples and integrate information from different modalities. Extensive experiments demonstrate that MDAA achieves state-of-the-art performance on MM-CTTA tasks while ensuring reliable model adaptation.","Yufei Zhang, Yicheng Xu, Hongxin Wei, Zhiping Lin, Huiping Zhuang","~Yufei_Zhang7, ~Yicheng_Xu1, ~Hongxin_Wei1, ~Zhiping_Lin1, ~Huiping_Zhuang2",test time adaptation; multi-modality; continual learning; analytic learning,"applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=UhKkWHkvfg,https://openreview.net/forum?id=UhKkWHkvfg
wdzCyr1stL,Conformal Prediction with Model-Aware Debiasing,"Bias in model estimation can lead to wider prediction intervals, diminishing the utility of predictive inference. Existing methods have attempted to address this issue, but they often rely on nontrivial assumptions such as specific error distributions or model sparsity, and fail to guarantee coverage in finite samples, which makes their predictions unreliable in practice. To overcome these limitations, we propose a model-aware conformal prediction method that utilizes known model information to achieve debiasing while leaving the unknown aspects, such as data distribution, to the conformal prediction framework. This approach requires only the assumption of exchangeability, making it broadly applicable across various models. Importantly, it retains the finite-sample coverage property and produces shorter prediction intervals compared to existing methods. When applied to threshold ridge regression, we theoretically demonstrate that the model-aware conformal prediction maintains finite-sample marginal coverage and, under certain assumptions, converges to the oracle prediction band, achieving asymptotic conditional validity. Numerical experiments further show that our method outperforms existing methods, providing more efficient prediction intervals across diverse regression datasets.","Jiamei Wu, Bei Jiang, Linglong Kong, Lingchen Kong, Yanlin Tang","~Jiamei_Wu1, ~Bei_Jiang1, ~Linglong_Kong2, ~Lingchen_Kong1, ~Yanlin_Tang3","conformal prediction, model-aware debiasing, statistical inference, prediction interval","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=wdzCyr1stL,https://openreview.net/forum?id=wdzCyr1stL
hVwS9KkY6V,Generative Visual Instruction Tuning,"We propose to use automatically generated instruction-following data to improve the zero-shot capabilities of a large multimodal model with additional support for generative and image editing tasks. We achieve this by curating a new multimodal instruction-following set using GPT-4V and existing datasets for image generation and editing. Using this instruction set and the existing LLaVA-Finetune instruction set for visual understanding tasks, we produce GenLLaVA, a Generative Large Language and Visual Assistant. GenLLaVA is built through a strategy that combines three types of large pretrained models through instruction finetuning: Mistral for language modeling, SigLIP for image-text matching, and StableDiffusion for text-to-image generation. Our model demonstrates visual understanding capabilities superior to LLaVA and additionally demonstrates competitive results with native multimodal models such as Unified-IO 2, paving the way for building advanced general-purpose visual assistants by effectively re-using existing multimodal models.","Jefferson Hernandez, Ruben Villegas, Vicente Ordonez","~Jefferson_Hernandez1, ~Ruben_Villegas1, ~Vicente_Ordonez2","generative models, multimodal large language models, instruction tuning, Vision Language, Representation Learning","applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=hVwS9KkY6V,https://openreview.net/forum?id=hVwS9KkY6V
PD8JVDg8mB,Annotation Bootstrapping: Reinforcing Visual Pre-Training using Unlabelled Images,"A common approach to learning from unlabeled images is to train models to satisfy invariances on these images, such as consistency under augmentations or crops. Despite successes on Imagenet, these approaches struggle to learn from larger uncurated datasets like web crawls or video, where such inductive biases only weakly hold. How can we more effectively learn from broader datasets? Instead of training models to be invariant across views, we study an alternative approach encouraging model representations to be \textit{predictive} of important semantics of adjacent views of an image. We concurrently train a model to predict semantic annotations from images (generated either self-supervised, or from auxiliary datasets); and bootstrap the model's semantics by predicting, given a cropped view of an image and the coordinates for a nearby crop, the model's annotation distribution for the neighboring view.  A core strength of this approach is the ability to extract information universally from both unlabelled and labelled image data, incorporating captions, bounding boxes, and other annotations when they are present. Our experiments show that annotation propagation improves pre-training on unlabelled datasets in the wild, including video datasets like EpicKitchens, scene datasets like COCO, and uncurated web-scale image datasets like CC12M.","Dibya Ghosh, Sergey Levine","~Dibya_Ghosh1, ~Sergey_Levine1","visual pretraining, self supervised learning, bootstrapping","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=PD8JVDg8mB,https://openreview.net/forum?id=PD8JVDg8mB
byofn4HN8F,2-Rectifications are Enough for Straight Flows: A Theoretical Insight into Wasserstein Convergence,"Diffusion models have emerged as a powerful tool for image generation and denoising. Typically, generative models learn a trajectory between the starting noise distribution and the target data distribution. Recently Liu et al. (2023b) designed a novel alternative generative model Rectified Flow(RF), which aims to learn straight flow trajectories from noise to data using a sequence of convex optimization problems with close ties to optimal transport. If the trajectory is curved, one must use many Euler discretization steps or novel strategies, such as exponential integrators, to achieve a satisfactory generation quality. In contrast, RF has been shown to theoretically straighten the trajectory through successive rectifications, reducing the number of function evaluations (NFEs) while sampling. It has also been shown empirically that RF may improve the straightness in two rectifications if one can solve the underlying optimization problem within a sufficiently small error. In this paper, we make two key theoretical contributions: 1) we provide the first theoretical analysis of the
Wasserstein distance between the sampling distribution of RF and the target distribution. Our error rate is characterized by the number of discretization steps and a new formulation of straightness stronger than that in the original work. 2) under a mild regularity assumption, we show that for a rectified flow from a Gaussian to any general target distribution with finite first moment (e.g. mixture of Gaussians), two rectifications are sufficient to achieve a straight flow, which is in line with the previous empirical findings. Additionally, we also present empirical results on both simulated and real datasets to validate our theoretical findings. The codes are available at https://github.com/bansal-vansh/rectified-flow.","Saptarshi Roy, Vansh Bansal, Purnamrita Sarkar, Alessandro Rinaldo","~Saptarshi_Roy1, ~Vansh_Bansal2, ~Purnamrita_Sarkar1, ~Alessandro_Rinaldo1","generative model, optimal transport, rectified flow, wasserstein distance",generative models,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=byofn4HN8F,https://openreview.net/forum?id=byofn4HN8F
hUdLs6TqZL,Mining your own secrets: Diffusion Classifier Scores for Continual Personalization of Text-to-Image Diffusion Models,"Personalized text-to-image diffusion models have grown popular for their ability to efficiently acquire a new concept from user-defined text descriptions and a few images. However, in the real world, a user may wish to personalize a model on multiple concepts but one at a time, with no access to the data from previous concepts due to storage/privacy concerns. When faced with this continual learning (CL) setup, most personalization methods fail to find a balance between acquiring new concepts and retaining previous ones -- a challenge that *continual personalization* (CP) aims to solve. 
Inspired by the successful CL methods that rely on class-specific information for regularization, we resort to the  inherent class-conditioned density estimates, also known as *diffusion classifier* (DC) scores, for CP of text-to-image diffusion models. 
Namely, we propose using DC scores for regularizing the parameter-space and function-space of text-to-image diffusion models.
Using several diverse evaluation setups, datasets, and  metrics, we show that our proposed regularization-based CP methods outperform the state-of-the-art C-LoRA, and other baselines. Finally, by operating in the replay-free CL setup and on low-rank adapters, our method incurs zero storage and parameter overhead, respectively, over the state-of-the-art.","Saurav Jha, Shiqi Yang, Masato Ishii, Mengjie Zhao, christian simon, Muhammad Jehanzeb Mirza, Dong Gong, Lina Yao, Shusuke Takahashi, Yuki Mitsufuji","~Saurav_Jha1, ~Shiqi_Yang1, ~Masato_Ishii1, ~Mengjie_Zhao1, ~christian_simon1, ~Muhammad_Jehanzeb_Mirza1, ~Dong_Gong1, ~Lina_Yao2, ~Shusuke_Takahashi1, ~Yuki_Mitsufuji1","Text-to-image diffusion model, Continual Learning, Personalization",generative models,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=hUdLs6TqZL,https://openreview.net/forum?id=hUdLs6TqZL
DLhjxxXYwH,Advancing Neural Network Performance through Emergence-Promoting Initialization Scheme,"We introduce a novel yet straightforward neural network initialization scheme that modifies conventional methods like Xavier and Kaiming initialization. Inspired by the concept of emergence and leveraging the emergence measures proposed by Li (2023), our method adjusts the layer-wise weight scaling factors to achieve higher emergence values. This enhancement is easy to implement, requiring no additional optimization steps for initialization compared to GradInit. We evaluate our approach across various architectures, including MLP and convolutional architectures for image recognition, and transformers for machine translation. We demonstrate substantial improvements in both model accuracy and training speed, with and without batch normalization. The simplicity, theoretical innovation, and demonstrable empirical advantages of our method make it a potent enhancement to neural network initialization practices. These results suggest a promising direction for leveraging emergence to improve neural network training methodologies.","Johnny Jingze Li, Vivek Kurien George, Gabriel A. Silva","~Johnny_Jingze_Li1, ~Vivek_Kurien_George1, ~Gabriel_A._Silva1","Emergence, Initialization, cascade effect",learning theory,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=DLhjxxXYwH,https://openreview.net/forum?id=DLhjxxXYwH
KZEqbwJfTl,Distribution-Specific Agnostic Conditional Classification With Halfspaces,"We study ""selective"" or ""conditional"" classification problems under an agnostic setting. Classification tasks commonly focus on modeling the relationship between features and categories that captures the vast majority of data. In contrast to common machine learning frameworks, conditional classification intends to model such relationships only on a subset of the data defined by some selection rule. Most work on conditional classification either solves the problem in a realizable setting or does not guarantee the error is bounded compared to an optimal solution. In this work, we consider selective/conditional classification by sparse linear classifiers for subsets defined by halfspaces, and give both positive as well as negative results for Gaussian feature distributions. On the positive side, we present the first PAC-learning algorithm for homogeneous halfspace selectors with error guarantee $\tilde{O}(\sqrt{\mathrm{opt}})$, where $\mathrm{opt}$ is the smallest conditional classification error over the given class of classifiers and homogeneous halfspaces. On the negative side, we find that, under cryptographic assumptions, approximating the conditional classification loss within a small additive error is computationally hard even under Gaussian distribution. We prove that approximating conditional classification is at least as hard as approximating agnostic classification in both additive and multiplicative form.","Jizhou Huang, Brendan Juba","~Jizhou_Huang2, ~Brendan_Juba1","Agnostic linear classification, PAC-learning, Intractability",learning theory,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=KZEqbwJfTl,https://openreview.net/forum?id=KZEqbwJfTl
BfQNrKJMXq,MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents,"Large Language Model (LLM)-based mobile agents are increasingly popular due to their capability to interact directly with mobile phone Graphic User Interfaces (GUIs) and their potential to autonomously manage daily tasks. Despite their promising prospects in both academic and industrial sectors, little research has focused on benchmarking the performance of existing mobile agents, due to the inexhaustible states of apps and the vague definition of feasible action sequences. To address this challenge, we propose an efficient and user-friendly benchmark, MobileAgentBench, designed to alleviate the burden of extensive manual testing. We initially define 100 tasks across 10 open-source apps, categorized by multiple levels of difficulty. Subsequently, we evaluate several existing mobile agents, including AppAgent and MobileAgent, to thoroughly and systematically compare their performance. All materials will be accessible on our project webpage, contributing to the advancement of both academic and industrial fields.","Luyuan Wang, Yongyu Deng, Yiwei Zha, Guodong Mao, Qinmin Wang, Tianchen Min, Wei Chen, Shoufa Chen","~Luyuan_Wang2, ~Yongyu_Deng1, ~Yiwei_Zha1, ~Guodong_Mao1, ~Qinmin_Wang2, ~Tianchen_Min1, ~Wei_Chen63, ~Shoufa_Chen1","LLM, Agent, Benchmark",datasets and benchmarks,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=BfQNrKJMXq,https://openreview.net/forum?id=BfQNrKJMXq
jNmsuEE4Gf,Feynman: Knowledge-Infused Diagramming Agent for Scaling Visual Reasoning Data,"Visual reasoning is an essential ability of state-of-the-art multi-modal AI systems. Improving these systems requires high-quality vision-language data at scale. Despite the abundance of internet image and text data, knowledge-rich and well-aligned image-text pairs are rare. In this paper, we present a scalable data generation pipeline built with our diagramming agent, **Feynman**. To create diagrams, Feynman first enumerates domain-specific knowledge components (""ideas"") and performs code planning based on the ideas. Given the plan, Feynman translates ideas into simple declarative programs and iterates to receives feedback and visually refine diagrams. Finally, the declarative programs are rendered by the Penrose diagramming system. The optimization-based rendering of Penrose preserves the visual semantics while injecting fresh randomness into the layout, thereby producing diagrams with visual consistency and diversity. As a result, Feynman can author diagrams along with grounded captions with very little cost and time. Using Feynman, we synthesized a dataset with more than 100$k$ well-aligned diagram-caption pairs. We also curate a visual-language benchmark, **Diagramma**, from freshly generated data.","Zixin Wen, Yifu Cai, Kyle Lee, Sam Estep, Joshua Sunshine, Aarti Singh, Yuejie Chi, Wode Ni","~Zixin_Wen1, ~Yifu_Cai1, ~Kyle_Lee2, ~Sam_Estep1, ~Joshua_Sunshine1, ~Aarti_Singh1, ~Yuejie_Chi1, ~Wode_Ni1","Vision-Language Dataset, Synthetic Data, Visual Reasoning Benchmark",datasets and benchmarks,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=jNmsuEE4Gf,https://openreview.net/forum?id=jNmsuEE4Gf
iTm4H6N4aG,ClassDiffusion: More Aligned Personalization Tuning with Explicit Class Guidance,"Recent text-to-image customization works have proven successful in generating images of given concepts by fine-tuning diffusion models on a few examples. However, tuning-based methods inherently tend to overfit the concepts, resulting in failure to create the concept under multiple conditions (*e.g.*, headphone is missing when generating ""a <sks>`dog wearing a headphone""). Interestingly, we notice that the base model before fine-tuning exhibits the capability to compose the base concept with other elements (*e.g.*, ""a dog wearing a headphone""), implying that the compositional ability only disappears after personalization tuning. We observe a semantic shift in the customized concept after fine-tuning, indicating that the personalized concept is not aligned with the original concept, and further show through theoretical analyses that this semantic shift leads to increased difficulty in sampling the joint conditional probability distribution, resulting in the loss of the compositional ability. Inspired by this finding, we present **ClassDiffusion**, a technique that leverages a **semantic preservation loss** to explicitly regulate the concept space when learning a new concept. Although simple, this approach effectively prevents semantic drift during the fine-tuning process of the target concepts. Extensive qualitative and quantitative experiments demonstrate that the use of semantic preservation loss effectively improves the compositional abilities of fine-tuning models. Lastly, we also extend our ClassDiffusion to personalized video generation, demonstrating its flexibility.","Jiannan Huang, Jun Hao Liew, Hanshu Yan, Yuyang Yin, Yao Zhao, Humphrey Shi, Yunchao Wei","~Jiannan_Huang2, ~Jun_Hao_Liew1, ~Hanshu_Yan1, ~Yuyang_Yin1, ~Yao_Zhao1, ~Humphrey_Shi1, ~Yunchao_Wei1","Diffusion, Subject-Driven Personalization",generative models,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=iTm4H6N4aG,https://openreview.net/forum?id=iTm4H6N4aG
k03mB41vyM,Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning,"Identifying latent representations or causal structures is important for good generalization and downstream task performance. However, both fields developed rather independently.
We observe that several structure and representation identifiability methods, particularly those that require multiple environments, rely on 
exchangeable non--i.i.d. (independent and identically distributed) data.
To formalize this connection, 
we propose the Identifiable Exchangeable Mechanisms (IEM) framework to unify key representation and causal structure learning methods. IEM provides a unified probabilistic graphical model encompassing causal discovery, Independent Component Analysis, and Causal Representation Learning.
With the help of the IEM model, we generalize the Causal de Finetti theorem of Guo et al., 2022 by relaxing the necessary conditions for causal structure identification in exchangeable data.
We term these conditions cause and mechanism variability, and show how they imply a duality condition in identifiable representation learning, leading to new identifiability results.","Patrik Reizinger, Siyuan Guo, Ferenc Huszár, Bernhard Schölkopf, Wieland Brendel","~Patrik_Reizinger1, ~Siyuan_Guo1, ~Ferenc_Huszár1, ~Bernhard_Schölkopf1, ~Wieland_Brendel1","causality, ICA, identifiability, causal representation learning",causal reasoning,ICLR 2025 Spotlight,2025,https://openreview.net/pdf?id=k03mB41vyM,https://openreview.net/forum?id=k03mB41vyM
oOSeOEXrFA,REPOFILTER: Adaptive Retrieval Context Trimming for Repository-Level Code Completion,"Retrieval-Augmented Generation (RAG) has recently emerged as a promising approach for repository-level code completion by integrating cross-file knowledge with in-file preceding code to provide comprehensive contexts for generation. To better understand the contribution of the retrieved cross-file contexts, we introduce a likelihood-based metric to evaluate the impact of each retrieved code chunk on the completion. Our analysis reveals that, despite retrieving numerous chunks, only a small subset positively contributes to the target completion, while some chunks even degrade performance. To address this issue, we leverage this metric to construct a repository-level dataset where each retrieved chunk is labeled as positive, neutral, or negative based on its relevance to the target completion. We then propose an adaptive retrieval context trimming framework, REPOFILTER, trained on this dataset to mitigate the harmful effects of negative retrieved contexts in RAG-based code completion. Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks demonstrates that REPOFILTER consistently improves completion accuracy compared to approaches without filtering operations across various tasks. Additionally, REPOFILTER significantly reduces the length of the input prompt, enhancing computational efficiency while exhibiting strong generalizability across different models. These results underscore the potential of REPOFILTER to enhance the accuracy, efficiency, and attributability of RAG-based repository-level code completion.","Yanzhou Li, Shangqing Liu, Kangjie Chen, Tianwei Zhang, Yang Liu","~Yanzhou_Li1, ~Shangqing_Liu1, ~Kangjie_Chen1, ~Tianwei_Zhang1, ~Yang_Liu36","Code completion, RAG, LLMs","applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=oOSeOEXrFA,https://openreview.net/forum?id=oOSeOEXrFA
xE5ZaZGqBW,Hypercone Assisted Contour Generation for Out-of-Distribution Detection,"Recent advances in the field of out-of-distribution (OOD) detection have placed great emphasis on learning better representations suited to this task. While there have been distance-based approaches, distributional awareness has seldom been exploited for better performance. We present HACk-OOD, a novel OOD detection method that makes no distributional assumption about the data, but automatically adapts to its distribution. Specifically, HACk-OOD constructs a set of hypercones by maximizing the angular distance to neighbors in a given data-point's vicinity, to approximate the contour within which in-distribution (ID) data-points lie. Experimental results show state-of-the-art FPR@95 and AUROC performance on Near-OOD detection and on Far-OOD detection on the challenging CIFAR-100 benchmark without explicitly training for OOD performance.","Annita Vapsi, Andrés Muñoz Garza, Nancy Thomas, Keshav Ramani, Daniel Borrajo","~Annita_Vapsi1, ~Andrés_Muñoz_Garza1, ~Nancy_Thomas1, ~Keshav_Ramani1, ~Daniel_Borrajo1","OOD detection, Out-of-distribution detection, Computer Vision, Deep Learning, Representation Learning","other topics in machine learning (i.e., none of the above)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=xE5ZaZGqBW,https://openreview.net/forum?id=xE5ZaZGqBW
AuAj4vRPkv,Transformers Provably Learn Two-Mixture of Linear Classification via Gradient Flow,"Understanding how transformers learn and utilize hidden connections between tokens is crucial to understand the behavior of large language models.
To understand this mechanism, we consider the task of two-mixture of linear classification which possesses a hidden correspondence structure among tokens, and study the training dynamics of a symmetric two-headed transformer with ReLU neurons.
Motivated by the stage-wise learning phenomenon in our experiments, we design and theoretically analyze a three-stage training algorithm, which can effectively characterize the actual gradient descent dynamics when we simultaneously train the neuron weights and the softmax attention.
The first stage is a neuron learning stage, where the neurons align with the underlying signals. 
The second stage is a attention feature learning stage, where we analyze the feature learning process of how the attention learns to utilize the relationship between the tokens to solve certain hard samples.
In the meantime, the attention features evolve from a nearly non-separable state (at the initialization) to a well-separated state.
The third stage is a convergence stage, where the population loss is driven towards zero.
The key technique in our analysis of softmax attention is to identify a critical sub-system inside a large dynamical system and bound the growth of the non-linear sub-system by a linear system. 
Finally, we discuss the setting with more than two mixtures. 
We empirically show the difficulty of generalizing our analysis of the gradient flow dynamics to the case even when the number of mixtures equals three, although the transformer can still successfully learn such distribution. 
On the other hand, we show by construction that there exists a transformer that can solve mixture of linear classification given any arbitrary number of mixtures.","Hongru Yang, Zhangyang Wang, Jason D. Lee, Yingbin Liang","~Hongru_Yang1, ~Zhangyang_Wang1, ~Jason_D._Lee1, ~Yingbin_Liang1","transformer, training dynamics, gradient flow, mixture of linear classification",learning theory,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=AuAj4vRPkv,https://openreview.net/forum?id=AuAj4vRPkv
jDpdQPMosW,"Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency","We investigate the statistical and computational limits of prompt tuning for transformer-based foundation models.  Our key contributions are that prompt tuning on *single-head* transformers with only a *single* self-attention layer:  (i) is universal, and  (ii) supports efficient (even almost-linear time) algorithms under the Strong Exponential Time Hypothesis (SETH).  Statistically,  we prove that prompt tuning on such the simplest possible transformers are universal approximators for sequence-to-sequence Lipschitz functions.  In addition, we provide an exponential-in-$dL$ and -in-$(1/\epsilon)$ lower bound on the required soft-prompt tokens for prompt tuning to memorize any dataset with 1-layer, 1-head transformers.  Computationally, we identify a phase transition in the efficiency of prompt tuning, determined by the norm of the *soft-prompt-induced* keys and queries, and provide an upper bound criterion.  Beyond this criterion, no sub-quadratic (efficient) algorithm for prompt tuning exists under SETH.  Within this criterion,  we showcase our theory by proving the existence of almost-linear time prompt tuning inference algorithms.  These fundamental limits provide important necessary conditions for designing expressive and efficient prompt tuning methods for practitioners.","Jerry Yao-Chieh Hu, Wei-Po Wang, Ammar Gilani, Chenyang Li, Zhao Song, Han Liu","~Jerry_Yao-Chieh_Hu1, ~Wei-Po_Wang1, ~Ammar_Gilani1, ~Chenyang_Li6, ~Zhao_Song3, ~Han_Liu4","Foundation Model, Prompt Tuning, Transformer, Universal Approximation, Memory Capacity, Computational Efficiency, Fine-Grained Complexity","foundation or frontier models, including LLMs",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=jDpdQPMosW,https://openreview.net/forum?id=jDpdQPMosW
o9ewXD1JuB,OLAPH: Improving Factuality in Biomedical Long-form Question Answering,"In the medical domain, numerous scenarios necessitate the long-form generation ability of large language models (LLMs). Specifically, when addressing patients' questions, it is essential that the model's response conveys factual claims, highlighting the need for an automated method to evaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset reconstructed using long-form question-answering datasets related to the biomedical domain. We use MedLFQA to facilitate a cost-effective automatic evaluations of factuality. We also propose OLAPH, a simple and novel framework that utilizes cost-effective and multifaceted automatic evaluation to construct a synthetic preference set and answers questions in our preferred manner. Our framework leads us to train LLMs step-by-step to reduce hallucinations and include crucial medical claims. We highlight that, even on evaluation metrics not used during training, LLMs trained with our OLAPH framework demonstrate significant performance improvement in factuality. Our findings reveal that a 7B LLM trained with our OLAPH framework can provide long answers comparable to the medical experts' answers in terms of factuality. We believe that our work could shed light on gauging the long-text generation ability of LLMs in the medical domain. Our code and datasets are available.","Minbyul Jeong, Hyeon Hwang, Chanwoong Yoon, Taewhoo Lee, Jaewoo Kang","~Minbyul_Jeong1, ~Hyeon_Hwang1, ~Chanwoong_Yoon1, ~Taewhoo_Lee1, ~Jaewoo_Kang1","medical question answering, automatic evaluation, factuality, hallucination","applications to physical sciences (physics, chemistry, biology, etc.)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=o9ewXD1JuB,https://openreview.net/forum?id=o9ewXD1JuB
0sJ8TqOLGS,LLM Spark: Critical Thinking Evaluation of Large Language Models,"Large language models (LLMs) excel in complex tasks but often struggle with
inconsistencies in problem framing, a critical skill for real-world scenarios. This
paper introduces SPARK, a novel evaluation framework grounded in the Hierar-
chical Three-Space Theory, to assess LLMs’ ability to identify missing informa-
tion and challenge flawed problem setups. We propose a general framework to
create benchmarks by introducing inconsistencies and misleading cues in diverse
question-answering datasets, covering mathematics, science, and reading compre-
hension. To assist with robust measuring of critical thinking, we employ two key
metrics: problem-solving capability rate and challenge rate. Our experiments with
state-of-the-art LLMs reveal their limitations in critical thinking, particularly in
recognizing inconsistencies. We also explore mitigation strategies, such as modi-
fied prompting and targeted fine-tuning. Furthermore, we conduct comprehensive
experiments to investigate how model and problem properties influence critical
thinking capabilities in LLMs.","Runing Yang, Adam Nguyen, Hoang Anh Just, Ruoxi Jia, Ming Jin","~Runing_Yang1, ~Adam_Nguyen1, ~Hoang_Anh_Just1, ~Ruoxi_Jia1, ~Ming_Jin2","critical thinking, llm, problem-solving, benchmarks",datasets and benchmarks,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=0sJ8TqOLGS,https://openreview.net/forum?id=0sJ8TqOLGS
SMlVEeoSyI,StretchySnake: Flexible VideoMamba for Short and Long-Form Action Recognition,"State space models (SSMs) have very recently been introduced as an alternative deep architecture to transformers, exhibiting competitive or superior performance across various language and vision tasks. However, both SSMs and transformers share certain limitations in the vision domain, namely spatio-temporal inflexibility. Traditionally, deep video models are trained on a fixed resolution and number of frames, often arbitrarily chosen as a trade-off between performance and computational cost. Changing the resolution and/or number of frames a model can ingest usually requires retraining the model, while avoiding re-training by variably changing the weights of a trained model leads to significantly reduced test accuracy. In this paper, we introduce a spatio-temporal flexible training method that encourages a single set of learned weights to adapt well to any input resolution or video length. We achieve this by simply randomly changing the spatial and temporal resolutions of a video during training, and dynamically interpolating the model's weights accordingly. This single change in training not only allows for one model to be applied to both short and long video understanding tasks alike, but also allows for user-specific tailoring of computational cost. We propose and evaluate $5$ different spatio-temporal flexible training methods to find the optimal type for training a video SSM. We then evaluate our best flexibly-trained SSM, which we call StretchySnake, across a variety of short- and long-form action recognition evaluation protocols, such as video retrieval, fine-tuning, and linear probing, and massively outperform the same vanilla video SSM trained in a standard fashion by up to $28$% in some cases. Therefore, our training method can be used as a simple drop-in training technique for any SSM-based video models to strongly improve performance and instill spatio-temporal and compute flexibility.","Nyle Siddiqui, Rohit Gupta, Swetha Sirnam, Mubarak Shah","~Nyle_Siddiqui1, ~Rohit_Gupta3, ~Swetha_Sirnam1, ~Mubarak_Shah3","Representation Learning, Video Understanding, State Space Models","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=SMlVEeoSyI,https://openreview.net/forum?id=SMlVEeoSyI
ywgwArtbDq,Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs,"Modern CAPTCHAs often rely on vision tasks that are supposedly hard for computers but easy for humans. Although image recognition models pose a significant threat to such CAPTCHAs, they can be fooled by hiding ``random'' noise in images. However, these methods are model-specific and thus can not aid CAPTCHAs in fooling all models. 
    We show in this work that by allowing for more significant changes to the images while preserving the semantic information and keeping it solvable by humans, we can fool many state-of-the-art models. Specifically, we demonstrate that by adding masks of various intensities the Top 1 Accuracy (Acc@1) drops by more than 50%-points for all models, and supposedly robust models such as vision transformers see an Acc@1 drop of 80%-points. 
    These masks can therefore effectively fool modern image classifiers, thus showing that machines have not caught up with humans -- yet.","Andreas Plesner, Yahya Jabary, Turlan Kuzhagaliyev, Roger Wattenhofer","~Andreas_Plesner1, ~Yahya_Jabary1, ~Turlan_Kuzhagaliyev1, ~Roger_Wattenhofer1","CAPTCHAs, Adversarial examples, Vision models, Robust models","other topics in machine learning (i.e., none of the above)",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=ywgwArtbDq,https://openreview.net/forum?id=ywgwArtbDq
6AUzsrsNUx,MetaTool: Facilitating Large Language Models to Master Tools with Meta-task Augmentation,"Utilizing tools with Large Language Models (LLMs) is essential for grounding AI agents in real-world applications. The prevailing approach involves few-shot prompting with demonstrations or fine-tuning with expert annotations. However, mere in-context demonstrations may fail to cover sufficient knowledge for complex tools and tasks. Training on solution paths is also hindered by the high cost of expert annotations and generalizing to new tools. A core challenge of generalizable tool use lies in understanding the ""meta'', or fundamental natures of tools that are transferable across tasks, such as causality and constraints. In this paper, we present MetaTool, a novel tool learning methodology designed to generalize across any reusable toolset. Our approach incorporates a self-supervised augmentation technique derived from a series of meta-tasks. This involves predicting masked elements in the tool execution process. The self-supervised procedure enables scalable generation of high-quality QA data, which is handy for supervising tool understanding. By incorporating meta-task data into task-oriented training, our method significantly enhances the performance of open-source LLMs, achieving results comparable to ChatGPT in both tool-based planning and chatting scenarios. Through large-scale instruction tuning, the MetaTool model demonstrates impressive zero-shot generalizability on new tasks.","Xiaohan Wang, Dian Li, Yilin Zhao, sinbadliu, Hui Wang","~Xiaohan_Wang3, ~Dian_Li1, ~Yilin_Zhao6, ~sinbadliu1, ~Hui_Wang23","large language models, tool learning, function calling, tool understanding, instruction tuning","foundation or frontier models, including LLMs",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=6AUzsrsNUx,https://openreview.net/forum?id=6AUzsrsNUx
2HN97iDvHz,LLM-Powered Predictive Decision-Making for Sustainable Data Center Operations,"The growing demand for AI-driven workloads, particularly from Large Language Models (LLMs), has raised concerns about the significant energy and resource consumption in data centers. This work introduces a novel LLM-based predictive scheduling system designed to enhance operational efficiency while reducing the environmental impact of data centers. Our system utilizes an LLM to predict key metrics such as execution time and energy consumption from source code, and it has the potential to extend to other sustainability-focused metrics like water usage for cooling and carbon emissions, provided the data center can track such data. The predictive model is followed by a real-time scheduling algorithm that allocates GPU resources, aiming to improve sustainability by optimizing both energy consumption and queuing delays. With fast inference times, the ability to generalize across diverse task types, and minimal data requirements for training, our approach offers a practical solution for data center scheduling. This framework demonstrates strong potential for advancing sustainability objectives in AI-driven infrastructure. Through our collaboration with a data center, we achieved a 32% reduction in energy consumption and a 30% decrease in waiting time.","Hanzhao Wang, Jingxuan Wu, Yu Pan, Yumeng Li, Yansong Wang, Helang Liu, Fuqiang Wang, Guanting Chen","~Hanzhao_Wang1, ~Jingxuan_Wu2, ~Yu_Pan9, ~Yumeng_Li6, ~Yansong_Wang4, ~Helang_Liu1, ~Fuqiang_Wang1, ~Guanting_Chen1","Large Language Models, Generative AI, Sustainability, Real-time decision-making","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=2HN97iDvHz,https://openreview.net/forum?id=2HN97iDvHz
K7xpl3LZQp,Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images,"Large vision-language models (LVLMs) have demonstrated remarkable image understanding and dialogue capabilities, allowing them to handle a variety of visual question answering tasks. However, their widespread availability raises concerns about unauthorized usage and copyright infringement, where users or individuals can develop their own LVLMs by fine-tuning published models. In this paper, we propose a novel method called Parameter Learning Attack (PLA) for tracking the copyright of LVLMs without modifying the original model. Specifically, we construct adversarial images through targeted attacks against the original model, enabling it to generate specific outputs. To ensure these attacks remain effective on potential fine-tuned models to trigger copyright tracking, we allow the original model to learn the trigger images by updating parameters in the opposite direction during the adversarial attack process. Notably, the proposed method can be applied after the release of the original model, thus not affecting the model’s performance and behavior. To simulate real-world applications, we fine-tune the original model using various strategies across diverse datasets, creating a range of models for copyright verification. Extensive experiments demonstrate that our method can more effectively identify the original copyright of fine-tuned models compared to baseline methods. Therefore, this work provides a powerful tool for tracking copyrights and detecting unlicensed usage of LVLMs.","Yubo Wang, Jianting Tang, Chaohu Liu, Linli Xu","~Yubo_Wang8, ~Jianting_Tang1, ~Chaohu_Liu1, ~Linli_Xu1","Copyright Tracking, Large Vision-Language Models, Adversarial Attacks, Fine-tuning","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=K7xpl3LZQp,https://openreview.net/forum?id=K7xpl3LZQp
EoTIlDT0Tr,$\mathcal{X}^2$-DFD: A framework for e$\mathcal{X}$plainable and e$\mathcal{X}$tendable Deepfake Detection,"Detecting deepfakes (*i.e.*, AI-generated content with malicious intent) has become an important task. Most existing detection methods provide only real/fake predictions without offering human-comprehensible explanations. Recent studies leveraging multimodal large-language models (MLLMs) for deepfake detection have shown improvements in explainability. However, the performance of pre-trained MLLMs (*e.g.*, LLaVA) remains limited due to a lack of understanding of their capabilities for this task and strategies to enhance them. In this work, we empirically assess the strengths and weaknesses of MLLMs specifically in deepfake detection via forgery-related feature analysis. Building on these assessments, we propose a novel framework called $\mathcal{X}^2$-DFD, consisting of three core modules. 
The first module, *Model Feature Assessment (MFA)*, measures the detection capabilities of forgery-related features intrinsic to MLLMs, and gives a descending ranking of these features. 
The second module, *Strong Feature Strengthening (SFS)*, enhances the detection and explanation capabilities by fine-tuning the MLLM on a dataset constructed based on the top-ranked features. 
The third module, *Weak Feature Supplementing (WFS)*, improves the fine-tuned MLLM's capabilities on lower-ranked features by integrating external dedicated deepfake detectors. 
To verify the effectiveness of this framework, we further present a practical implementation, where an automated forger-related feature generation, evaluation, and ranking procedure is designed for *MFA* module; an automated generation procedure of the fine-tuning dataset containing real and fake images with explanations based on top-ranked features is developed for *SFS* model; an external conventional deepfake detector focusing on blending artifact, which corresponds to a low detection capability in the pre-trained MLLM, is integrated for *WFS* module. 
Experimental results show that the proposed implementation enhances overall detection performance compared to pre-trained MLLMs, while providing more convincing explanations. 
More encouragingly, our framework is designed to be plug-and-play, allowing it to seamlessly integrate with more advanced MLLMs and external detectors, leading to continual improvement and extension to face the challenges of rapidly evolving deepfake technologies.","Yize Chen, Zhiyuan Yan, Siwei Lyu, Baoyuan Wu","~Yize_Chen2, ~Zhiyuan_Yan3, ~Siwei_Lyu1, ~Baoyuan_Wu1",Deepfake Detection; Multimodal Large Language Models; Media Forensics,"other topics in machine learning (i.e., none of the above)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=EoTIlDT0Tr,https://openreview.net/forum?id=EoTIlDT0Tr
CI5Cj0vktS,Robust Barycenter Estimation using Semi-Unbalanced Neural Optimal Transport,"Aggregating data from multiple sources can be formalized as an *Optimal Transport* (OT) barycenter problem, which seeks to compute the average of probability distributions with respect to OT discrepancies. However, in real-world scenarios, the presence of outliers and noise in the data measures can significantly hinder the performance of traditional statistical methods for estimating OT barycenters. To address this issue, we propose a novel scalable approach for estimating the *robust* continuous barycenter, leveraging the dual formulation of the *(semi-)unbalanced* OT problem. To the best of our knowledge, this paper is the first attempt to develop an algorithm for robust barycenters under the continuous distribution setup. Our method is framed as a $\min$-$\max$ optimization problem and is adaptable to *general* cost functions. We rigorously establish the theoretical underpinnings of the proposed method and demonstrate its robustness to outliers and class imbalance through a number of illustrative experiments. Our source code is publicly available at https://github.com/milenagazdieva/U-NOTBarycenters.","Milena Gazdieva, Jaemoo Choi, Alexander Kolesov, Jaewoong Choi, Petr Mokrov, Alexander Korotin","~Milena_Gazdieva1, ~Jaemoo_Choi1, ~Alexander_Kolesov1, ~Jaewoong_Choi1, ~Petr_Mokrov1, ~Alexander_Korotin2","unbalanced optimal transport, barycenter, generative modeling",generative models,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=CI5Cj0vktS,https://openreview.net/forum?id=CI5Cj0vktS
AFAmM5dsFu,Inv-PnCO: Invariant Predict-and-Combinatorial Optimization under Distribution Shifts,"Machine learning has been well introduced to solve combinatorial optimization (CO) problems over the decade, while most works only consider the deterministic setting. Yet in real-world applications, decisions have often to be made in uncertain environments, which is typically reflected by the stochasticity of the coefficients of the problem at hand, considered as a special case of the more general and emerging ""predict-and-optimize"" (PnO) paradigm in the sense that the prediction and optimization are jointly learned and performed. In this paper, we consider the problem of learning to solve CO under the above uncertain setting and formulate it as ""predict-and-combinatorial optimization"" (PnCO), particularly in a challenging yet practical out-of-distribution (OOD) setting, where there is a distribution shift between training and testing CO instances. We propose the Invariant Predict-and-Combinatorial Optimization (Inv-PnCO) framework to alleviate this challenge. Inv-PnCO derives a learning objective that reduces the distance of distribution of solutions with the true distribution and uses a regularization term to learn invariant decision-oriented factors that are stable under various environments, thereby enhancing the generalizability of predictions and subsequent optimizations. We also provide a theoretical analysis of how the proposed loss reduces OOD error. The empirical evaluation across three distinct tasks on knapsack, visual shortest path planning, and traveling salesman problem covering array, image, and graph inputs underscores the efficacy of Inv-PnCO to enhance the generalizability, both for predict-then-optimize and predict-and-optimize approaches.","Haoyu Geng, Qitian Wu, Yang Li, Hang Ruan, Xiangpeng Wan, Yu Cheng, Junchi Yan","~Haoyu_Geng1, ~Qitian_Wu1, ~Yang_Li32, ~Hang_Ruan1, ~Xiangpeng_Wan1, ~Yu_Cheng1, ~Junchi_Yan2","Combinatorial Optimization, Predict-and-optimize, Generalization",optimization,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=AFAmM5dsFu,https://openreview.net/forum?id=AFAmM5dsFu
H1nykRhieN,MvHSTM: A Multi-view Hypergraph Spatio-Temporal Model for Traffic Speed Forecasting,"Accurate traffic speed prediction is critical in modern society as it is effective for both individuals and authorities. Due to the large scale of urban road networks, traffic speed exhibits complex spatio-temporal dependencies, not only among adjacent nodes but also across the network, reflecting both local and cross-regional simultaneous correlations. However, existing studies have not effectively addressed these characteristics. In this context, we propose a novel framework called Multi-view Hypergraph Spatio-Temporal Model (MvHSTM) that employs a temporal transformer to capture temporal dependencies and utilizes hypergraph convolutional networks to inherently model spatial relationships. Specifically, we introduce two hypergraph construction methods, the Geographical Adjacency Hypergraph (GAH) and the Feature Similarity Hypergraph (FSH), to capture spatial correlations on neighboring and non-neighboring scales. Extensive experiments on real-world traffic speed datasets demonstrate that our approach achieves state-of-the-art performance compared to baseline methods.","Bo Shen, Ruyu Shang, Yapeng Qi","~Bo_Shen7, ~Ruyu_Shang1, ~Yapeng_Qi1","Traffic Prediction, Deep Learning, Hypergraph Convolution","other topics in machine learning (i.e., none of the above)",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=H1nykRhieN,https://openreview.net/forum?id=H1nykRhieN
SaOxhcDCM3,Large Language Models Suffer From Their Own Output: An Analysis of the Self-Consuming Training Loop,"Large Language Models (LLM) are already widely used to generate content for a variety of online platforms. As we are not able to safely distinguish LLM-generated content from human-produced content, LLM-generated content is used to train the next generation of LLMs, giving rise to a self-consuming training loop. From the image generation domain we know that such a self-consuming training loop reduces both quality and diversity of images finally ending in a model collapse. However, it is unclear whether this alarming effect can also be observed for LLMs. Therefore, we present the first study investigating the self-consuming training loop for LLMs. Further, we propose a novel method based on logic expressions that allows us to unambiguously verify the correctness of LLM-generated content, which is difficult for natural language text. We find that the self-consuming training loop produces correct outputs, however, the output declines in its diversity depending on the proportion of the used generated data. Fresh data can slow down this decline, but not stop it. Further, we observe similar results on a real natural language dataset. Given these concerning results, we encourage researchers to study methods to negate this process.","Martin Briesch, Dominik Sobania, Franz Rothlauf","~Martin_Briesch1, ~Dominik_Sobania1, ~Franz_Rothlauf1","self-consuming training loop, large language models, model collapse, generative models",generative models,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=SaOxhcDCM3,https://openreview.net/forum?id=SaOxhcDCM3
kBVPD2kJMy,ROMA: Regularization for Out-of-distribution Detection with Masked Autoencoders,"Existing out-of-distribution (OOD) detection methods without outlier exposure learn effective in-distribution (ID) representations distinguishable for OOD samples, which have shown promising performance on many OOD detection tasks. However, we find a performance degradation in some challenging OOD detection, where pre-trained networks tend to perform worse during the fine-tuning process, exhibiting the over-fitting of ID representations. Motivated by this observation, we propose a critical task of hidden OOD detection, wherein ID representations provide limited or even counterproductive assistance in identifying hidden OOD data. To address this issue, we introduce a novel Regularization framework for OOD detection with Masked Autoencoders (ROMA), which utilizes the masked image modeling task to regularize the network. With distribution-agnostic auxiliary data exposure, ROMA notably surpasses previous OOD detection methods in hidden OOD detection. Moreover, the robustness of ROMA is further evidenced by its state-of-the-art performance on benchmarks for other challenging OOD detection tasks.","Xiaochen Feng, Yuan Jiang, Hao Sha, Yongbing Zhang","~Xiaochen_Feng1, ~Yuan_Jiang8, ~Hao_Sha6, ~Yongbing_Zhang1","out-of-distribution detection, masked autoencoders, regularization, masked image modeling","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=kBVPD2kJMy,https://openreview.net/forum?id=kBVPD2kJMy
OFukl9Qg8P,Resolution Attack: Exploiting Image Compression to Deceive Deep Neural Networks,"Model robustness is essential for ensuring the stability and reliability of machine learning systems. Despite extensive research on various aspects of model robustness, such as adversarial robustness and label noise robustness, the exploration of robustness towards different resolutions, remains less explored. To address this gap, we introduce a novel form of attack: the resolution attack. This attack aims to deceive both classifiers and human observers by generating images that exhibit different semantics across different resolutions. To implement the resolution attack, we propose an automated framework capable of generating dual-semantic images in a zero-shot manner. Specifically, we leverage large-scale diffusion models for their comprehensive ability to construct images and propose a staged denoising strategy to achieve a smoother transition across resolutions. Through the proposed framework, we conduct resolution attacks against various off-the-shelf classifiers. The experimental results exhibit high attack success rate, which not only validates the effectiveness of our proposed framework but also reveals the vulnerability of current classifiers towards different resolutions. Additionally, our framework, which incorporates features from two distinct objects, serves as a competitive tool for applications such as face swapping and facial camouflage. The code is available at https://github.com/ywj1/resolution-attack.","Wangjia Yu, Xiaomeng Fu, Qiao Li, Jizhong Han, Xiaodan Zhang","~Wangjia_Yu1, ~Xiaomeng_Fu1, ~Qiao_Li4, ~Jizhong_Han1, ~Xiaodan_Zhang3",Resolution Attack、Image Generation、Deep Learning Robustness、Image Classification,"alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=OFukl9Qg8P,https://openreview.net/forum?id=OFukl9Qg8P
N0ts5QGEW9,CXPMRG-Bench: Pre-training and Benchmarking for X-ray Medical Report Generation on CheXpert Plus Dataset,"X-ray image-based medical report generation (MRG) is a pivotal area in artificial intelligence which can significantly reduce diagnostic burdens and patient wait times. Despite significant progress, we believe that the task has reached a bottleneck due to the limited benchmark datasets and the existing large models' insufficient capability enhancements in this specialized domain. Specifically, the recently released CheXpert Plus dataset lacks comparative evaluation algorithms and their results, providing only the dataset itself. This situation makes the training, evaluation, and comparison of subsequent algorithms challenging. Thus, we conduct a comprehensive benchmarking of existing mainstream X-ray report generation models and large language models (LLMs), on the CheXpert Plus dataset. We believe that the proposed benchmark can provide a solid comparative basis for subsequent algorithms and serve as a guide for researchers to quickly grasp the state-of-the-art models in this field. More importantly, we propose a big model for the X-ray image report generation using a multi-stage pre-training strategy, including self-supervised autoregressive generation and Xray-report contrastive learning, and supervised fine-tuning. Extensive experimental results indicate that the autoregressive pre-training based on Mamba effectively encodes X-ray images, and the image-text contrastive pre-training further aligns the feature spaces, achieving better experimental results. All the source codes will be released upon acceptance.","Xiao Wang, Fuling Wang, Yuehang Li, Qingchuan Ma, Shiao Wang, Bo Jiang, Chuanfu Li, Jin Tang","~Xiao_Wang16, ~Fuling_Wang1, ~Yuehang_Li2, ~Qingchuan_Ma1, ~Shiao_Wang1, ~Bo_Jiang5, ~Chuanfu_Li1, ~Jin_Tang4",Medical Report Generation; X-ray Image Pre-training; State Space Model; Benchmark,"foundation or frontier models, including LLMs",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=N0ts5QGEW9,https://openreview.net/forum?id=N0ts5QGEW9
ueeqGvQozB,ML4MILP: A Benchmark Dataset for Machine Learning-based Mixed-Integer Linear Programming,"Machine learning (ML)-based approaches for solving mixed integer linear programming (MILP) problems have shown significant potential and are growing in sophistication. Despite this advancement, progress in this field is often hindered by the mixed and unsorted nature of current benchmark datasets, which typically lack carefully categorized collections of homogeneous instances.
To bridge this gap, we propose ML4MILP, a new open-source benchmark dataset specifically designed for evaluating ML-based optimization algorithms in the MILP domain. Based on the proposed structure and embedding similarity metrics, we used a novel classification algorithm to carefully categorize the collected and generated instances, resulting in a benchmark dataset encompassing 100,000 instances across more than 70 heterogeneous classes.
We demonstrate the utility of ML4MILP through extensive benchmarking against a comprehensive suite of algorithms in the baseline library, consisting of traditional exact solvers and heuristic algorithms, as well as ML-based approaches. Our ML4MILP is open-source and accessible at: https://anonymous.4open.science/r/ML4MILP-6BE0.","Huigen Ye, Yaoyang Cheng, Hua Xu, Zhiguang Cao, Hanzhang Qin","~Huigen_Ye1, ~Yaoyang_Cheng1, ~Hua_Xu1, ~Zhiguang_Cao1, ~Hanzhang_Qin1","Mixed Integer Linear Programming, Machine Learning, Benchmark Dataset",datasets and benchmarks,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=ueeqGvQozB,https://openreview.net/forum?id=ueeqGvQozB
hmDt068MoZ,Can Knowledge Editing Really Correct Hallucinations?,"Large Language Models (LLMs) suffer from hallucinations, referring to the non-factual information in generated content, despite their superior capacities across tasks. Meanwhile, knowledge editing has been developed as a new popular paradigm to correct  erroneous factual knowledge encoded in LLMs with the advantage of avoiding retraining from scratch. However, a common issue of existing evaluation datasets for knowledge editing is that they do not ensure that LLMs actually generate hallucinated answers to the evaluation questions before editing. When LLMs are evaluated on such datasets after being edited by different techniques, it is hard to directly adopt the performance to assess the effectiveness of different knowledge editing methods in correcting hallucinations. Thus, the fundamental question remains insufficiently validated: Can knowledge editing really correct hallucinations in LLMs? We proposed HalluEditBench to holistically benchmark knowledge editing methods in correcting real-world hallucinations. First, we rigorously construct a massive hallucination dataset with 9 domains, 26 topics and more than 6,000 hallucinations. Then, we assess the performance of knowledge editing methods in a holistic way on five dimensions including Efficacy, Generalization, Portability, Locality, and Robustness. Through HalluEditBench, we have provided new insights into the potentials and limitations of different knowledge editing methods in correcting hallucinations, which could inspire future improvements and facilitate progress in the field of knowledge editing.","Baixiang Huang, Canyu Chen, Xiongxiao Xu, Ali Payani, Kai Shu","~Baixiang_Huang1, ~Canyu_Chen1, ~Xiongxiao_Xu1, ~Ali_Payani1, ~Kai_Shu1","LLMs, Knowledge Editing, Hallucination, Benchmark","foundation or frontier models, including LLMs",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=hmDt068MoZ,https://openreview.net/forum?id=hmDt068MoZ
ogXkmugNZw,Conflict-Averse Gradient Aggregation for Constrained Multi-Objective Reinforcement Learning,"In real-world applications, a reinforcement learning (RL) agent should consider multiple objectives and adhere to safety guidelines.
To address these considerations, we propose a constrained multi-objective RL algorithm named constrained multi-objective gradient aggregator (CoMOGA).
In the field of multi-objective optimization, managing conflicts between the gradients of the multiple objectives is crucial to prevent policies from converging to local optima.
It is also essential to efficiently handle safety constraints for stable training and constraint satisfaction.
We address these challenges straightforwardly by treating the maximization of multiple objectives as a constrained optimization problem (COP), where the constraints are defined to improve the original objectives.
Existing safety constraints are then integrated into the COP, and the policy is updated by solving the COP, which ensures the avoidance of gradient conflicts.
Despite its simplicity, CoMOGA guarantees convergence to global optima in a tabular setting.
Through various experiments, we have confirmed that preventing gradient conflicts is critical, and the proposed method achieves constraint satisfaction across all tasks.","Dohyeong Kim, Mineui Hong, Jeongho Park, Songhwai Oh","~Dohyeong_Kim1, ~Mineui_Hong1, ~Jeongho_Park1, ~Songhwai_Oh1","Multi-Objective Reinforcement Learning, Safe Reinforcement Learning, Gradient Aggregation",reinforcement learning,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=ogXkmugNZw,https://openreview.net/forum?id=ogXkmugNZw
K2jOacHUlO,To Trust or Not to Trust? Enhancing Large Language Models' Situated Faithfulness to External Contexts,"Large Language Models (LLMs) are often augmented with external contexts, such as those used in retrieval-augmented generation (RAG). However, these contexts can be inaccurate or intentionally misleading, leading to conflicts with the model’s internal knowledge. We argue that robust LLMs should demonstrate situated faithfulness, dynamically calibrating their trust in external information based on their confidence in the internal knowledge and the external context to resolve knowledge conflicts. To benchmark this capability, we evaluate LLMs across several QA datasets, including a newly created dataset featuring in-the-wild incorrect contexts sourced from Reddit posts. We show that when provided with both correct and incorrect contexts, both open-source and proprietary models tend to overly rely on external information, regardless of its factual accuracy. To enhance situated faithfulness, we propose two approaches: Self-Guided Confidence Reasoning (SCR) and Rule-Based Confidence Reasoning (RCR). SCR enables models to self-access the confidence of external information relative to their own internal knowledge to produce the most accurate answer. RCR, in contrast, extracts explicit confidence signals from the LLM and determines the final answer using predefined rules. 
Our results show that for LLMs with strong reasoning capabilities, such as GPT-4o and GPT-4o mini, SCR outperforms RCR, achieving improvements of up to 24.2\% over a direct input augmentation baseline. Conversely, for a smaller model like Llama-3-8B, RCR outperforms SCR. Fine-tuning SCR with our proposed Confidence Reasoning Direct Preference Optimization (CR-DPO) method improves performance on both seen and unseen datasets, yielding an average improvement of 8.9\% on Llama-3-8B. In addition to quantitative results, we offer insights into the relative strengths of SCR and RCR. Our findings highlight promising avenues for improving situated faithfulness in LLMs.","Yukun Huang, Sanxing Chen, Hongyi Cai, Bhuwan Dhingra","~Yukun_Huang3, ~Sanxing_Chen1, ~Hongyi_Cai3, ~Bhuwan_Dhingra1","Large Language Model, Knowledge Conflict, Retrieval Augmented Generation, Confidence Estimation, Reasoning",interpretability and explainable AI,ICLR 2025 Spotlight,2025,https://openreview.net/pdf?id=K2jOacHUlO,https://openreview.net/forum?id=K2jOacHUlO
vyHFTsOUWu,Instruction Following without Instruction Tuning,"Adaptations that seem deficient compared to instruction-tuning (finetuning on instruction-response pairs) can still implicitly yield instruction-following language models. We show that training solely on responses, without any corresponding
instructions, yields instruction following. This suggests that instruction-tuning just needs to teach the desired distribution of responses. However, we then show that one can finetune on instruction-response pairs from a distribution unlike the test distribution of instructions, like just poetry, or just math, and still yield a model that broadly follows instructions. Instead of acting, e.g., just as math models, these single-task models sometimes behave more as general-purpose chatbots for, e.g., non-math instructions. To begin to explain this implicit instruction tuning, we hypothesize that simple changes to a language model’s distribution yield instruction following. We support this by hand-writing a rule-based adapter that yields instruction-following behavior in language models. The rules are to slowly increase the probability of ending the sequence, penalize repetition, and uniformly change 15 words’ probabilities. In summary, adaptations made without being designed to yield instruction following can do so implicitly.","John Hewitt, Nelson F. Liu, Christopher D Manning, Percy Liang","~John_Hewitt1, ~Nelson_F._Liu1, ~Christopher_D_Manning1, ~Percy_Liang1","instruction tuning, instruction following, ablation, rule-based","foundation or frontier models, including LLMs",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=vyHFTsOUWu,https://openreview.net/forum?id=vyHFTsOUWu
5cYTAcZAgt,SAN-Diff: Structure-aware noise for super-resolution diffusion model,"Recent advances in diffusion models, like Stable Diffusion, have been shown to significantly improve performance in image super-resolution (SR) tasks. However, existing diffusion techniques often sample noise from just one distribution, which limits their effectiveness when dealing with complex scenes or intricate textures in different semantic areas. With the advent of the segment anything model (SAM), it has become possible to create highly detailed region masks that can improve the recovery of fine details in diffusion SR models. Despite this, incorporating SAM directly into SR models significantly increases computational demands. In this paper, we propose the SAN-Diff model, which can utilize the fine-grained structure information from SAM in the process of sampling noise to improve the image quality without additional computational cost during inference. In the process of training, we encode structural position information into the segmentation mask from SAM. Then the encoded mask is integrated into the forward diffusion process by modulating it to the sampled noise. This adjustment allows us to independently adapt the noise mean within each corresponding segmentation area. The diffusion model is trained to estimate this modulated noise. Crucially, our proposed framework does NOT change the reverse diffusion process and does NOT require SAM at inference. Experimental results demonstrate the effectiveness of our proposed method, which exhibits the fewest artifacts compared to other generated models, and surpassing existing diffusion-based methods by 0.74 dB at
the maximum in terms of PSNR on DIV2K dataset.","Chengcheng Wang, Zhiwei Hao, Yehui Tang, Jianyuan Guo, Yujie Yang, Chang Xu, Kai Han, Yunhe Wang","~Chengcheng_Wang1, ~Zhiwei_Hao1, ~Yehui_Tang1, ~Jianyuan_Guo1, ~Yujie_Yang4, ~Chang_Xu4, ~Kai_Han2, ~Yunhe_Wang1","Diffusion Model, Image Super-Resolution","applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=5cYTAcZAgt,https://openreview.net/forum?id=5cYTAcZAgt
kFoJXqiGKz,The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind,"We propose Decrypto, a novel interactive benchmark for evaluating coordination, competition, and theory of mind (ToM) reasoning capabilities in agentic, foundational AI models. Existing benchmarks often suffer from data leakage, saturation, and lack of interactivity, making it hard to measure the ability of intelligent systems to model other agents' reasoning. To overcome or alleviate these limitations, we introduce Decrypto, a multi-agent benchmark based on a popular, language-based board game and designed to be future-proof for large language models (LLMs). We validate Decrypto's effectiveness through comprehensive empirical evaluations of frontier LLMs, ablation studies, and human-AI cross-play experiments. We show that LLMs do not coordinate well with other LLMs or humans and perform strictly worse than the latter. Specifically, LLMs struggle to reason about the choices of others, even if they use the same underlying model, pointing to a fundamental limitation of current systems.","Andrei Lupu, Timon Willi, Jakob Nicolaus Foerster","~Andrei_Lupu1, ~Timon_Willi1, ~Jakob_Nicolaus_Foerster1","theory of mind, multi-agent reasoning, LLM benchmark, zero-shot coordination",datasets and benchmarks,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=kFoJXqiGKz,https://openreview.net/forum?id=kFoJXqiGKz
0bswm093Yl,GeneBench: Systematic Evaluation of Genomic Foundation Models and Beyond,"The Genomic Foundation Model (GFM) paradigm is expected to facilitate the extraction of generalizable representations from massive genomic data, thereby enabling their application across a spectrum of downstream applications. Despite advancements, a lack of evaluation framework makes it difficult to ensure equitable assessment due to experimental settings, model intricacy, benchmark datasets, and reproducibility challenges. In the absence of standardization, comparative analyses risk becoming biased and unreliable. To surmount this impasse, we introduce GeneBench, a comprehensive benchmarking suite specifically tailored for evaluating the efficacy of Genomic Foundation Models. GeneBench offers a modular and expandable framework that encapsulates a variety of state-of-the-art methodologies. Through systematic evaluations of datasets spanning diverse biological domains with a particular emphasis on both short-range and long-range genomic tasks, firstly including the three most important DNA tasks covering Coding Region, Non-Coding Region, Genome Structure, etc. Our results on GenBench has led to an interesting discovery: regardless of the number of parameters, the noticeable variation in preference between attention-based and convolution-based models for short- and long-range tasks could offer valuable insights for the future development of GFM. As a result, we propose a straightforward modified model called Genhybrid, which is an effective and efficient convolution-attention hybrid model suitable for all tasks.","Zicheng Liu, Jiahui Li, Lei Xin, Siyuan Li, Chang Yu, Zelin Zang, Cheng Tan, Yufei Huang, yajingbai, Jun Xia, Stan Z. Li","~Zicheng_Liu2, ~Jiahui_Li3, ~Lei_Xin3, ~Siyuan_Li6, ~Chang_Yu2, ~Zelin_Zang2, ~Cheng_Tan1, ~Yufei_Huang4, ~yajingbai1, ~Jun_Xia1, ~Stan_Z._Li2","genetic foundation model, benchmark, hybrid model",datasets and benchmarks,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=0bswm093Yl,https://openreview.net/forum?id=0bswm093Yl
762u1p9dgg,MOEfication by Experts as Masks,"In this work, we investigate how to sparsify a pre-trained dense large language model into a mixture-of-experts (MoE) architecture for faster inference. Our approach applies mask matrix to the activations for each expert, constrained by $L_0$ regularization to minimize the number of activated parameters. Starting with all parameters active, the model is progressively sparsified during training, ensuring minimal performance loss. This approach proves more efficient than one-shot sparsification techniques~\citep{zhang2022moefication}, which typically require significant resources for performance recovery. Moreover, our approach automatically identifies shared, token-specific, and inactive experts, allowing for more efficient allocation of computational resources. Through extensive experiments, we achieve up to 97\% performance retention on downstream tasks with only 50\% of the feed-forward parameters activated in dense models. Beyond enhancing inference efficiency, this strategy of sharing computational units among experts presents a valuable framework for designing more generalized and efficient MoE architectures, opening avenues for future advancements in expert-based models.","Peiyu Liu, Tianwen Wei, Bo Zhu, Xin Zhao, Shuicheng YAN","~Peiyu_Liu1, ~Tianwen_Wei1, ~Bo_Zhu5, ~Xin_Zhao10, ~Shuicheng_YAN3","sparse activated, mixture-of-experts, L0 regularization","foundation or frontier models, including LLMs",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=762u1p9dgg,https://openreview.net/forum?id=762u1p9dgg
MKP1g8wU0P,Spectral-Refiner: Accurate Fine-Tuning of Spatiotemporal Fourier Neural Operator for Turbulent Flows,"Recent advancements in operator-type neural networks have shown promising results in approximating the solutions of spatiotemporal Partial Differential Equations (PDEs). However, these neural networks often entail considerable training expenses, and may not always achieve the desired accuracy required in many scientific and engineering disciplines. In this paper, we propose a new learning framework to address these issues. A new spatiotemporal adaptation is proposed to generalize any Fourier Neural Operator (FNO) variant to learn maps between Bochner spaces, which can perform an arbitrary-length temporal super-resolution for the first time. To better exploit this capacity, a new paradigm is proposed to refine the commonly adopted end-to-end neural operator training and evaluations with the help from the wisdom from traditional numerical PDE theory and techniques. Specifically, in the learning problems for the turbulent flow modeled by the Navier-Stokes Equations (NSE), the proposed paradigm trains an FNO only for a few epochs. Then, only the newly proposed spatiotemporal spectral convolution layer is fine-tuned without the frequency truncation. The spectral fine-tuning loss function uses a negative Sobolev norm for the first time in operator learning, defined through a reliable functional-type a posteriori error estimator whose evaluation is exact thanks to the Parseval identity. Moreover, unlike the difficult nonconvex optimization problems in the end-to-end training, this fine-tuning loss is convex. Numerical experiments on commonly used NSE benchmarks demonstrate significant improvements in both computational efficiency and accuracy, compared to end-to-end evaluation and traditional numerical PDE solvers under certain conditions. The source code is publicly available at https://github.com/scaomath/torch-cfd.","Shuhao Cao, Francesco Brarda, Ruipeng Li, Yuanzhe Xi","~Shuhao_Cao2, ~Francesco_Brarda1, ~Ruipeng_Li1, ~Yuanzhe_Xi1","operator learning, neural operators, Navier-Stokes, PDE, partial differential equations, computational fluid dynamics","applications to physical sciences (physics, chemistry, biology, etc.)",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=MKP1g8wU0P,https://openreview.net/forum?id=MKP1g8wU0P
liqUhMECuY,Towards Aligned Data Forgetting via Twin Machine Unlearning,"Modern privacy regulations have spurred the evolu-
tion of machine unlearning, a technique enabling a trained model
to efficiently forget specific training data. In prior unlearning
methods, the concept of “data forgetting” is often interpreted
and implemented as achieving zero classification accuracy on
such data. Nevertheless, the authentic aim of machine unlearn-
ing is to achieve alignment between the unlearned model and
the gold model (i.e., the model derived from re-training from
scratch without the data to be forgotten). Here, “alignment”
signifies the encouragement for both models to achieve identical
classification accuracy. Owing to its generalization ability, the
gold model can correctly classify a portion of the forgotten data,
resulting in a non-zero classification accuracy. To better align
the unlearned model with the gold model, we propose a Twin
Machine Unlearning (TMU) approach, where a twin unlearning
problem is defined corresponding to the original unlearning
problem. Consequently, the generalization-label predictor trained
on the twin problem can be transferred to the original problem,
facilitating aligned data forgetting. Additionally, we introduce a
noise-perturbed fine-tuning scheme to balance the trade-off be-
tween retaining the model’s generalization ability and enhancing
its resilience to Membership Inference Attacks. Comprehensive
empirical experiments illustrate that our approach significantly
enhances the alignment between the unlearned model and the
gold model. Meanwhile, our method allows data forgetting
without compromising the model’s accuracy.","haoxuan ji, Yuyao Sun, Zhenxing Niu, Gang Hua, Rong Jin, Quan Wang","~haoxuan_ji1, ~Yuyao_Sun1, ~Zhenxing_Niu1, ~Gang_Hua3, ~Rong_Jin3, ~Quan_Wang8",machine unlearning,"other topics in machine learning (i.e., none of the above)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=liqUhMECuY,https://openreview.net/forum?id=liqUhMECuY
mAztx8QO3B,Coreset Selection via Reducible Loss in Continual Learning,"Rehearsal-based continual learning (CL) aims to mitigate catastrophic forgetting by maintaining a subset of samples from previous tasks and replaying them. The rehearsal memory can be naturally constructed as a coreset, designed to form a compact subset that enables training with performance comparable to using the full dataset. The coreset selection task can be formulated as bilevel optimization that solves for the subset to minimize the outer objective of the learning task. Existing methods primarily rely on inefficient probabilistic sampling or local gradient-based scoring to approximate sample importance through an iterative process that can be susceptible to ambiguity or noise. Specifically, non-representative samples like ambiguous or noisy samples are difficult to learn and incur high loss values even when training on the full dataset. However, existing methods relying on local gradient tend to highlight these samples in an attempt to minimize the outer loss, leading to a suboptimal coreset. To enhance coreset selection, especially in CL where high-quality samples are essential, we propose a coreset selection method that measures sample importance using reducible loss (ReL) that quantifies the impact of adding a sample to model performance. By leveraging ReL and a process derived from bilevel optimization, we identify and retain samples that yield the highest performance gain. They are shown to be informative and representative. Furthermore, ReL requires only forward computation, making it significantly more efficient than previous methods. To better apply coreset selection in CL, we extend our method to address key challenges such as task interference, streaming data, and knowledge distillation. Experiments on data summarization and continual learning demonstrate the effectiveness and efficiency of our approach.","Ruilin Tong, Yuhang Liu, Javen Qinfeng Shi, Dong Gong","~Ruilin_Tong1, ~Yuhang_Liu1, ~Javen_Qinfeng_Shi1, ~Dong_Gong1","Continual learning, Coreset selection","transfer learning, meta learning, and lifelong learning",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=mAztx8QO3B,https://openreview.net/forum?id=mAztx8QO3B
qyU5s4fzLg,Improving Unsupervised Constituency Parsing via Maximizing Semantic Information,"Unsupervised constituency parsers organize phrases within a sentence into a tree-shaped syntactic constituent structure that reflects the organization of sentence semantics. 
However, the traditional objective of maximizing sentence log-likelihood (LL) does not explicitly account for the close relationship between the constituent structure and the semantics, resulting in a weak correlation between LL values and parsing accuracy.
In this paper, we introduce a novel objective that trains parsers by maximizing SemInfo, the semantic information encoded in constituent structures.
We introduce a bag-of-substrings model to represent the semantics and estimate the SemInfo value using the probability-weighted information metric.
We apply the SemInfo maximization objective to training Probabilistic Context-Free Grammar (PCFG) parsers and develop a Tree Conditional Random Field (TreeCRF)-based model to facilitate the training. 
Experiments show that SemInfo correlates more strongly with parsing accuracy than LL, establishing SemInfo as a better unsupervised parsing objective.
As a result, our algorithm significantly improves parsing accuracy by an average of 7.85 sentence-F1 scores across five PCFG variants and in four languages, achieving state-of-the-art level results in three of the four languages.","Junjie Chen, Xiangheng He, Yusuke Miyao, Danushka Bollegala","~Junjie_Chen3, ~Xiangheng_He1, ~Yusuke_Miyao2, ~Danushka_Bollegala1","unsupervised constituency parsing, information theory, semantic information","applications to computer vision, audio, language, and other modalities",ICLR 2025 Spotlight,2025,https://openreview.net/pdf?id=qyU5s4fzLg,https://openreview.net/forum?id=qyU5s4fzLg
VZC9aJoI6a,PromptWizard: Task-Aware Prompt Optimization Framework,"Large language models (LLMs) have transformed AI across diverse domains, with \textit{prompting} being central to their success in guiding model outputs. However, manual prompt engineering is both labor-intensive and domain-specific, necessitating the need for automated solutions. We introduce PromptWizard, a novel, fully automated framework for discrete prompt optimization, utilizing a self-evolving, self-adapting mechanism. Through a feedback-driven critique and synthesis process, PromptWizard achieves an effective balance between exploration and exploitation, iteratively refining both prompt instructions and in-context examples to generate human-readable, task-specific prompts. This guided approach systematically improves prompt quality, resulting in superior performance across 45 tasks. PromptWizard excels even with limited training data, smaller LLMs, and various LLM architectures. Additionally, our cost analysis reveals a substantial reduction in API calls, token usage, and overall cost, demonstrating PromptWizard's efficiency, scalability, and advantages over existing prompt optimization strategies.","Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, Akshay Nambi","~Eshaan_Agarwal1, ~Joykirat_Singh1, ~Vivek_Dani1, ~Raghav_Magazine1, ~Tanuja_Ganu1, ~Akshay_Nambi1","Prompt optimization, LLMs, task-aware","foundation or frontier models, including LLMs",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=VZC9aJoI6a,https://openreview.net/forum?id=VZC9aJoI6a
tEM1u9VT2W,Learning with Multi-Group Guarantees for Clusterable Subpopulations,"A canonical desideratum for prediction problems is that performance guarantees should hold not just on average over the population, but also for meaningful subpopulations within the overall population. 
But what constitutes a meaningful subpopulation?
In this work, we take the perspective that relevant subpopulations should be defined with respect to the clusters that naturally emerge from the distribution of individuals for which predictions are being made. 
In this perspective, a population refers to a mixture model whose components constitute the relevant subpopulations.
We suggest two formalisms for capturing per-subgroup guarantees: first, by attributing each individual to the component from which they were most likely drawn, given their features; and second, by attributing each individual to all components in proportion to their relative likelihood of having been drawn from each component.
Using online calibration for Gaussian mixture models as a case study, we study a multi-objective algorithm that provides guarantees for each of these formalisms by handling all plausible underlying subpopulation structures simultaneously, and achieve a $O(T^{1/2})$ rate even when the subpopulations are not well-separated.
In comparison, the more natural _cluster-then-predict_ approach that first recovers the structure of the subpopulations and then makes predictions suffers from a $O(T^{2/3})$ rate and requires the subpopulations to be separable.
Along the way, we prove that providing per-subgroup calibration guarantees for underlying clusters can be easier than learning the clusters: separation between median subgroup features is required for the latter but not the former.","Jessica Dai, Nika Haghtalab, Eric Zhao","~Jessica_Dai1, ~Nika_Haghtalab2, ~Eric_Zhao1","multicalibration, fairness, clustering",learning theory,ICLR 2025 Conference Desk Rejected Submission,2025,https://openreview.net/pdf?id=tEM1u9VT2W,https://openreview.net/forum?id=tEM1u9VT2W
SjRLAzrVRo,Meta ControlNet: Enhancing Task Adaptation via Meta Learning,"Diffusion-based image synthesis has attracted extensive attention recently. In particular, 
ControlNet that uses image-based prompts exhibits powerful capability in image tasks such as canny edge detection and generates images well aligned with these prompts. However, vanilla ControlNet generally requires extensive training of around 5000 steps to achieve a desirable control for a single task. Recent context-learning approaches have improved its adaptability, but mainly for edge-based tasks, and rely on paired examples. Thus, two important open issues are yet to be addressed to reach the full potential of ControlNet: (i) zero-shot control for certain tasks and (ii) faster adaptation for non-edge-based tasks. In this paper, we introduce a novel Meta ControlNet method, 
which adopts the task-agnostic meta learning technique and features a new layer freezing design. Meta ControlNet significantly reduces learning steps to attain control ability from 5000 to 1000. Further, Meta ControlNet exhibits direct zero-shot adaptability in edge-based tasks without any finetuning, and achieves control within only 100 finetuning steps in more complex non-edge tasks such as Human Pose.","Junjie Yang, Jinze Zhao, Peihao Wang, Yingbin Liang","~Junjie_Yang2, ~Jinze_Zhao1, ~Peihao_Wang1, ~Yingbin_Liang1","Diffusion Models, Meta Learning","transfer learning, meta learning, and lifelong learning",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=SjRLAzrVRo,https://openreview.net/forum?id=SjRLAzrVRo
KYxxSgwRxf,Action Typicality and Uniqueness Learning for Zero-Shot Video Anomaly Detection,"Zero-Shot Video Anomaly Detection (ZS-VAD) is an urgent task in scenarios where the target video domain lacks training data due to various concerns, \emph{e.g.}, data privacy. The skeleton-based approach is a promising way to achieve ZS-VAD as it eliminates domain disparities in both background and human appearance. However, existing methods only learn low-level skeleton representation and rely on the domain-specific normality boundary, which cannot generalize well to new scenes with different normal and abnormal behavior patterns. In this paper, we propose a novel skeleton-based zero-shot video anomaly detection framework, which captures both scene-generic typical anomalies and scene-adaptive unique anomalies. Firstly, we introduce a language-guided typicality modeling module that projects skeleton snippets into action semantic space and learns generalizable typical distributions of normal and abnormal behavior. Secondly, we propose a test-time context uniqueness analysis module to finely analyze the spatio-temporal differences between skeleton snippets and then derive scene-adaptive boundaries. Without using any training samples from the target domain, our method achieves state-of-the-art results on four large-scale VAD datasets: ShanghaiTech, UBnormal, NWPU, and UCF-Crime. The Code will be publicly available.","Canhui Tang, Sanping Zhou, Haoyue Shi, Hao Sun, Le Wang","~Canhui_Tang1, ~Sanping_Zhou1, ~Haoyue_Shi3, ~Hao_Sun15, ~Le_Wang8","video anomaly detection, zero-shot, skeleton-based","applications to computer vision, audio, language, and other modalities",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=KYxxSgwRxf,https://openreview.net/forum?id=KYxxSgwRxf
uZmmgHY1mD,The Perfect Blend: Redefining RLHF with Mixture of Judges,"Reinforcement learning from human feedback (RLHF) has become the leading approach for fine-tuning large language models (LLM). However, RLHF has limitations in multi-task learning (MTL) due to challenges of reward hacking and extreme multi-objective optimization (i.e., trade-off of multiple and/or sometimes conflicting objectives). Applying RLHF for MTL currently requires careful tuning of the weights for reward model and data combinations. This is often done via human intuition and does not generalize. In this work, we introduce a novel post-training paradigm which we called Constrained Generative Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with cost-efficient constrained policy optimization with stratification, which can identify the perfect blend in RLHF in a principled manner. It shows strong empirical results with theoretical guarantees, does not require extensive hyper-parameter tuning, and is plug-and-play in common post-training pipelines. Together, this can detect and mitigate reward hacking behaviors while reaching a pareto-optimal point across an extremely large number of objectives. 

Our results show that CGPO consistently outperforms other commonly used SoTA RLHF algorithms (such as PPO and DPO) on a wide range of tasks -- general chat, STEM questions, instruction following, math, coding and knowledge. In particular, CGPO improves over PPO by 7.4% in AlpacaEval-2 (general chat), 12.5% in Arena-Hard (STEM\reasoning), 2% in IFEval (Instrcution Following), 2% in both MATH and GSM8K (Math\reasoning), 5% in HumanEval (Coding), and 2% in the ARC challenge (Knowledge). We also observe that PPO is susceptible to severe reward hacking behaviors (it exhibits severe regression in popular coding benchmarks) which can be addressed by CGPO. CGPO represents a breakthrough in RLHF, simultaneously addressing reward-hacking and extreme multi-objective optimization, and thereby advancing the state-of-the-art in aligning general-purpose LLMs.","Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talebzadeh, Madian Khabsa, Gabriel Cohen, Sinong Wang, Yuandong Tian, Hao Ma, Han Fang","~Tengyu_Xu1, ~Eryk_Helenowski1, ~Karthik_Abinav_Sankararaman1, ~Di_Jin1, ~Kaiyan_Peng1, ~Eric_Han1, ~Shaoliang_Nie1, ~Chen_Zhu2, ~Hejia_Zhang2, ~Wenxuan_Zhou1, ~Zhouhao_Zeng1, ~Yun_He2, ~Karishma_Mandyam1, ~Arya_Talebzadeh1, ~Madian_Khabsa1, ~Gabriel_Cohen1, ~Sinong_Wang1, ~Yuandong_Tian1, ~Hao_Ma1, ~Han_Fang4","Large Language Model, Reinforcement Learning from Human Feedback, Mixture of Judges, Constrained Policy Optimization","foundation or frontier models, including LLMs",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=uZmmgHY1mD,https://openreview.net/forum?id=uZmmgHY1mD
bgpNJBD6Va,No Preference Left Behind: Group Distributional Preference Optimization,"Preferences within a group of people are not uniform but follow a distribution. While existing alignment methods like Direct Preference Optimization (DPO) attempt to steer models to reflect human preferences, they struggle to capture the distributional pluralistic preferences within a group. These methods often skew toward dominant preferences, overlooking the diversity of opinions, especially when conflicting preferences arise. To address this issue, we propose Group Distributional Preference Optimization (GDPO), a novel framework that aligns language models with the distribution of preferences within a group by incorporating the concept of beliefs that shape individual preferences. GDPO calibrates a language model using statistical estimation of the group's belief distribution and aligns the model with belief-conditioned preferences, offering a more inclusive alignment framework than traditional methods. In experiments using both synthetic controllable opinion generation and real-world movie review datasets, we show that DPO fails to align with the targeted belief distributions, while GDPO consistently reduces this alignment gap during training. Additionally, our evaluation metrics demonstrate that GDPO outperforms existing approaches in aligning with group distributional preferences, marking a significant advance in pluralistic alignment.","Binwei Yao, Zefan Cai, Yun-Shiuan Chuang, Shanglin Yang, Ming Jiang, Diyi Yang, Junjie Hu","~Binwei_Yao1, ~Zefan_Cai1, ~Yun-Shiuan_Chuang1, ~Shanglin_Yang1, ~Ming_Jiang6, ~Diyi_Yang2, ~Junjie_Hu2",preference alignment; large language model; fairness; group preferences,"alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=bgpNJBD6Va,https://openreview.net/forum?id=bgpNJBD6Va
DumcCxxzka,RNAinformer: Generative RNA Design with Tertiary Interactions,"The function of an RNA molecule depends on its structure and a strong structure-to-function relationship is already achieved on the secondary structure level of RNA. Therefore, the secondary structure based design of RNAs is one of the major challenges in computational biology. A common approach of RNA design is inverse RNA folding. However, existing RNA design approaches cannot invert all folding algorithms because they cannot represent all types of base interactions. In this work, we propose RNAinformer, a novel generative transformer based approach to the inverse RNA folding problem. Leveraging axial-attention, we directly model the secondary structure input represented as an adjacency matrix in a 2D latent space, which allows us to invert all existing secondary structure prediction algorithms. Consequently, RNAinformer is the first model capable of designing RNAs from secondary structures with all base interactions, including non-canonical base pairs and tertiary interactions like pseudoknots and base multiplets. We demonstrate RNAinformer’s state-of-the-art performance across different RNA design benchmarks and showcase its novelty by inverting different RNA secondary structure prediction algorithms.","Sharat Patil, Frederic Runge, Jörg K.H. Franke, Frank Hutter","~Sharat_Patil1, ~Frederic_Runge1, ~Jörg_K.H._Franke1, ~Frank_Hutter1","RNA, RNA Design, RNA Inverse Folding, Transformers, Generative Design, Axial Attention, pseduoknots, multiplets","applications to physical sciences (physics, chemistry, biology, etc.)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=DumcCxxzka,https://openreview.net/forum?id=DumcCxxzka
UoYxPYMUWd,Outcome-Driven Action Flexibility for Robust Offline Reinforcement Learning,"We address the challenge of offline reinforcement learning using realistic data, specifically non-expert data collected through sub-optimal behavior policies. A primary concern is that the learned policy must be conservative enough to manage \textit{distribution shift} while maintaining sufficient flexibility for generalization. To tackle this issue, we introduce a novel method called Outcome-Driven Action Flexibility (ODAF), which seeks to reduce reliance on the empirical action distribution of the behavior policy.
Specifically, we develop a new reward mechanism that evaluates whether the subsequent states, following the current policy, meet specified performance requirements (e.g., safety—remaining within the state support area), rather than solely depending on the characteristics of the actions taken (e.g., whether the action imitates the behavior policy).
Besides theoretical justification, we provide empirical evidence on widely used D4RL benchmarks, demonstrating that our ODAF method, implemented using uncertainty quantification techniques, effectively tolerates unseen transitions for improved ""trajectory stitching,"" while enhancing the agent's ability to learn from realistic non-expert data.","Ke Jiang, Xiaoyang Tan","~Ke_Jiang2, ~Xiaoyang_Tan2",Offline reinforcement learning; Robust reinforcement learning;Outcome-driven action flexibility;,reinforcement learning,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=UoYxPYMUWd,https://openreview.net/forum?id=UoYxPYMUWd
HSGCCUwH7r,Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligence,"We propose Model Swarms, a collaborative search algorithm to adapt LLMs via swarm intelligence, the collective behavior guiding individual systems. Specifically, Model Swarms starts with a pool of LLM experts and a utility function. Guided by the best-found checkpoints across models, diverse LLM experts collaboratively move in the weight space and optimize a utility function representing model adaptation objectives. Compared to existing model composition approaches, Model Swarms offers tuning-free model adaptation, works in low-data regimes with as few as 200 examples, and does not require assumptions about specific experts in the swarm or how they should be composed. Extensive experiments demonstrate that Model Swarms could flexibly adapt LLM experts to a single task, multi-task domains, reward models, as well as diverse human interests, improving over 12 model composition baselines by up to 21.0% across tasks and contexts. Further analysis reveals that LLM experts discover previously unseen capabilities in initial checkpoints and that Model Swarms enable the weak-to-strong transition of experts through the collaborative search process.","Shangbin Feng, Zifeng Wang, Yike Wang, Sayna Ebrahimi, Hamid Palangi, Lesly Miculicich, Achin Kulshrestha, Nathalie Rauschmayr, Yejin Choi, Yulia Tsvetkov, Chen-Yu Lee, Tomas Pfister","~Shangbin_Feng1, ~Zifeng_Wang1, ~Yike_Wang1, ~Sayna_Ebrahimi1, ~Hamid_Palangi1, ~Lesly_Miculicich1, ~Achin_Kulshrestha1, ~Nathalie_Rauschmayr1, ~Yejin_Choi1, ~Yulia_Tsvetkov1, ~Chen-Yu_Lee2, ~Tomas_Pfister1","evolutionary algorithm, model adaptation, model merging","applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=HSGCCUwH7r,https://openreview.net/forum?id=HSGCCUwH7r
KlalQu2423,CtD: Composition through Decomposition in Emergent Communication,"Compositionality is a cognitive mechanism that allows humans to systematically combine known concepts in novel ways.
This study demonstrates how artificial neural agents acquire and utilize compositional generalization to describe previously unseen images.
Our method, termed \`\`Composition through Decomposition'', involves two sequential training steps.
In the \'Decompose\' step, the agents learn to decompose an image into basic concepts using a codebook acquired during interaction in a multi-target coordination game.
Subsequently, in the \`Compose\' step, the agents employ this codebook to describe novel images by composing basic concepts into complex phrases.
Remarkably, we observe cases where generalization in the `Compose' step is achieved zero-shot, without the need for additional training.","Boaz Carmeli, Ron Meir, Yonatan Belinkov","~Boaz_Carmeli1, ~Ron_Meir1, ~Yonatan_Belinkov1","Emergent communication, Compositionality, Codebook learning","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=KlalQu2423,https://openreview.net/forum?id=KlalQu2423
w0389y0W9D,Flat-LoRA: Low-Rank Adaption over a Flat Loss Landscape,"Fine-tuning large-scale pre-trained models is prohibitively expensive in terms of computational and memory costs. Low-Rank Adaptation (LoRA), a popular Parameter-Efficient Fine-Tuning (PEFT) method, provides an efficient way to fine-tune models by optimizing only a low-rank matrix. Despite recent progress made in improving LoRA's performance, the connection between the LoRA optimization space and the original full parameter space is often overlooked. A solution that appears flat in the LoRA space may exist sharp directions in the full parameter space, potentially harming generalization performance. In this paper, we propose Flat-LoRA, an efficient approach that seeks a low-rank adaptation located in a flat region of the full parameter space. Instead of relying on the well-established sharpness-aware minimization approach, which can incur significant computational and memory burdens, we utilize random weight perturbation with a Bayesian expectation loss objective to maintain training efficiency and design a refined perturbation generation strategy for improved performance. Experiments on natural language processing and image classification tasks with various architectures demonstrate the effectiveness of our approach.","Tao Li, Zhengbao He, Yujun Li, Yasheng Wang, Lifeng Shang, Xiaolin Huang","~Tao_Li12, ~Zhengbao_He1, ~Yujun_Li1, ~Yasheng_Wang1, ~Lifeng_Shang1, ~Xiaolin_Huang1","low-rank adaption, flat minima, efficient training",optimization,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=w0389y0W9D,https://openreview.net/forum?id=w0389y0W9D
r4GxmIBDbO,Diffusion Pretraining for Gait Recognition in the Wild,"Recently, diffusion models have garnered much attention for their remarkable generative capabilities. Yet, their application for representation learning remains largely unexplored. In this paper, we explore the possibility of using the diffusion process to pretrain the backbone of a deep learning model for a specific application—gait recognition in the wild. To do so, we condition a latent diffusion model on the output of a gait recognition model backbone. Our pretraining experiments on the Gait3D and GREW datasets reveal an interesting phenomenon: diffusion pretraining causes the gait recognition backbone to separate gait sequences belonging to different subjects further apart than those belonging to the same subjects, which translates to a steady improvement in gait recognition performance. Subsequently, our transfer learning experiments on Gait3D and GREW show that the pretrained backbone can serve as an effective initialization for the downstream gait recognition task, allowing the gait recognition model to achieve better performance within much fewer supervised training iterations. We validated the applicability of our approach across multiple existing gait recognition methods and conducted extensive ablation studies to investigate the impact of different pretraining hyperparameters on the final gait recognition performance.","Wei Ming Neo, Koichi Shinoda, Tat-Jen Cham","~Wei_Ming_Neo1, ~Koichi_Shinoda1, ~Tat-Jen_Cham1","Diffusion Models, Gait Recognition, Representation Learning","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=r4GxmIBDbO,https://openreview.net/forum?id=r4GxmIBDbO
NA2vUMaMOm,Online Clustering with Nearly Optimal Consistency,"We give online algorithms for $k$-Means(more generally, $(k, z)$-Clustering) with nearly optimal consistency (a notion suggested by Lattanzi & Vassilvitskii (2017)). 
Our result turns any $\alpha$-approximate offline algorithm for clustering into an $(1+\epsilon)\alpha^2$-competitive online algorithm for clustering with $O(k \text{poly} \log n)$ consistency. 
This consistency bound is optimal up to $\text{poly} \log(n)$ factors. 
Plugging in the offline algorithm that returns the exact optimal solution, 
we obtain the first
$(1 + \epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.
This simultaneously improves several previous results (Lattanzi & Vassilvitskii, 2017; Fichtenberger et al., 2021). 
We validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm. 
Our online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.","T-H. Hubert Chan, Shaofeng H.-C. Jiang, Tianyi Wu, Mengshi Zhao","~T-H._Hubert_Chan1, ~Shaofeng_H.-C._Jiang1, ~Tianyi_Wu9, ~Mengshi_Zhao3","clustering, online, consistency","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=NA2vUMaMOm,https://openreview.net/forum?id=NA2vUMaMOm
Pui7Sa6Jwi,CLEAR: An Information-Theoretic  Framework for Distraction-Free Representation Learning in Visual Offline RL,"Visual offline RL aims to learn an optimal policy for visual domains, solely from the pre-collected dataset comprised of actions taken on visual observations. Prior works on visual RL typically learn a dynamics model by extracting a latent state representation. However, the learned representation would contain factors irrelevant to control when there are distractions in the visual observations. These nuisance factors introduced by the distraction further exacerbates the difficulties of learning a good policy in the offline RL setting. In this work, we formalize the visual offline RL setting as a Partially Observable Markov Decision Process with exogenous variables (ExoPOMDP) and identify  these problems with previous approaches under an information-theoretic lens. To overcome these challenges, we propose CLEAR (**C**ontrollable **L**atent State **E**xtr**A**cto**R**) for visual offline RL, which learns the dynamics model of a succinct agent-centric state representation that is consistent with the underlying ExoPOMDP. We empirically demonstrate that CLEAR is able to outperform baselines on the DeepMind Control Suite with various types of distractions and perform consistently well across these distractions. We further provide qualitative analysis on the results showing that our approach successfully disentangles the distraction factors from the agent-centric state representation.","Tri Wahyu Guntara, Daiki E. Matsunaga, HyeongJoo Hwang, Kee-Eung Kim","~Tri_Wahyu_Guntara1, ~Daiki_E._Matsunaga1, ~HyeongJoo_Hwang1, ~Kee-Eung_Kim2","Visual Offline Reinforcement Learning, Information-Theoretic Representation Learning",reinforcement learning,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=Pui7Sa6Jwi,https://openreview.net/forum?id=Pui7Sa6Jwi
107ZsHD8h7,Autoformulation of Mathematical Optimization Models Using LLMs,"Mathematical optimization is fundamental to decision-making across diverse domains, from operations research to healthcare. Yet, translating real-world problems into optimization models remains a formidable challenge, often demanding specialized expertise. This paper formally introduces the concept of *autoformulation*---an automated approach to creating optimization models from natural language descriptions for commercial solvers.
We identify the three core challenges of autoformulation: (1) defining the vast, problem-dependent hypothesis space, (2) efficiently searching this space under uncertainty, and (3) evaluating formulation correctness (ensuring a formulation accurately represents the problem).
To address these challenges, we introduce a novel method leveraging *Large Language Models* (LLMs) within a *Monte-Carlo Tree Search* framework. This approach systematically explores the space of possible formulations by exploiting the hierarchical nature of optimization modeling.  LLMs serve two key roles: as dynamic formulation hypothesis generators and as evaluators of formulation correctness. To enhance search efficiency, we introduce a pruning technique to remove trivially equivalent formulations. 
Empirical evaluations across benchmarks containing linear and mixed-integer programming problems demonstrate our method's superior performance. Additionally, we observe significant efficiency gains from employing LLMs for correctness evaluation and from our pruning techniques.","Nicolás Astorga, Tennison Liu, Yuanzhang Xiao, Mihaela van der Schaar","~Nicolás_Astorga1, ~Tennison_Liu1, ~Yuanzhang_Xiao1, ~Mihaela_van_der_Schaar2","Large Language Models, optimization modeling","applications to robotics, autonomy, planning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=107ZsHD8h7,https://openreview.net/forum?id=107ZsHD8h7
VkqqZcofEu,A Controlled Study on Long Context  Extension and Generalization in LLMs,"Broad textual understanding and in-context learning require language models that utilize full document contexts. Due to the implementation challenges associated with directly training long-context models, many methods have been proposed for extending models to handle long contexts. However, owing to differences in data and model classes, it has been challenging to compare these approaches, leading to uncertainty as to how to evaluate long-context performance and whether it differs from standard evaluation. We implement a controlled protocol for extension methods with a standardized evaluation, utilizing consistent base models and extension data. Our study yields several insights into long-context behavior. First, we reaffirm the critical role of perplexity as a general-purpose performance indicator even in longer-context tasks. Second, we find that current approximate attention methods systematically underperform across long-context tasks. Finally, we confirm that exact fine-tuning based methods are generally effective within their extension range, whereas extrapolation remains challenging. All codebases, models, and checkpoints will be made available open-source, promoting transparency and facilitating further research in this critical area of AI development.","Yi Lu, Jing Nathan Yan, Songlin Yang, Justin T Chiu, Siyu Ren, Fei Yuan, Wenting Zhao, Zhiyong Wu, Alexander M Rush","~Yi_Lu7, ~Jing_Nathan_Yan1, ~Songlin_Yang1, ~Justin_T_Chiu1, ~Siyu_Ren1, ~Fei_Yuan2, ~Wenting_Zhao1, ~Zhiyong_Wu3, ~Alexander_M_Rush1","Controlled Study, Long Context, Extension, Benchmark, Analysis","other topics in machine learning (i.e., none of the above)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=VkqqZcofEu,https://openreview.net/forum?id=VkqqZcofEu
WoPovNkM5h,Small Models are LLM Knowledge Triggers for Medical Tabular Prediction,"Recent development in large language models (LLMs) has demonstrated impressive domain proficiency on unstructured textual or multi-modal tasks. However, despite with intrinsic world knowledge, their application on structured tabular data prediction still lags behind, primarily due to the numerical insensitivity and modality discrepancy that brings a gap between LLM reasoning and statistical tabular learning. Unlike textual or vision data (e.g., electronic clinical notes or medical imaging data), tabular data is often presented in heterogeneous numerical values (e.g., CBC reports). This ubiquitous data format requires intensive expert annotation, and its numerical nature limits LLMs' capability to effectively transfer untapped domain expertise. In this paper, we propose SERSAL, a general self-prompting method by synergy learning with small models to enhance LLM tabular prediction in an unsupervised manner. Specifically, SERSAL utilizes the LLM's prior outcomes as original soft noisy annotations, which are dynamically leveraged to teach a better small student model. Reversely, the outcomes from the trained small model are used to teach the LLM to further refine its real capability. This process can be repeatedly applied to gradually distill refined knowledge for continuous progress. Comprehensive experiments on widely used medical domain tabular datasets show that, without access to gold labels, applying SERSAL to OpenAI GPT reasoning process attains substantial improvement compared to linguistic prompting methods, which serves as an orthogonal direction for tabular LLM, and increasing prompting bonus is observed as more powerful LLMs appear. Codes are available at https://github.com/jyansir/sersal.","Jiahuan Yan, Jintai Chen, Chaowen Hu, Bo Zheng, Yaojun Hu, Jimeng Sun, Jian Wu","~Jiahuan_Yan1, ~Jintai_Chen1, ~Chaowen_Hu1, ~Bo_Zheng7, ~Yaojun_Hu2, ~Jimeng_Sun3, ~Jian_Wu6","tabular data, prompt learning, classification","applications to computer vision, audio, language, and other modalities",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=WoPovNkM5h,https://openreview.net/forum?id=WoPovNkM5h
71pur4y8gs,TabWak: A Watermark for Tabular Diffusion Models,"Synthetic data offers alternatives for data augmentation and sharing. Till date, it remains unknown how to use watermarking techniques to trace and audit synthetic tables generated by tabular diffusion models to mitigate potential misuses. In this paper, we design TabWak, the first watermarking method to embed invisible signatures that control the sampling of Gaussian latent codes used to synthesize table rows via the diffusion backbone. TabWak has two key features. Different from existing image watermarking techniques, TabWak uses self-cloning and shuffling to embed the secret key in positional information of random seeds that control the Gaussian latents, allowing to use different seeds at each row for high inter-row diversity and enabling row-wise detectability. To further boost the robustness of watermark detection against post-editing attacks, TabWak uses a valid-bit mechanism that focuses on the tail of the latent code distribution for superior noise resilience. We provide theoretical guarantees on the row diversity and effectiveness of detectability. We evaluate TabWak on five datasets against baselines to show that the quality of watermarked tables remains nearly indistinguishable from non-watermarked tables while achieving high detectability in the presence of strong post-editing attacks, with a 100% true positive rate at a 0.1% false positive rate on synthetic tables with fewer than 300 rows. Our code is available at the following anonymized repository https://github.com/chaoyitud/TabWak.","Chaoyi Zhu, Jiayi Tang, Jeroen M. Galjaard, Pin-Yu Chen, Robert Birke, Cornelis Bos, Lydia Y. Chen","~Chaoyi_Zhu2, ~Jiayi_Tang3, ~Jeroen_M._Galjaard1, ~Pin-Yu_Chen1, ~Robert_Birke1, ~Cornelis_Bos1, ~Lydia_Y._Chen1","Watermarking, Tabular data, Generative models, Tabular diffusion models","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Spotlight,2025,https://openreview.net/pdf?id=71pur4y8gs,https://openreview.net/forum?id=71pur4y8gs
ajxAJ8GUX4,Learning Geometric Reasoning Networks For Robot Task And Motion Planning,"Task and Motion Planning (TAMP) is a computationally challenging robotics problem due to the tight coupling of discrete symbolic planning and continuous geometric planning of robot motions. In particular, planning manipulation tasks in complex 3D environments leads to a large number of costly geometric planner queries to verify the feasibility of considered actions and plan their motions. To address this issue, we propose Geometric Reasoning Networks (GRN), a graph neural network (GNN)-based model for action and grasp feasibility prediction, designed to significantly reduce the dependency on the geometric planner. Moreover, we introduce two key interpretability mechanisms: inverse kinematics (IK) feasibility prediction and grasp obstruction (GO) estimation. These modules not only improve feasibility predictions accuracy, but also explain why certain actions or grasps are infeasible, thus allowing a more efficient search for a feasible solution. Through extensive experimental results, we show that our model outperforms state-of-the-art methods, while maintaining generalizability to more complex environments, diverse object shapes, multi-robot settings, and real-world robots.","Smail Ait Bouhsain, Rachid Alami, Thierry Simeon","~Smail_Ait_Bouhsain1, ~Rachid_Alami1, ~Thierry_Simeon1","Graph Neural Networks, Deep Learning for Robotics, Task and Motion Planning, Robot Manipulation Planning","applications to robotics, autonomy, planning",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=ajxAJ8GUX4,https://openreview.net/forum?id=ajxAJ8GUX4
l0tg0jzsdL,Taming Overconfidence in LLMs: Reward Calibration in RLHF,"Language model calibration refers to the alignment between the confidence of the model and the actual performance of its responses.
While previous studies point out the overconfidence phenomenon in Large Language Models (LLMs) and show that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) are overconfident with a more sharpened output probability, in this study, we reveal that RLHF tends to lead models to express verbalized overconfidence in their own responses. We investigate the underlying cause of this overconfidence and demonstrate that reward models used for Proximal Policy Optimization (PPO) exhibit inherent biases towards high-confidence scores regardless of the actual quality of responses. Building upon this insight, we propose two PPO variants: PPO-M: $\underline{PPO}$ with Calibrated Reward $\underline{M}$odeling and PPO-C: $\underline{PPO}$ with Calibrated Reward $\underline{C}$alculation. PPO-M integrates explicit confidence scores in reward model training, which calibrates reward models
to better capture the alignment between response quality and verbalized confidence. PPO-C adjusts the reward score during PPO based on the difference between the current reward and the moving average of past rewards. Both PPO-M and PPO-C can be seamlessly integrated into the current PPO pipeline and do not require additional golden labels. We evaluate our methods on both $\texttt{Llama3-8B}$ and $\texttt{Mistral-7B}$ across six diverse datasets including multiple-choice and open-ended generation. Experiment results demonstrate that both of our methods can reduce calibration error and maintain performance comparable to standard PPO. We further show that they do not compromise model capabilities in open-ended conversation settings.","Jixuan Leng, Chengsong Huang, Banghua Zhu, Jiaxin Huang","~Jixuan_Leng1, ~Chengsong_Huang1, ~Banghua_Zhu1, ~Jiaxin_Huang1","Calibration, RLHF, Large Language Models",generative models,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=l0tg0jzsdL,https://openreview.net/forum?id=l0tg0jzsdL
XcFJZORJgY,Discrimination for Generation,"There are two primary approaches to learning from data: discriminative models, which make predictions based on provided data, and generative models, which learn data distributions to create new instances. This paper introduces a novel framework, Discrimination for Generation (DFG), as the first attempt to bridge the gap between discriminative and generative models. Through DFG, discriminative models can function as generative models. We leverage the Neural Tangent Kernel (NTK) to map discriminative models into a connected functional space, enabling the calculation of the distance between the data manifold and a sampled data point.
Our experimental results demonstrate that the proposed algorithm can generate high-fidelity images and can be applied to various tasks such as Targeted Editing and Inpainting, in addition to both unconditional and conditional image generation.
This connection provides a novel perspective for interpreting models. Moreover, our method is algorithm-, architecture-, and dataset-agnostic, offering flexibility and proving to be a robust technique across a wide range of scenarios.","Junhoo Lee, Hyeonjin Kim, Han Sangbum, Nojun Kwak","~Junhoo_Lee2, ~Hyeonjin_Kim2, ~Han_Sangbum1, ~Nojun_Kwak1","Generative model, Discriminative model, Neural Tangent Kernel, Functional Analysis",generative models,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=XcFJZORJgY,https://openreview.net/forum?id=XcFJZORJgY
PDgZ3rvqHn,Select before Act: Spatially Decoupled Action Repetition for Continuous Control,"Reinforcement Learning (RL) has achieved remarkable success in various continuous control tasks, such as robot manipulation and locomotion.
Different to mainstream RL which makes decisions at individual steps, recent studies have incorporated action repetition into RL, achieving enhanced action persistence with improved sample efficiency and superior performance.
However, existing methods treat all action dimensions as a whole during repetition, ignoring variations among them.
This constraint leads to inflexibility in decisions, which reduces policy agility with inferior effectiveness. 
In this work, we propose a novel repetition framework called SDAR, which implements Spatially Decoupled Action Repetition through performing closed-loop act-or-repeat selection for each action dimension individually.
SDAR achieves more flexible repetition strategies, leading to an improved balance between action persistence and diversity.
Compared to existing repetition frameworks, SDAR is more sample efficient with higher policy performance and reduced action fluctuation.
Experiments are conducted on various continuous control scenarios, 
demonstrating the effectiveness of spatially decoupled repetition design proposed in this work.","Buqing Nie, Yangqing Fu, Yue Gao","~Buqing_Nie1, ~Yangqing_Fu1, ~Yue_Gao8","Reinforcement Learning, Action Repetition",reinforcement learning,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=PDgZ3rvqHn,https://openreview.net/forum?id=PDgZ3rvqHn
yJduhi9mDQ,HÖLDER PRUNING: LOCALIZED PRUNING FOR BACKDOOR REMOVAL IN DEEP NEURAL NETWORKS,"Deep Neural Networks (DNNs) have become the cornerstone of modern machine
learning applications, achieving impressive results in domains ranging from com-
puter vision to autonomous systems. However, their dependence on extensive data
and computational resources exposes them to vulnerabilities such as backdoor
attacks, where poisoned samples can lead to erroneous model outputs. To counter
these threats, we introduce a defense strategy called Hölder Pruning to detect
and eliminate neurons affected by triggers embedded in poisoned samples. Our
method partitions the neural network into two stages: feature extraction and feature
processing, aiming to detect and remove backdoored neurons—the highly sensitive
neurons affected by the embedded triggers—while maintaining model performance
This improves model sensitivity to perturbations and enhances pruning precision
by exploiting the unique clustering properties of poisoned samples. We use the
Hölder constant to quantify sensitivity of neurons to input perturbations and prove
that using the Fast Gradient Sign Method (FGSM) can effectively identify highly
sensitive backdoored neurons. Our extensive experiments demonstrate efficacy of
Hölder Pruning across six clean feature extractors (SimCLR, Pretrained ResNet-18,
ViT, ALIGN, CLIP, and BLIP-2) and confirm robustness against nine backdoor
attacks (BadNets, LC, SIG, LF, WaNet, Input-Aware, SSBA, Trojan, BppAttack)
using three datasets (CIFAR-10, CIFAR-100, GTSRB). We compare Hölder Pruning to eight SOTA backdoor defenses (FP, ANP, CLP, FMP, ABL, DBD, D-ST)
and show that Hölder Pruning outperforms all eight SOTA methods. Moreover,
Hölder Pruning achieves a runtime up to 1000x faster than SOTA defenses when
a clean feature extractor is available. Even when clean feature extractors are not
available, our method is up to 10x faster.","Yuchen Wu, Yifei Zhao, Kaiyuan Zheng, Dinuka Sahabandu, Bhaskar Ramasubramanian, Radha Poovendran","~Yuchen_Wu2, ~Yifei_Zhao4, ~Kaiyuan_Zheng1, ~Dinuka_Sahabandu1, ~Bhaskar_Ramasubramanian1, ~Radha_Poovendran1","Holder Pruning, Holder iteration defense, backdoor attacks, Deep Neural Networks, backdoor defense","other topics in machine learning (i.e., none of the above)",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=yJduhi9mDQ,https://openreview.net/forum?id=yJduhi9mDQ
CjXaMI2kUH,MrSteve: Instruction-Following Agents in Minecraft with What-Where-When Memory,"Significant advances have been made in developing general-purpose embodied AI in environments like Minecraft through the adoption of LLM-augmented hierarchical approaches. While these approaches, which combine high-level planners with low-level controllers, show promise, low-level controllers frequently become performance bottlenecks due to repeated failures. In this paper, we argue that the primary cause of failure in many low-level controllers is the absence of an episodic memory system. To address this, we introduce MrSteve (Memory Recall Steve), a novel low-level controller equipped with Place Event Memory (PEM), a form of episodic memory that captures what, where, and when information from episodes. This directly addresses the main limitation of the popular low-level controller, Steve-1. Unlike previous models that rely on short-term memory, PEM organizes spatial and event-based data, enabling efficient recall and navigation in long-horizon tasks. Additionally, we propose an Exploration Strategy and a Memory-Augmented Task Solving Framework, allowing agents to alternate between exploration and task-solving based on recalled events. Our approach significantly improves task-solving and exploration efficiency compared to existing methods. We will release our code and demos on the project page: https://sites.google.com/view/mr-steve.","Junyeong Park, Junmo Cho, Sungjin Ahn","~Junyeong_Park1, ~Junmo_Cho1, ~Sungjin_Ahn1","Generalist Agents, Minecraft, Place Event Memory","other topics in machine learning (i.e., none of the above)",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=CjXaMI2kUH,https://openreview.net/forum?id=CjXaMI2kUH
wSozvhEYq7,Achieving Optimal Complexity in Decentralized Learning over Row-Stochastic Networks,"A key challenge in decentralized optimization is determining the optimal convergence rate and designing algorithms that can achieve it. While this issue has been thoroughly addressed for doubly-stochastic and column-stochastic mixing matrices, the row-stochastic setting remains largely unexplored. This study establishes the first convergence lower bound for decentralized learning over row-stochastic networks. However, developing algorithms to achieve this lower bound is highly challenging due to several factors: (i) the widely used Row-Only gossip protocol,  Pull-Diag, suffers from significant instability in achieving average consensus; (ii)  Pull-Diag-based algorithms are sensitive to data heterogeneity; and (iii) there has been no analysis in nonconvex and stochastic settings to date. This work addresses these deficiencies by proposing and analyzing a new gossip protocol called Pull-Sum, along with its gradient tracking extension, Pull-Sum-GT. The Pull-Sum protocol mitigates the instability issues of Pull-Diag, while Pull-Sum-GT achieves the first linear speedup convergence rate without relying on data heterogeneity assumptions. Additionally, we introduce a multi-step strategy that enables Pull-Sum-GT to match the established lower bound up to logarithmic factors, demonstrating its near-optimal performance and the tightness of our established lower bound. Experiments validate our theoretical results.","Liyuan Liang, Xinyi Chen, Gan Luo, Kun Yuan","~Liyuan_Liang1, ~Xinyi_Chen9, ~Gan_Luo1, ~Kun_Yuan4","decentralized stochastic optimization, directed graph, row-stochastic matrix, gradient tracking",optimization,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=wSozvhEYq7,https://openreview.net/forum?id=wSozvhEYq7
NnwDdPDwUq,Contextual Bandits with Entropy-based Human Feedback,"In recent years, preference-based human feedback mechanisms have become integral to improving model performance across a range of applications, including conversational AI systems like ChatGPT. However, existing methodologies often overlook critical factors such as model uncertainty and variability in feedback quality. To address these limitations, we propose an innovative entropy-based human feedback framework designed for contextual bandits, which balances exploration and exploitation by soliciting expert feedback when model entropy surpasses a predefined threshold. Our method is model-agnostic and adaptable to any contextual bandit agent employing stochastic policies. Through rigorous experimentation, we demonstrate that our approach requires minimal human feedback to achieve significant performance gains, even with suboptimal feedback quality. Our work not only introduces a novel feedback solicitation strategy but also underscores the robustness of integrating human guidance into machine learning systems. Our code is publicly available: \url{https://anonymous.4open.science/r/CBHF-33C5}","Raihan Seraj, Tristan Sylvain, Lili Meng","~Raihan_Seraj1, ~Tristan_Sylvain2, ~Lili_Meng2","Contextual bandits, human feedback",reinforcement learning,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=NnwDdPDwUq,https://openreview.net/forum?id=NnwDdPDwUq
TKRIRI9tQv,Exact Recovery Guarantees for Parameterized Nonlinear System Identification Problem under Adversarial Attacks,"In this work, we study the system identification problem for parameterized nonlinear systems using basis functions under adversarial attacks. Motivated by the LASSO-type estimators, we analyze the exact recovery property of a nonsmooth estimator, which is generated by solving an embedded $\ell_1$-loss minimization problem. First, we derive necessary and sufficient conditions for the well-specifiedness of the estimator and the uniqueness of global solutions to the underlying optimization problem. Next, we provide exact recovery guarantees for the estimator under two different scenarios of boundedness and Lipschitz continuity of the basis functions. The non-asymptotic exact recovery is guaranteed with high probability, even when there are more severely corrupted data than clean data. Finally, we numerically illustrate the validity of our theory. This is the first study on the sample complexity analysis of a nonsmooth estimator for the nonlinear system identification problem.","Haixiang Zhang, Baturalp Yalcin, Javad Lavaei, Eduardo Sontag","~Haixiang_Zhang1, ~Baturalp_Yalcin1, ~Javad_Lavaei1, ~Eduardo_Sontag1","System identification, robust control, exact recovery",learning on time series and dynamical systems,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=TKRIRI9tQv,https://openreview.net/forum?id=TKRIRI9tQv
