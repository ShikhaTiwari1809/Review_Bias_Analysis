paper_id,title,abstract,authors,authorids,keywords,primary_area,venue,year,pdf_url,forum_url,author_ids,submission_date
0yqWGNFEJA,DMIL-Net: A Multi-View Fusion and Region Decoupling Network For Diffusion-Based Generative Image Forgery Localization,"With the increasing application of image generation technology in artistic creation and image editing, its potential for misuse in image forgery has also become increasingly prominent, posing new challenges to verifying image authenticity. In response to this issue, we propose the DMIL-Net. Specifically, we first design a multi-view feature learning strategy combining RGB views, noise views, and high-frequency information to fully capture clues from forgery regions. Secondly, we introduce multi-level contrastive learning to capture long-term dependencies across different modalities, leading to better fusion of multi-view features. Finally, we propose a forgery region decoupling and integration strategy, which iteratively decouples and integrates the body region and detail region to generate complete and detail-accurate localization results. In addition, we construct the DMI dataset, which contains 50,000 generative forgery images created via five prevalent diffusion-based generative image forgery methods, to support model training and testing. Experimental results show that DMIL-Net outperforms five mainstream methods on localization performance, generalization, extensibility, and robustness.",,,Generative Image Forgery Localization; Image Manipulation Detection; Forgery Image Dataset;  Diffusion Model,"applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=0yqWGNFEJA,https://openreview.net/forum?id=0yqWGNFEJA,,
1QaTq2NXD6,ACTIVE-o3 : Empowering MLLMs with Active Perception via Pure Reinforcement Learning,"Active vision, also known as active perception, refers to actively selecting where and how to look in order to gather task-relevant information. It is a critical component of efficient perception and decision-making in humans and advanced embodied agents. With the rise of Multimodal Large Language Models (MLLMs) as central planners in robotic systems, the lack of methods for equipping MLLMs with active perception has become a key gap. We first provide a systematic definition of MLLM-based active perception tasks and show that GPT-o3's zoom-in strategy can be viewed as a special case, though it suffers from low efficiency and inaccurate region selection. To address these issues, we propose Active-o3, a reinforcement learning framework built on GRPO that equips MLLMs with active perception capabilities. Leveraging a modular sensing-action design and a dual-form reward, Active-o3 autonomously learns efficient and stable region selection strategies without explicit supervision. We further establish a comprehensive benchmark covering both open-world tasks (small/dense-object grounding) and domain-specific scenarios (remote sensing, autonomous driving, interactive segmentation). Experimental results demonstrate that Active-o3 significantly enhances active perception capabilities compared to Qwen2.5-VL-CoT. Moreover, we show that our RL framework not only preserves the model’s general understanding ability but can also serve as a proxy task for leveraging perception data, further improving performance on benchmarks such as RealWorldQA. We hope that our work can provide a simple codebase and unified evaluation protocol to facilitate future research on active perception with MLLMs.",,,"vlm, RL, reasoning, MLLM","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=1QaTq2NXD6,https://openreview.net/forum?id=1QaTq2NXD6,,
2EvMmC23sC,Critique-Guided Distillation for Efficient and Robust Language Model Reasoning,"Supervised fine-tuning (SFT) with expert demonstrations often suffers from the imitation problem, where models reproduce correct responses without internalizing the underlying reasoning. We propose $\text{C{\small RITIQUE-}G{\small UIDED} D{\small ISTILLATION} (CGD)}$, a multi-stage training framework that augments SFT with teacher-generated $\textit{explanatory critiques}$ and $\textit{refined responses}$. Instead of directly imitating teacher outputs, a student learns to map the triplet of prompt, its own initial response, and teacher critique into the refined teacher response, thereby capturing both $\textit{what}$ to output and $\textit{why}$. Our analyses show that $\text{CGD}$ consistently reduces refinement uncertainty, improves alignment between critiques and responses, and enhances sample efficiency. On reasoning benchmarks, $\text{CGD}$ achieves substantial gains across LLaMA and Qwen families, including +15.0\% on AMC23 and +12.2\% on MATH-500, while avoiding the format drift issues observed in prior critique-based fine-tuning. Importantly, on LLaMA-3.1-8B $\text{CGD}$ approaches or exceeds the performance of SimpleRL-Zero, which is a DeepSeek-R1 replication, while requiring 60x less compute. Beyond reasoning, $\text{CGD}$ maintains or improves general instruction-following and factual accuracy, matching baseline performance on IFEval, MUSR, TruthfulQA, and BBH. In contrast, prior critique-based methods degrade these capabilities (e.g., -21\% on IFEval). Taken together, these results establish $\text{CGD}$ as a robust and generalizable alternative to both conventional SFT and RL-based methods, offering a more efficient path toward advancing the reasoning and safety of large language models.",,,"Large Language Models, Knowledge Distillation, Critique, Iterative Refinement, Reasoning","foundation or frontier models, including LLMs",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=2EvMmC23sC,https://openreview.net/forum?id=2EvMmC23sC,,
2wFXD2upSQ,A Demon at Work: Leveraging Neuron Death for Efficient Neural Network Pruning,"When training deep neural networks, the phenomenon of ""dying neurons"" —units that become inactive and output zero throughout training—has traditionally been viewed as undesirable, linked with optimization challenges, and contributing to plasticity loss, particularly in continual learning scenarios. In this paper, we reassess this phenomenon through the lens of network sparsity and pruning. By systematically exploring the influence of various hyperparameter configurations on the occurrence of dying neurons, we unveil their potential to facilitate simple yet effective structured pruning algorithms. We introduce ""Demon's Pruning"" (DemP), a method that controls the proliferation of dead neurons, dynamically sparsifying neural networks as training progresses. Remarkably, our approach, characterized by its simplicity and broad applicability,  outperforms existing structured pruning techniques, while achieving results comparable to prevalent unstructured pruning methods. These findings pave the way for leveraging dying neurons as a valuable resource for efficient model compression and optimization.","Simon Dufort-Labbé, Pierluca D'Oro, Evgenii Nikishin, Razvan Pascanu, Pierre-Luc Bacon, Aristide Baratin","~Simon_Dufort-Labbé1, ~Pierluca_D'Oro1, ~Evgenii_Nikishin1, ~Razvan_Pascanu1, ~Pierre-Luc_Bacon1, ~Aristide_Baratin1","Pruning, Sparsity, Deep Learning, Regularization, Model Compression","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=2wFXD2upSQ,https://openreview.net/forum?id=2wFXD2upSQ,,
2XBBumBGeP,sRGB Real Noise Modeling via Noise-Aware Sampling with Normalizing Flows,"Noise poses a widespread challenge in signal processing, particularly when it comes to denoising images. Although convolutional neural networks (CNNs) have exhibited remarkable success in this field, they are predicated upon the belief that noise follows established distributions, which restricts their practicality when dealing with real-world noise. To overcome this limitation, several efforts have been taken to collect noisy image datasets from the real world. Generative methods, employing techniques such as generative adversarial networks (GANs) and normalizing flows (NFs), have emerged as a solution for generating realistic noisy images. Recent works model noise using camera metadata, however requiring metadata even for sampling phase. In contrast, in this work, we aim to estimate the underlying camera settings, enabling us to improve noise modeling and generate diverse noise distributions. To this end, we introduce a new NF framework that allows us to both classify noise based on camera settings and generate various noisy images. Through experimental results, our model demonstrates exceptional noise quality and leads in denoising performance on benchmark datasets.","Dongjin Kim, Donggoo Jung, Sungyong Baik, Tae Hyun Kim","~Dongjin_Kim3, ~Donggoo_Jung1, ~Sungyong_Baik1, ~Tae_Hyun_Kim2","sRGB real noise modeling, Normalizing flow, Low-level vision","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 poster,2024,https://openreview.net/pdf?id=2XBBumBGeP,https://openreview.net/forum?id=2XBBumBGeP,,
2YDSK1eiiD,What Can an LLM Flip if It Fails to Flip Coins?,"Large language models (LLMs) can often accurately describe probability distributions using natural language, yet they still struggle to generate faithful samples from them. This mismatch limits their use in tasks requiring reliable stochasticity, such as Monte Carlo methods, agent-based simulations, and randomized decision-making. We investigate this gap between knowledge and sampling in the context of Bernoulli distributions. We introduce Verbalized Rejection Sampling (VRS), a natural-language adaptation of classical rejection sampling that prompts the LLM to reason about and accept or reject proposed samples. Despite relying on the same Bernoulli mechanism internally, VRS substantially reduces sampling bias across models. We provide theoretical analysis showing that, under mild assumptions, VRS improves over direct sampling, with gains attributable to both the algorithm and prompt design. More broadly, our results show how classical probabilistic tools can be verbalized and embedded into LLM workflows to improve reliability, without requiring access to model internals or heavy prompt engineering.",,,"rejection sampling, large language models","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=2YDSK1eiiD,https://openreview.net/forum?id=2YDSK1eiiD,,
3X3LuwzZrl,Multi-Label Node Classification with Label Influence Propagation,"Graphs are a complex and versatile data structure used across various domains, with possibly multi-label nodes playing a particularly crucial role. 
Examples include proteins in PPI networks with multiple functions and users in social or e-commerce networks exhibiting diverse interests. 
Tackling multi-label node classification (MLNC) on graphs has led to the development of various approaches. Some methods leverage graph neural networks (GNNs) to exploit label co-occurrence correlations, while others incorporate label embeddings to capture label proximity. However, these approaches fail to account for the intricate influences between labels in non-Euclidean graph data.
To address this issue, we decompose the message passing process in GNNs into two operations: propagation and transformation. 
We then conduct a comprehensive analysis and quantification of the influence correlations between labels in each operation. 
Building on these insights, we propose a novel model, Label Influence Propagation (LIP). 
Specifically, we construct a label influence graph based on the integrated label correlations. 
Then, we propagate high-order influences through this graph, dynamically adjusting the learning process by amplifying labels with positive contributions and mitigating those with negative influence.
Finally, our framework is evaluated on comprehensive benchmark datasets, consistently outperforming SOTA methods across various settings, demonstrating its effectiveness on MLNC tasks.","Yifei Sun, Zemin Liu, Bryan Hooi, Yang Yang, Rizal Fathony, Jia Chen, Bingsheng He","~Yifei_Sun1, ~Zemin_Liu1, ~Bryan_Hooi1, ~Yang_Yang35, ~Rizal_Fathony1, ~Jia_Chen2, ~Bingsheng_He1","graph neural networks, multi-label, node classification",learning on graphs and other geometries & topologies,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=3X3LuwzZrl,https://openreview.net/forum?id=3X3LuwzZrl,,
49jkevjF6x,Multlingual Abstractive Event Extraction for the Real World,"Event extraction (EE) is a valuable tool for making sense of large amounts of unstructured data, with a wide range of real-world applications, from studying disease outbreaks to monitoring political violence. Current EE systems rely on cumbersome mention-level annotations, and event arguments are frequently restricted to ungrounded spans of text, which hinders the aggregation and analysis of extracted events. In this paper, we define a new abstractive event extraction (AEE) task that moves away from the surface form and instead requires a deeper
wholistic understanding of the input text. To support research in this direction, we release a new multilingual, expert-annotated event dataset called Lemonade, which covers 16 languages, including several for which no event dataset currently exists. Lemonade has 41,148 events, and is based on the Armed Conflict Location and Event Data Project, which has been collecting and coding data on political violence around the globe for over a decade. We introduce a novel zero-shot AEE system Zest that achieves a score of 57.2% F1 on Lemonade. With our supervised model that achieves 71.6% F1, they represent strong baselines for this new dataset.","Sina Semnani, Pingyue Zhang, Wanyue Zhai, Haozhuo Li, Ryan Beauchamp, Trey Billing, Katayoun Kishi, Manling Li, Monica Lam","~Sina_Semnani1, ~Pingyue_Zhang1, ~Wanyue_Zhai1, ~Haozhuo_Li1, ~Ryan_Beauchamp1, ~Trey_Billing1, ~Katayoun_Kishi1, ~Manling_Li1, ~Monica_Lam1","dataset, event extraction, multilingual, zero-shot, entity linking",datasets and benchmarks,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=49jkevjF6x,https://openreview.net/forum?id=49jkevjF6x,,
4CR5Uc9EYf,EraseDiff: Erasing Data Influence in Diffusion Models,"We introduce EraseDiff, an unlearning algorithm designed for diffusion models to address concerns related to data memorization. Our approach formulates the unlearning task as a constrained optimization problem, aiming to preserve the utility of the diffusion model on retained data while removing the information associated with the data to be forgotten. This is achieved by altering the generative process to deviate away from the ground-truth denoising procedure. 
To manage the computational complexity inherent in the diffusion process, we develop a first-order method for solving the optimization problem, which has shown empirical benefits. Extensive experiments and thorough comparisons with state-of-the-art algorithms demonstrate that EraseDiff effectively preserves the model's utility, efficacy, and efficiency.","Jing Wu, Trung Le, Munawar Hayat, Mehrtash Harandi","~Jing_Wu6, ~Trung_Le2, ~Munawar_Hayat2, ~Mehrtash_Harandi2","machine unlearning, diffusion model","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=4CR5Uc9EYf,https://openreview.net/forum?id=4CR5Uc9EYf,,
5XL8c0Vg9k,Infinite-parameter Large Language Model,"In the standard transformer architecture, increasing model parameters leads to linear growth in computational cost and activation memory. To address this issue, we propose a novel Infinite Parameter Large Language Model (IP-LLM) architecture that decouples model size from computational cost and device memory. Existing large language models are all fixed-parameter models, while human knowledge is infinite and expands daily. Finite parameters are inherently limited in their capacity to accommodate this boundless knowledge. Our IP-LLM architecture can potentially accommodate infinite knowledge, resolving this issue and laying the foundation for realizing a truly omniscient and omnipotent artificial general intelligence in the future.",Fei Ding,~Fei_Ding6,lifelong learning,"transfer learning, meta learning, and lifelong learning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=5XL8c0Vg9k,https://openreview.net/forum?id=5XL8c0Vg9k,,
5Y8PMEeAkv,ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models,"As the capabilities of Vision-Language Models (VLMs) advance, they can process increasingly large inputs, which, unlike in LLMs, generates significant visual token redundancy and leads to prohibitive inference costs. While many methods aim to reduce these costs by pruning visual tokens, existing approaches, whether based on attention or diversity, typically neglect the guidance of the text prompt and thus fail to prioritize task relevance. In this work, we propose a novel, zero-shot method that reframes the problem by introducing a prompt-aware perspective, explicitly modeling visual token pruning as a balance between task relevance and information diversity. Our hierarchical approach first selects a core set of task-relevant visual tokens and then supplements them with diversity tokens to preserve broader context. Experiments across multiple models and benchmarks show that our method achieves performance that matches or surpasses the state-of-the-art with only minimal accuracy loss, even when pruning up to 90\% of the tokens. Furthermore, these gains are accompanied by significant reductions in GPU memory footprint and inference latency.",,,"VLM, Prompt-Aware, Zero-Shot, Visual token pruning","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=5Y8PMEeAkv,https://openreview.net/forum?id=5Y8PMEeAkv,,
5ZaoXB3MdP,R-WoM: Retrieval-augmented World Model For Computer-use Agents,"Large Language Models (LLMs) can serve as world models to enhance agent decision-making in digital environments by simulating future states and predicting action outcomes, potentially eliminating costly trial-and-error exploration. However, this capability is fundamentally limited by LLM’s tendency to hallucination and their reliance on static training knowledge, which could lead to compounding errors that inhibit long-horizon simulations. To systematically investigate whether LLMs are appropriate for world modeling, we probe two core capabilities of world models – future state prediction and reward estimation – through three tasks: next-state identification, full-procedure planning alignment, and milestone transition recognition. Our analysis shows that while LLMs effectively capture immediate next states and identify meaningful state transitions, their performance rapidly degrades in full-procedure planning. This highlights LLMs’ limitations in reliably modeling environment dynamics over long horizons. To address these limitations, we propose the Retrieval-augmented World Model (R-WoM), which grounds LLM simulations by incorporating factual, up-to-date knowledge retrieved from external tutorials. Experiments show that R-WoM achieves substantial improvements of up to 25.3% (OSWorld) and 18.1% (WebArena) com-
pared to baselines, with particular advantage in longer-horizon simulations.",,,"Large Language Model, Computer-use Agent, World Model","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=5ZaoXB3MdP,https://openreview.net/forum?id=5ZaoXB3MdP,,
601vEMLqie,DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion,"Diffusion Transformer models can generate images with remarkable fidelity and detail, yet training them at ultra-high resolutions remains extremely costly due to the self-attention mechanism's quadratic scaling with the number of image tokens. In this paper, we introduce Dynamic Position Extrapolation (DyPE), a novel, training-free method that enables pre-trained diffusion transformers to synthesize images at resolutions far beyond their training data, with no additional sampling cost. DyPE takes advantage of the spectral progression inherent to the diffusion process, where low-frequency structures converge early, while high-frequencies take more steps to resolve. Specifically, DyPE dynamically adjusts the model's positional encoding at each diffusion step, matching their frequency spectrum with the current stage of the generative process. This approach allows us to generate images at resolutions that exceed the training resolution dramatically, e.g., 16 million pixels using FLUX. On multiple benchmarks, DyPE consistently improves performance and achieves state-of-the-art fidelity in ultra-high-resolution image generation, with gains becoming even more pronounced at higher resolutions.",,,"Diffusion, Text to Image, High Resolution",generative models,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=601vEMLqie,https://openreview.net/forum?id=601vEMLqie,,
6pmxBlGXyM,​Aligning Stance Dynamics in Foundation Dialogue Models: Towards Context-Aware Safety Control​,"Neural dialogue foundation models exhibit critical safety vulnerabilities by implicitly amplifying toxic discourse through contextual stance alignment. Current mitigation strategies fail to address the nuanced interplay between conversational dynamics and implicit harm. We propose a paradigm shift with three core contributions:
First, we introduce ​context-aware stance classifiers​ leveraging graph-based reasoning and contrastive learning. These models decode complex stance expressions—including sarcastic agreement and indirect bias—that perpetuate harmful echo chambers.
Second, we design ​dynamic safety controllers​ combining attribute-guided decoding with retrieval-augmented counter-speech generation. This hybrid approach steers foundation models toward constructive responses while preserving conversational integrity.
Third, we establish ​multidimensional harm metrics​ quantifying implicit biases across intersectional identities, moving beyond surface-level toxicity. Our framework pioneers joint optimization of stance neutrality, bias mitigation, and fluency preservation.
Validated against adversarial conversational contexts, our method demonstrates significant improvements in ethical alignment for generative dialogue systems. We open-source toolkit facilitates safer deployment of foundation language models.","Rong Fu, GUO XIAOYU, Simon James Fong","~Rong_Fu2, ~GUO_XIAOYU1, ~Simon_James_Fong2","Stance Alignment, Contextual Offensive Language, Controllable Text Generation, Neural Dialogue Safety, Foundation Models, Societal Impact","alignment, fairness, safety, privacy, and societal considerations",ICLR 2026 Conference Withdrawn Submission,2026,https://openreview.net/pdf?id=6pmxBlGXyM,https://openreview.net/forum?id=6pmxBlGXyM,,
7pgAwaq6Rx,RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation,"Enabling robots to flexibly schedule and compose learned skills for novel long-horizon manipulation under diverse perturbations remains a core challenge. Early explorations with end-to-end VLA models show limited success, as these models struggle to generalize beyond the training distribution. Hierarchical approaches, where high-level planners generate subgoals for low-level policies, bring certain improvements but still suffer under complex perturbations, revealing limited capability in skill composition. However, existing benchmarks primarily emphasize task completion in long-horizon settings, offering little insight into compositional generalization, robustness, and the interplay between planning and execution.
To systematically investigate these gaps, we propose RoboHiMan, a hierarchical evaluation paradigm for compositional generalization in long-horizon manipulation. RoboHiMan introduces HiMan-Bench, a benchmark of atomic and compositional tasks under diverse perturbations, supported by a multi-level training dataset for analyzing progressive data scaling, and proposes three evaluation paradigms (vanilla, decoupled, coupled) that probe the necessity of skill composition and reveal bottlenecks in hierarchical architectures.
Experiments highlight clear capability gaps across representative models and architectures, pointing to directions for advancing models better suited to real-world long-horizon manipulation tasks.
Anonymous project website: https://robohiman.github.io/.",,,"Compositional Generalization, Long-horizon Manipulation, Benchmarking Robotics","applications to robotics, autonomy, planning",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=7pgAwaq6Rx,https://openreview.net/forum?id=7pgAwaq6Rx,,
7QlJcWwd14,ReasonAudio: Semantic Reasoning and Temporal Synchrony in Video–Text-to-Audio Generation,"The rapid advancement of video-text-to-audio (VT2A) diffusion models has enabled unprecedented audio generation conditioned on video and text, yet two major challenges remain: following complex semantic descriptions and achieving robust audio–visual synchronization. In this work, we propose ReasonAudio, an MLLM-empowered flow-matching generative model with stronger semantic and robust temporal alignment. To enhance semantic understanding, we 1) address the scarcity of semantically rich tri-modal (video–text–audio) annotations by constructing VGGSound-Think, a dataset enriched with acoustic hints and audio–visual relation descriptions, and 2) leverage MLLMs to understand multimodal conditions (video and text) by introducing learnable queries that bridge understanding and generation components. To tackle temporal alignment, we employ preference optimization (Flow-DPO, Flow-RWR) with synchronization feedback, aligning generative models with visual synchrony preferences. Extensive experiments demonstrate that ReasonAudio achieves state-of-the-art performance in VT2A generation, with substantial improvements in both semantic alignment and temporal synchronization. Moreover, evaluations on VGGSound-Think show that our model excels at reasoning over acoustic hints and following descriptions of audio–visual relations (e.g., object interactions and on-/off-screen attribution). The demo page is available at https://ReasonAudio.github.io.",,,Multimodal Large Language Models; Video-to-Audio Generation; Preference Optimization;,"applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=7QlJcWwd14,https://openreview.net/forum?id=7QlJcWwd14,,
7qXmJbjbl8,Attribute-Centric Representation Learning for Interpretable Crime Scene Analysis in Video Anomaly Detection,"Automatic crime scene analysis is an important application area for representation learning in Video Anomaly Detection (VAD). Effective interpretation of anomalous events requires models to learn rich, disentangled representations that capture fine-grained, crime-relevant attributes. However, widely used VAD datasets (e.g., UCA, CUVA) primarily offer coarse event-level labels and they lack attribute-level supervision often needed for modeling crime-specific behaviors. To bridge this gap, we propose an attribute-centric learning framework that explicitly conditions video representations on crime-causing attributes. We extend the UCA dataset with over 1.5M new attribute-centric annotations generated using carefully designed prompts and LLMs. These annotations enable supervised fine-tuning of a curated CLIP-based model, leading to more discriminative, attribute-aware video representations, and precise event captions. An LLM-based summarizer then distills these captions into context-rich explanations, facilitating interpretable scene understanding. Our approach answers three core questions in crime scene analysis: \textbf{What? When? How?} Extensive experiments show that the proposed representation learning framework yields significant improvements ($\approx 20\%\uparrow$) in attribute-centric crime classification accuracy and ($\approx 6.4\%\uparrow$) according to MMEval scores over the baselines. We further analyze and mitigate biases in MMEval to ensure robustness and fair evaluation. These results highlight the importance of attribute-conditioned representation learning for interpretable and reliable VAD.",,,"Crime Scene Analysis, Video Anomaly Detection, Explainable AI, Visual Language Reasoning",interpretability and explainable AI,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=7qXmJbjbl8,https://openreview.net/forum?id=7qXmJbjbl8,,
7WsivwyHrS,You Only Query Once: An Efficient Label-Only Membership Inference Attack,"As one of the privacy threats to machine learning models, the membership inference attack (MIA) tries to infer whether a given sample is in the original training set of a victim model by analyzing its outputs. Recent studies only use the predicted hard labels to achieve impressive membership inference accuracy. However, such label-only MIA approach requires very high query budgets to evaluate the distance of the target sample from the victim model's decision boundary.  
   We propose YOQO, a novel label-only attack to overcome the above limitation.YOQO aims at identifying a special area (called improvement area) around the target sample and crafting a query sample, whose hard label from the victim model can reliably reflect the target sample's membership. YOQO can successfully reduce the query budget from more than 1,000 times to only ONCE. Experiments demonstrate that YOQO is not only as effective as SOTA attack methods, but also performs comparably or even more robustly against many sophisticated defenses.","YUTONG WU, Han Qiu, Shangwei Guo, Jiwei Li, Tianwei Zhang","~YUTONG_WU3, ~Han_Qiu3, ~Shangwei_Guo1, ~Jiwei_Li1, ~Tianwei_Zhang1","Machine learning, Membership Inference Attack, Computer Vision","societal considerations including fairness, safety, privacy",ICLR 2024 poster,2024,https://openreview.net/pdf?id=7WsivwyHrS,https://openreview.net/forum?id=7WsivwyHrS,,
8FihPljvWf,Video-As-Prompt: Unified Semantic Control for Video Generation,"Unified, generalizable semantic control in video generation remains a critical open challenge. Existing methods either introduce artifacts by enforcing inappropriate pixel-wise priors from structure-based controls, or rely on non-generalizable, condition-specific finetuning or task-specific architectures. We introduce Video-As-Prompt (VAP), a new paradigm that reframes this problem as in-context generation. VAP leverages a reference video as a direct semantic prompt, guiding a frozen Video Diffusion Transformer (DiT) via a plug-and-play Mixture-of-Transformers (MoT) expert. This architecture prevents catastrophic forgetting and is guided by a temporally biased position embedding that eliminates spurious mapping priors for robust context retrieval. To power this approach and catalyze future research, we built VAP-Data, the largest dataset for this task with over 100K paired videos across 100 semantic conditions. As a single unified model, VAP sets a new state-of-the-art for open-source methods, achieving a 38.7\% user preference rate that rivals leading condition-specific commercial models. VAP's strong zero-shot generalization and support for various applications mark a significant advance toward general-purpose, controllable video generation.",,,"Video Generation, Controllable Video Generation, Video Dataset",generative models,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=8FihPljvWf,https://openreview.net/forum?id=8FihPljvWf,,
8mal7Q96Fc,Mitigating Classifier Dimensional Collapse via Random Masking in Federated Linear Probing,"Integrating a pre-trained model into federated learning (FL) is an emergent direction to facilitate the industrial deployment. Federated linear probing (FLP) is a practical paradigm that gains the communication efficiency from FL and generalization from pre-trained model, while still suffering from dimensional collapse that undermines its effectiveness. Dimensional collapse, originating from data heterogeneity, challenges the embedding space construction in FL, leading to suboptimal convergence and generalization. With a generalized frozen embedding extractor, FLP seems to be robust against dimensional collapse. However, in this paper, we emphasize that the dimensional collapse can also be represented in classifier construction, affecting the performance of the model. We propose FedRM to solve this problem, which randomly masks the dimension of the embedding and the classifier during the training to enforce the classifier to focus fairly on each dimension, guaranteeing diversity during decision generation. The simplicity of the method retains the communication efficiency of the FLP. We conduct empirical experiments to comprehensively evaluate the performance of FedRM. The results show FedRM achieves an overwhelming trade-off between efficiency and utility.",,,"federated learning, data heterogeneity, dimensional collapse, pre-trained model","other topics in machine learning (i.e., none of the above)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=8mal7Q96Fc,https://openreview.net/forum?id=8mal7Q96Fc,,
90UhF7e8jo,Goal Achievement Guided Exploration: Mitigating Premature Convergence in Reinforcement Learning,"Premature convergence to suboptimal policies remains a significant challenge in reinforcement learning (RL), particularly in tasks with sparse rewards or non-convex reward landscapes. Existing work usually utilizes reward shaping, such as curiosity-based internal rewards, to encourage exploring promising spaces. However, this may inadvertently introduce new local optima and impair the optimization for the actual target reward. To address this issue, we propose Goal Achievement Guided Exploration (GAGE), a novel approach that incorporates an agent's goal achievement as a dynamic criterion for balancing exploration and exploitation. GAGE adaptively adjusts the exploitation level based on the agent's current performance relative to an estimated optimal performance, thereby mitigating premature convergence. Extensive evaluations demonstrate that GAGE substantially improves learning outcomes across various challenging tasks by adapting convergence based on task success. Applicable to both continuous and discrete tasks, GAGE seamlessly integrates into existing RL frameworks, highlighting its potential as a versatile tool for enhancing exploration strategies in RL.","Shengchao Yan, Baohe Zhang, Joschka Boedecker, Wolfram Burgard","~Shengchao_Yan1, ~Baohe_Zhang1, ~Joschka_Boedecker1, ~Wolfram_Burgard3","reinforcement learning, exploration, deep reinforcement learning",reinforcement learning,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=90UhF7e8jo,https://openreview.net/forum?id=90UhF7e8jo,,
AEszIYnVos,NECromancer: Breathing Life into Skeletons via BVH Animation,"Motion tokenization is fundamental to the development of generalizable motion models, yet existing approaches remain restricted to species-specific skeletons, such as humans, thereby limiting their applicability across diverse morphologies. We present NECromancer (NEC), a universal motion tokenizer designed to operate on arbitrary BVH skeletons. NEC is built upon three core components: (1) an
Ontology-aWare Skeletal Graph EncOder (OwO), which leverages graph neural networks to encode structural priors extracted from BVH files—including joint-name semantics, rest-pose offsets, and skeletal topology—into robust skeletal embeddings; (2) a Topology-Agnostic Tokenizer (TAT), which compresses motion sequences into a universal, topology–invariant latent representation, thereby decoupling motion dynamics from morphology; and (3) the Unified BVH Universe (UvU), a large-scale dataset that consolidates BVH motions across heterogeneous skeletons (humans, quadrupeds, and other species), enabling systematic training and evaluation under diverse morphologies. Experimental results demonstrate that NEC achieves high-fidelity motion reconstruction with substantial compression, while effectively disentangling motion from skeletal structure. This capability supports a broad range of downstream tasks, including cross-species motion transfer, motion composition, denoising, generation (plug-and-play with any token-based generator; e.g., MoMask) and motion–text retrieval (via an OwO-based CLIP variant). By grounding motion representation in BVH animation while removing species-specific constraints, NEC establishes a principled framework for universal motion analysis and synthesis across varied morphologies.",,,Motion tokenization，Motion Generation，BVH Animation，Skeletal-Invariant Representation，Cross-Species Motion Transfer，Motion Compression,generative models,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=AEszIYnVos,https://openreview.net/forum?id=AEszIYnVos,,
AmKn0wA652,VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain Knowledge,"Current multimodal benchmarks often conflate reasoning with domain-specific knowledge, making it difficult to isolate and evaluate general reasoning abilities in non-expert settings. 
To address this, we introduce VisualPuzzles, a benchmark that targets visual reasoning while deliberately minimizing reliance on specialized knowledge. 
VisualPuzzles consists of diverse questions spanning five categories: algorithmic, analogical, deductive, inductive, and spatial reasoning. One major source of our questions is manually translated logical reasoning questions from the Chinese Civil Service Examination. Experiments show that VisualPuzzles requires significantly less intensive domain-specific knowledge and more complex reasoning compared to benchmarks like MMMU, enabling us to better evaluate genuine multimodal reasoning.
Evaluations show that state-of-the-art multimodal large language models consistently lag behind human performance on VisualPuzzles, and that strong performance on knowledge-intensive benchmarks does not necessarily translate to success on reasoning-focused, knowledge-light tasks.  
Additionally, reasoning enhancements such as scaling up inference compute (with ''thinking'' modes) yield inconsistent gains across models and task types, and we observe no clear correlation between model size and performance. We also found that models exhibit different reasoning and answering patterns on VisualPuzzles compared to benchmarks with heavier emphasis on knowledge. VisualPuzzles offers a clearer lens through which to evaluate reasoning capabilities beyond factual recall and domain knowledge.",,,"MLLM, benchmark, reasoning",datasets and benchmarks,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=AmKn0wA652,https://openreview.net/forum?id=AmKn0wA652,,
bgyWXX8HCk,Trustless Audits without Revealing Data or Models,"There is an increasing conflict between business incentives to hide models and data as trade secrets, and the societal need for algorithmic transparency. For example, a rightsholder who currently wishes to know whether their copyrighted works have been used during training must convince the model provider to allow a third party to audit the model and data. Finding a mutually agreeable third party is difficult, and the associated costs often make this approach impractical.

In this work, we show that it is possible to simultaneously allow model providers to keep their models and data secret while allowing other parties to trustlessly audit properties of the model and data. We do this by designing a protocol called ZkAudit in which model providers publish cryptographic commitments of datasets and model weights, alongside a zero-knowledge proof (ZKP) certifying that published commitments are derived from training the model. Model providers can then respond to audit requests by privately computing any function F of the dataset (or model) and releasing the output of F alongside another ZKP certifying the correct execution of F. To enable ZkAudit, we develop new methods of computing ZKPs for SGD on modern neural nets for recommender systems and image classification models capable of high accuracies on ImageNet. Empirically, we show it is possible to provide trustless audits of DNNs, including copyright, censorship, and counterfactual audits with little to no loss in accuracy.","Suppakit Waiwitlikhit, Ion Stoica, Yi Sun, Tatsunori Hashimoto, Daniel Kang","~Suppakit_Waiwitlikhit3, ~Ion_Stoica1, ~Yi_Sun3, ~Tatsunori_Hashimoto1, ~Daniel_Kang1","trustless audit, zero-knowledge proof","societal considerations including fairness, safety, privacy",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=bgyWXX8HCk,https://openreview.net/forum?id=bgyWXX8HCk,,
BlzBcWYmdB,Cross-modal Mitigation of Spurious Correlation for Prompt-tuning in VLMs with Causally Motivated Logic Alignment,"Recent studies have shown that pre-trained vision-language models can effectively adapt to diverse downstream tasks through parameter-efficient prompt tuning. Unfortunately, the tuned models can exploit spurious correlations during prediction, resulting in a failure to generalize to out-of-distribution test data, especially when the tuning dataset exhibits bias. How to achieve cross-modal mitigation of spurious correlations during prompt tuning of vision-language models remains an open question. In this paper, the challenging problem is tackled by leveraging the stable relationship between necessary and sufficient causal features and the corresponding label. On the one hand, we constrain the learning process of prompt by reinforcing the necessary and sufficient connection between the textual labels and textual features. On the other hand, the probability of necessity and sufficiency between the textual features and the filtered visual features is measured and maximized to enhance cross-modal feature alignment. By iteratively optimizing these two objectives, we can achieve cross-modal mitigation of spurious correlations because the logic equivalence between textual labels and visual features is bolstered. The theoretical analysis on generalization error indicates that our method can achieve a tighter generalization error bound than existing approaches. We evaluate the proposed method on several commonly adopted out-of-distribution datasets, and the empirical results demonstrate the superiority of our method over the state-of-the-art competitors.","Xueyang Tang, Song Guo, Xiaosong Ma, Haoxi Li, Jie ZHANG, Yue Yu","~Xueyang_Tang1, ~Song_Guo5, ~Xiaosong_Ma4, ~Haoxi_Li1, ~Jie_ZHANG18, ~Yue_Yu8","Vision-Language Models, Prompt Tuning, Spurious Correlations, Out-of-Distribution Generalization, Causality, Probability of Necessity and Sufficiency","other topics in machine learning (i.e., none of the above)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=BlzBcWYmdB,https://openreview.net/forum?id=BlzBcWYmdB,,
Bp0HBaMNRl,Differentiable Causal Discovery for Latent Hierarchical Causal Models,"Discovering causal structures with latent variables from observational data is a fundamental challenge in causal discovery. Existing methods often rely on constraint-based, iterative discrete searches, limiting their scalability for large numbers of variables. Moreover, these methods frequently assume linearity or invertibility, restricting their applicability to real-world scenarios. We present new theoretical results on the identifiability of non-linear latent hierarchical causal models, relaxing previous assumptions in the literature about the deterministic nature of latent variables and exogenous noise. Building on these insights, we develop a novel differentiable causal discovery algorithm that efficiently estimates the structure of such models. To the best of our knowledge, this is the first work to propose a differentiable causal discovery method for non-linear latent hierarchical models. Our approach outperforms existing methods in both accuracy and scalability. Furthermore, we demonstrate its practical utility by learning interpretable hierarchical latent structures from high-dimensional image data and demonstrate its effectiveness on downstream tasks such as transfer learning.","Parjanya Prajakta Prashant, Ignavier Ng, Kun Zhang, Biwei Huang","~Parjanya_Prajakta_Prashant1, ~Ignavier_Ng1, ~Kun_Zhang1, ~Biwei_Huang1","Differentiable causal discovery, causal representation learning, latent variable models, causal structure learning, causal identifiability",causal reasoning,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=Bp0HBaMNRl,https://openreview.net/forum?id=Bp0HBaMNRl,,
BydD1vNMCV,Statistical Inference for Deep Learning via Stochastic Modeling,"Deep learning has revolutionized big data analysis in modern data science, however, how to make statistical inference for deep neural networks remains largely unclear. To this end, we explore a stochastic 
variant of the deep neural network known as the stochastic neural network (StoNet). Firstly, we show that the StoNet falls into the framework of statistical modeling. It not only enables us to address fundamental issues in deep learning, such as structure interpretability and uncertainty quantification, but also provides with us a platform for transferring the theory and methods developed for linear models to the realm of deep learning. Specifically, we show how the sparse learning theory with the Lasso penalty can be adapted to deep neural networks (DNNs) from linear models; establish that the sparse StoNet is consistent in network structure selection; and provides a recursive method to quantify the prediction uncertainty for the Stonet. Furthermore, we extend this result to the DNN by its asymptotic equivalence with the StoNet, showing that consistent sparse deep learning can be obtained by training a DNN with an appropriate Lasso penalty. Additionally, we propose to remodel the last hidden layer output and the target output of a well-trained DNN model using a StoNet on the validation dataset, and then assess the prediction uncertainty of the DNN model via the Stonet. The proposed method has been compared with conformal inference on extensive examples, and numerical results suggests its superiority.","Yan Sun, Faming Liang","~Yan_Sun6, ~Faming_Liang1","Stochastic neural network, uncertainty quantification, nonlinear variable selection, stochastic gradient MCMC, imputation regularized-optimization","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=BydD1vNMCV,https://openreview.net/forum?id=BydD1vNMCV,,
c8IS4Xouqy,Topology-Informed Approaches to Enhanced Index Tracking,"We address the problem of cross-market index tracking, replicating the performance of a foreign benchmark using only domestic assets, a task particularly relevant for markets with limited access to international investments. We propose a novel optimization framework that incorporates a topology-informed regularization term to extract persistent structural patterns from time-series price data. Our method leverages topological alignment between markets to construct robust index-mimicking portfolios without requiring constituent-level information. We further introduce a cost-aware formulation that accounts for transaction costs and their compounding effects. Empirical results on real-world data show notable gains over traditional tracking methods in both accuracy and robustness. Our approach holds broader potential for general time-series decomposition and synthesis.",,,"Topological Data Analysis, Time-series synthesis, Time-Series Featurization, Quantitative Finance, Mimicking Portfolio",learning on time series and dynamical systems,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=c8IS4Xouqy,https://openreview.net/forum?id=c8IS4Xouqy,,
cEyj6ewRFZ,Nonparametric Teaching for Sequential Property Learners,"Determining the properties of sequence-structured data, e.g., the sentiment of a text, fundamentally requires learning the implicit relationship that maps sequences to their corresponding properties. This learning process is often expensive for sequential property learners like Recurrent Neural Networks (RNNs). To tackle this, we introduce a paradigm called **Re**current **N**eural **T**eaching (ReNT), which reinterprets the learning process through a novel nonparametric teaching lens. Specifically, the latter provides a theoretical framework for teaching implicitly defined (i.e., nonparametric) mappings via example selection. Such an implicit mapping is realized by a dense set of sequence-property pairs, with the ReNT teacher selecting a subset of them to facilitate faster convergence in RNN training. By analytically investigating the effect of sequence order on parameter-based gradient descent during training, and recasting the evolution of RNNs—driven by parameter updates—through functional gradient descent in nonparametric teaching, we reveal *for the first time* that teaching sequential property learners (i.e., RNNs) is consistent with teaching order-aware nonparametric learners. These new findings readily prompt ReNT to improve the learning efficiency of the sequential property learner, achieving substantial cuts in training time for sequence-level (-32.77% to -46.39%) and element-level (-36% to -39.17%) tasks, while still preserving its generalization performance.",,,"Nonparametric Teaching, Sequential Property Learning, Functional Gradient Descent","other topics in machine learning (i.e., none of the above)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=cEyj6ewRFZ,https://openreview.net/forum?id=cEyj6ewRFZ,,
CgkAGcp9lk,Compositional Search of Stable Crystalline Structures in Multi-Component Alloys Using Generative Diffusion Models,"Exploring the vast composition space of multi-component alloys presents a challenging task for both ab initio (first principles) and experimental methods due to the time-consuming procedures involved. This ultimately impedes the discovery of novel, stable materials that may display exceptional properties. Here, the Crystal Diffusion Variational Autoencoder (CDVAE) model is adapted to characterize the stable compositions of a well studied multi-component alloy, NiFeCr, with two distinct crystalline phases known to be stable across its compositional space. To this end, novel extensions to CDVAE were proposed, enhancing the model’s ability to reconstruct configurations from their latent space within the test set by approximately 30% . A fact that increases a model’s probability of discovering new materials when dealing with various crystalline structures. Afterwards, the new model is applied for materials generation, demonstrating excellent agreement in identifying stable configurations within the ternary phase space when compared to first principles data. Finally, a computationally efficient framework for inverse design is proposed, employing Molecular Dynamics (MD) simulations of multi- component alloys with reliable interatomic potentials, enabling the optimization of materials property across the phase space.","Grzegorz Kaszuba, Amirhossein Naghdi Dorabati, Stefanos Papanikolaou, Andrzej Jaszkiewicz, Piotr Sankowski","~Grzegorz_Kaszuba1, ~Amirhossein_Naghdi_Dorabati1, ~Stefanos_Papanikolaou2, andrzej.jaszkiewicz@put.poznan.pl, ~Piotr_Sankowski1","Multi-Component Alloys, Generative Diffusion Models, Composition Search, Inverse Design",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=CgkAGcp9lk,https://openreview.net/forum?id=CgkAGcp9lk,,
cKAUvMePUN,Exploring Effective Stimulus Encoding via Vision System Modeling for Visual Prostheses,"Visual prostheses are potential devices to restore vision for blind people, which highly depends on the quality of stimulation patterns of the implanted electrode array. However, existing processing frameworks prioritize the generation of stimulation while disregarding the potential impact of restoration effects and fail to assess the quality of the generated stimulation properly. In this paper, we propose for the first time an end-to-end visual prosthesis framework (StimuSEE) that generates stimulation patterns with proper quality verification using V1 neuron spike patterns as supervision. StimuSEE consists of a retinal network to predict the stimulation pattern, a phosphene model, and a primary vision system network (PVS-net) to simulate the signal processing from the retina to the visual cortex and predict the firing rate of V1 neurons. Experimental results show that the predicted stimulation shares similar patterns to the original scenes, whose different stimulus amplitudes contribute to a similar firing rate with normal cells. Numerically, the predicted firing rate and the recorded response of normal neurons achieve a Pearson correlation coefficient of 0.78.","Chuanqing Wang, Di Wu, Chaoming Fang, Jie Yang, Mohamad Sawan","~Chuanqing_Wang2, ~Di_Wu10, ~Chaoming_Fang1, ~Jie_Yang16, ~Mohamad_Sawan1","Visual prostheses, Spiking recurrent neural network, Dynamic vision sensor, Biological phosphene model",applications to neuroscience & cognitive science,ICLR 2024 poster,2024,https://openreview.net/pdf?id=cKAUvMePUN,https://openreview.net/forum?id=cKAUvMePUN,,
cMEnMVvMw9,Token-Importance Guided Direct Preference Optimization,"Aligning Large Language Models (LLMs) with human preferences is crucial for safe and effective AI interactions. While popular methods like Direct Preference Optimization (DPO) have simplified alignment, they remain sensitive to data noise and overlook the differential importance of individual tokens. Existing token-level approaches often rely on probability prediction or simplistic weighting schemes to obtain token importance, which still cannot fully address these issues. To solve this problem, we propose the Token-Importance Guided Direct Preference Optimization (TI-DPO), a framework that achieves fine-grained semantic control through two synergistic innovations. 
First, we propose a novel hybrid weighting mechanism that combines gradient attribution with a Gaussian prior, ensuring both the accuracy and robustness of token importance scores. Second, we employ a triplet loss to provide structured guidance for the optimization, explicitly guiding model outputs to approach preferred responses and diverge from non-preferred ones. Experimental results show that TI-DPO achieves higher accuracy and stronger generative diversity, providing more stable and computationally efficient solutions compared with DPO and other RLHF methods.",,,"LLMs, RLHF, DPO, Human Preference Alignment, Token-lmportance, Triplet Loss","foundation or frontier models, including LLMs",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=cMEnMVvMw9,https://openreview.net/forum?id=cMEnMVvMw9,,
COO51g41Q4,Synergistic Patch Pruning for Vision Transformer: Unifying Intra- & Inter-Layer Patch Importance,"The Vision Transformer (ViT) has emerged as a powerful architecture for various computer vision tasks. Nonetheless, this comes with substantially heavier computational costs than Convolutional Neural Networks (CNNs). The attention mechanism in ViTs, which integrates information from different image patches to the class token ([CLS]), renders traditional structured pruning methods used in CNNs unsuitable. To overcome this issue, we propose SynergisTic pAtch pRuning (STAR) that unifies intra-layer and inter-layer patch importance scoring. Specifically, our approach combines a) online evaluation of intra-layer importance for the [CLS] and b) offline evaluation of the inter-layer importance of each patch. The two importance scores are fused by minimizing a weighted average of Kullback-Leibler (KL) Divergences and patches are successively pruned at each layer by maintaining only the top-k most important ones. Unlike prior art that relies on manual selection of the pruning rates at each layer, we propose an automated method for selecting them based on offline-derived metrics. We also propose a variant that uses these rates as weighted percentile parameters (for the layer-wise normalized scores), thus leading to an alternate adaptive rate selection technique that is input-based. Extensive experiments demonstrate the significant acceleration of the inference with minimal performance degradation. For instance, on the ImageNet dataset, the pruned DeiT-Small reaches a throughput of 4,256 images/s, which is over 66\% higher than the much smaller (unpruned) DeiT-Tiny model, while having a substantially higher accuracy (+6.8\% Top-1 and +3.1\% Top-5).","Yuyao Zhang, Lan Wei, Nikolaos Freris","~Yuyao_Zhang4, ~Lan_Wei2, ~Nikolaos_Freris2","Vision Transformers, Model compression, Dynamic pruning","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 poster,2024,https://openreview.net/pdf?id=COO51g41Q4,https://openreview.net/forum?id=COO51g41Q4,,
Cox6AaRyan,Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception,"Multimodal Large Language Models (MLLMs) require high-resolution visual information to perform fine-grained perception, yet processing entire high-resolution images is computationally prohibitive. 
While recent methods leverage a Region-of-Interest (RoI) mechanism to focus on salient areas, they typically present a difficult trade-off: training-based approaches depend on large-scale annotated datasets, while training-free methods that utilize the model's internal attention are computationally inefficient and less accurate, requiring either multi-pass prefill stages or reliance on the slow auto-regressive decoding process.
In this paper, we propose an efficient, annotation-free Self-Distilled Region Proposal Network (SD-RPN) that resolves this trade-off. The SD-RPN is built around a pipeline that transforms the noisy attention maps from the MLLM's middle layers into high-quality pseudo-RoI labels by explicitly denoising the signal and resolving ambiguity. We use these labels to train a lightweight Region Proposal Network (RPN) that learns a more precise localization. This RPN is also highly efficient, predicting the RoI in a single forward pass using features from the MLLM's middle layers, decoupling RoI identification from the auto-regressive generation and avoiding costly multi-pass operations.
To validate our approach, we integrate the framework into the LLaVA-1.5 architecture. Despite being trained on only a few (e.g. 10K) question-answer pairs, our method demonstrates exceptional data efficiency and generalization, achieving over a 10\% absolute accuracy improvement on unseen benchmarks, including TextVQA, DocVQA, and V-Star. Our work presents a practical and scalable solution for enhancing the fine-grained perception of MLLMs without requiring costly supervision or full model fine-tuning.",,,"MLLM, Self-Distillation, Fine-Grained Perception","foundation or frontier models, including LLMs",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=Cox6AaRyan,https://openreview.net/forum?id=Cox6AaRyan,,
cWHonXThtM,Knowledge Distillation with Multi-granularity Mixture of Priors for Image Super-Resolution,"Knowledge distillation (KD) is a promising yet challenging model compression approach that transmits rich learning representations from robust but resource-demanding teacher models to efficient student models. Previous methods for image super-resolution (SR) are often tailored to specific teacher-student architectures, limiting their potential for improvement and hindering broader applications. This work presents a novel KD framework for SR models, the multi-granularity Mixture of Priors Knowledge Distillation (MiPKD), which can be universally applied to a wide range of architectures at both feature and block levels. The teacher’s knowledge is effectively integrated with the student's feature via the Feature Prior Mixer, and the reconstructed feature propagates dynamically in the training phase with the Block Prior Mixer. Extensive experiments illustrate the significance of the proposed MiPKD technique.","Simiao Li, Yun Zhang, Wei Li, Hanting Chen, Wenjia Wang, Bingyi Jing, Shaohui Lin, Jie Hu","~Simiao_Li2, ~Yun_Zhang5, ~Wei_Li60, ~Hanting_Chen1, ~Wenjia_Wang2, ~Bingyi_Jing1, ~Shaohui_Lin1, ~Jie_Hu8","Image Super-Resolution, Knowledge Distillation, Model Compression","applications to computer vision, audio, language, and other modalities",ICLR 2025 Spotlight,2025,https://openreview.net/pdf?id=cWHonXThtM,https://openreview.net/forum?id=cWHonXThtM,,
CyKVrhNABo,Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences,"Submissions are rising fast, and venues use different rules, data formats, and update times. As a result, signals of progress get split across places, and key moments (rebuttal, discussion, final decision) are easy to miss, making analysis hard. We present Paper Copilot, a system and scalable peer-review archive that pulls data from official sites, OpenReview, and opt-in forms into a single, standardized, versioned record with timestamps. This lets us track trends over time and compare venues, institutions, and countries in a consistent way. Using the archive for ICLR 2024/2025, we see larger score changes after rebuttal for higher-tier papers, reviewer agreement that dips during active discussion and tightens by the end, and in 2025 a sharper, mean-score–driven assignment of tiers with lower decision uncertainty than expected at that scale. We also state simple rules for ethics—clear sourcing and consent, privacy protection, and limits on use for closed venues. Together, we provide a clear, reusable base for tracking AI/ML progress, and, with this data, enable validation, benchmarking, and otherwise hard-to-run studies.",,,"peer review, review dynamic, aiml, community","infrastructure, software libraries, hardware, systems, etc.",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=CyKVrhNABo,https://openreview.net/forum?id=CyKVrhNABo,,
d159zNCmOq,From Static to Dynamic: Leveraging Implicit Behavioral Models to Facilitate Transition in Offline-to-Online Reinforcement Learning,"Transitioning reinforcement learning (RL) models from offline training environments to dynamic online settings faces critical challenges because of the distributional shift and the model inability in effectively adapting to new, unseen scenarios. This work proposes the \textbf{B}ehavior \textbf{A}daption \textbf{Q}-Learning (BAQ), a novel framework facilitating smoother transitions in offline-to-online RL. BAQ strategically leverages the implicit behavioral model to imitate and adapt behaviors of offline datasets, enabling the model to handle out-of-distribution state-action pairs more effectively during its online deployment. The key to our approach is the integration of a composite loss function that not only mimics the offline data-driven policy but also dynamically adjusts to new experiences encountered online. This dual-focus mechanism enhances the model's adaptability and robustness, reducing Q-value estimation errors and improving the overall learning efficiency. Extensive empirical evaluations demonstrate that BAQ significantly outperforms existing methods, achieving enhanced adaptability and reduced performance degradation in diverse RL settings. Our framework sets a new standard for offline-to-online RL, offering a robust solution for applications requiring reliable transitions from theoretical training to practical, real-world execution.","Lipeng Zu, Xiaonan Zhang, Yukun Yuan, Shayok Chakraborty","~Lipeng_Zu1, ~Xiaonan_Zhang1, ~Yukun_Yuan1, ~Shayok_Chakraborty1","Offline-to-Online Reinforcement Learning, Behavioral Adaptation, Q-value Estimation, Priority Sampling Strategy",reinforcement learning,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=d159zNCmOq,https://openreview.net/forum?id=d159zNCmOq,,
dAn82lpLx4,The Agent's Marathon: Probing the Limits of Endurance in Long-Horizon Tasks,"Large Language Model (LLM) agents, augmented with diverse tools, have shown impressive progress in domains such as scientific discovery and enterprise automation. Yet they remain brittle in long-horizon tasks that require extended sequences of interactions, where performance often deteriorates rapidly. Existing benchmarks provide only partial coverage of this challenge: manual or crowdsourced tasks are too short, tool-use benchmarks emphasize breadth over depth, and web-based evaluations rely on emergent rather than controllable complexity. To fill this gap, we introduce TaskWeaver, a rule-based, controllable platform for generating benchmark tasks with precisely adjustable difficulty and horizon length. At its core, TaskWeaver abstracts all tool use as file-read operations. This design choice removes superficial API complexities, allowing us to directly probe an agent’s core ability to reason and integrate intermediate results over long, dependent sequences. We instantiate the framework across three domains: document understanding and navigation, multi-modal information integration, and executable code analysis. Each domain probes a complementary aspect of agentic reasoning, and together they form a unified benchmark, LORE (Long-horizon Reasoning Evaluation). Empirical results show that even for the strongest models we tested, performance degrades significantly as task length and per-step complexity increase. Specifically, their accuracy approaches zero on tasks exceeding 120 steps, and on more challenging variants, performance collapses in fewer than 15 steps. These findings highlight long-horizon robustness as a central open challenge for future agent development.",,,"natural language model, agent, benchmark",datasets and benchmarks,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=dAn82lpLx4,https://openreview.net/forum?id=dAn82lpLx4,,
dfxrltDpBe,Can Large Language Models Really Recognize Your Name?,"Large language models (LLMs) are increasingly being used to protect personal user data. These privacy solutions often assume that LLMs can reliably detect named entities and personally identifiable information (PII). In this paper, we challenge that assumption by revealing how LLMs can regularly overlook broad types of sensitive names even in short text snippets due to ambiguity in the contexts. We construct AMBENCH, a benchmark dataset of seemingly ambiguous yet real entity names designed around the name regularity bias phenomenon and embedded within concise text snippets containing benign prompt injections. Our experiments with state-of-the-art LLMs and specialized PII detection tools show that the recall of AMBENCH names drops by 20--40\% compared to more recognizable names. AMBENCH names are also four times more likely to be ignored in supposedly privacy-preserving LLM-powered text analysis tools adopted in the industry. Our findings showcase blind spots in current LLM-based privacy defenses and call for a systematic investigation into their privacy failure modes.",,,"large language model, privacy, personally identifiable information, named entity detection","alignment, fairness, safety, privacy, and societal considerations",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=dfxrltDpBe,https://openreview.net/forum?id=dfxrltDpBe,,
DjeQ39QoLQ,Robustifying State-space Models for Long Sequences via Approximate Diagonalization,"State-space models (SSMs) have recently emerged as a framework for learning long-range sequence tasks. An example is the structured state-space sequence (S4) layer, which uses the diagonal-plus-low-rank structure of the HiPPO initialization framework. However, the complicated structure of the S4 layer poses challenges; and, in an effort to address these challenges, models such as S4D and S5 have considered a purely diagonal structure. This choice simplifies the implementation, improves computational efficiency, and allows channel communication. However, diagonalizing the HiPPO framework is itself an ill-posed problem. In this paper, we propose a general solution for this and related ill-posed diagonalization problems in machine learning. We introduce a generic, backward-stable ``perturb-then-diagonalize'' (PTD) methodology, which is based on the pseudospectral theory of non-normal operators, and which may be interpreted as the approximate diagonalization of the non-normal matrices defining SSMs. Based on this, we introduce the S4-PTD and S5-PTD models. Through theoretical analysis of the transfer functions of different initialization schemes, we demonstrate that the S4-PTD/S5-PTD initialization strongly converges to the HiPPO framework, while the S4D/S5 initialization only achieves weak convergences. As a result, our new models show resilience to Fourier-mode noise-perturbed inputs, a crucial property not achieved by the S4D/S5 models. In addition to improved robustness, our S5-PTD model averages 87.6% accuracy on the Long-Range Arena benchmark, demonstrating that the PTD methodology helps to improve the accuracy of deep learning models.","Annan Yu, Arnur Nigmetov, Dmitriy Morozov, Michael W. Mahoney, N. Benjamin Erichson","~Annan_Yu1, ~Arnur_Nigmetov1, ~Dmitriy_Morozov1, ~Michael_W._Mahoney1, ~N._Benjamin_Erichson1","state-space models, sequence models, Long-Range Arena, recurrent neural networks","general machine learning (i.e., none of the above)",ICLR 2024 spotlight,2024,https://openreview.net/pdf?id=DjeQ39QoLQ,https://openreview.net/forum?id=DjeQ39QoLQ,,
dTkqaCKLPp,SCOPE: A Self-supervised Framework for Improving Faithfulness in Conditional Text Generation,"Large Language Models (LLMs), when used for conditional text generation, often produce hallucinations, i.e., information that is unfaithful or not grounded in the input context. This issue arises in typical conditional text generation tasks, such as text summarization and data-to-text generation, where the goal is to produce fluent text based on contextual input. When fine-tuned on specific domains, LLMs struggle to provide faithful answers to a given context, often adding information or generating errors. One underlying cause of this issue is that LLMs rely on statistical patterns learned from their training data. This reliance can interfere with the model's ability to stay faithful to a provided context, leading to the generation of ungrounded information. We build upon this observation and introduce a novel self-supervised method for generating a training set of unfaithful samples. We then refine the model using a training process that encourages the generation of grounded outputs over unfaithful ones, drawing on preference-based training. Our approach leads to significantly more grounded text generation, outperforming existing self-supervised techniques in faithfulness, as evaluated through automatic metrics, LLM-based assessments, and human evaluations.","Song Duong, Florian Le Bronnec, Alexandre Allauzen, Vincent Guigue, Alberto Lumbreras, Laure Soulier, Patrick Gallinari","~Song_Duong1, ~Florian_Le_Bronnec1, ~Alexandre_Allauzen1, ~Vincent_Guigue1, ~Alberto_Lumbreras1, ~Laure_Soulier1, ~Patrick_Gallinari2","faithfulness, hallucination, conditional text generation, natural language processing, large language models","applications to computer vision, audio, language, and other modalities",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=dTkqaCKLPp,https://openreview.net/forum?id=dTkqaCKLPp,,
DUfwD5yiN4,Exact Distributed Structure-Learning for Bayesian Networks,"Learning the structure of a Bayesian network is currently practical for only a limited number of variables. Existing distributed learning approaches approximate the true structure. We present an exact distributed structure-learning algorithm to find a P-map for a set of random variables. First, by using conditional independence, the variables are divided into sets $\X_1,\ldots,\X_I$ such that for each $\X_i$, the presence and absence of edges that are adjacent with any interior node (a node that is not in any other $\X_j, j\neq i$) can be correctly identified by learning the structure of $\X_i$ separately without using the information of the variables other than $\X_i$. Second, constraint or score-based structure learners are employed to learn the P-map of $\X_i$, in a decentralized way. Finally, the separately learned structures are appended by checking a conditional independence test on the boundary nodes (those that are in at least two $\X_i$'s). The result is proven to be a P-map. This approach allows for a significant reduction in computation time and opens the door for structure learning for a ``giant'' number of variables.","Hamid Kalantari, Mohammad Hossein Roohi, Pouria Ramazi","~Hamid_Kalantari1, ~Mohammad_Hossein_Roohi1, ~Pouria_Ramazi1","Bayesian networks, Causality, Structure learning, Distributed learning",learning theory,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=DUfwD5yiN4,https://openreview.net/forum?id=DUfwD5yiN4,,
DUtfVs1xxD,Uni-PrevPredMap: Extending PrevPredMap to a Unified Framework of Prior-Informed Modeling for Online Vectorized HD Map Construction,"Safety constitutes a foundational imperative for autonomous driving systems, necessitating maximal incorporation of accessible prior information. This study establishes that temporal perception buffers and cost-efficient high-definition (HD) maps inherently form complementary prior sources for online vectorized HD map construction. We present Uni-PrevPredMap, a unified prior-informed framework systematically integrating previous predictions with corrupted HD maps. Our framework introduces a tri-mode paradigm maintaining operational consistency across non-prior, temporal-prior, and temporal-map-fusion modes. This tri-mode paradigm simultaneously decouples the framework from ideal map assumptions while ensuring robust performance in both map-present and map-absent scenarios. Additionally, we develop a tile-indexed 3D vectorized global map processor enabling efficient 3D prior data refreshment, compact storage, and real-time retrieval. Uni-PrevPredMap achieves state-of-the-art map-absent performance across established online vectorized HD map construction benchmarks. When provided with corrupted HD maps, it exhibits robust capabilities in error-resilient prior fusion, empirically confirming the synergistic complementarity between temporal predictions and imperfect map data. Code is available in supplementary materials.",,,"online vectorized HD map construction, prior-informed modeling, unified framework","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=DUtfVs1xxD,https://openreview.net/forum?id=DUtfVs1xxD,,
dYaeDrazj5,From Images to Connections: Can DQN with GNNs learn the Strategic Game of Hex?,"The gameplay of strategic board games such as chess, Go and Hex is often characterized by combinatorial, relational structures---capturing distinct interactions and non-local patterns---and not just images. Nonetheless, most common self-play reinforcement learning (RL) approaches simply approximate policy and value functions using convolutional neural networks (CNN).
A key feature of CNNs, is their relational inductive biases towards locality and translational invariance. In contrast, graph neural networks (GNN) can encode more complicated and distinct relational structures. Hence, we investigate the crucial question: Can GNNs, with their ability to encode complex connections, replace CNNs in self-play reinforcement learning? To this end, we do a comparison with Hex---an abstract yet strategically rich board game---serving as our experimental platform. Our findings reveal
that GNNs excel at dealing with long range dependency situations in game states and are less prone to overfitting, but also showing a reduced proficiency in discerning local patterns. This suggests a potential paradigm shift, signaling the use of game-specific structures to reshape self-play reinforcement learning.","Yannik Keller, Jannis Blüml, Gopika Sudhakaran, Kristian Kersting","~Yannik_Keller1, ~Jannis_Blüml1, ~Gopika_Sudhakaran1, ~Kristian_Kersting1","Self-play Reinforcement Learning, Graph Neural Networks, Hex, Long Range Dependency Problems, Board games",reinforcement learning,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=dYaeDrazj5,https://openreview.net/forum?id=dYaeDrazj5,,
e5r5j8SiSS,E-DDPG: Dual-Objective Deep Deterministic Policy Gradient for MRI Acceleration and Disease Classification,"Long acquisition times remain a major challenge in clinical MRI, where a fundamental trade-off exists between the acceleration achieved through undersampling and the diagnostic utility of the reconstructed images. We cast the problem of acquiring MRI data within a fixed time budget as a discrete reinforcement learning (RL) task and propose an algorithm based on Deep Deterministic Policy Gradient, referred to as E-DDPG. E-DDPG jointly optimizes sampling patterns, image reconstruction quality, and diagnostic accuracy. We introduces three key innovations: (1) a composite reward function that simultaneously encourages cross-entropy reduction, structural similarity improvement, and decrease in predictive entropy; (2) a percentile-based replay buffer that diversifies learning by equally sampling low- and high-value transitions; and (3) integration of the Straight-Through Gumbel-Softmax mechanism to preserve end-to-end differentiability while enabling discrete action selection. We evaluate E-DDPG against state-of-the-art RL-based methods and ablation variants on the fastMRI/fastMRI+ knee datasets at acceleration factors of 4X, 8X, and 10X, demonstrating its superior performance and validating the effectiveness of each proposed component.",,,"Magnetic Resonance Imaging, Reinforcement Learning, Disease Diagnosis, Sampling Strategy",reinforcement learning,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=e5r5j8SiSS,https://openreview.net/forum?id=e5r5j8SiSS,,
e7AUJpP8bV,PAD: Personalized Alignment of LLMs at Decoding-time,"Aligning with personalized preferences, which vary significantly across cultural, educational, and political differences, poses a significant challenge due to the computational costs and data demands of traditional alignment methods. In response, this paper presents Personalized Alignment at Decoding-time (PAD), a novel framework designed to align LLM outputs with diverse personalized preferences during the inference phase, eliminating the need for additional training. By introducing a unique personalized reward modeling strategy, this framework decouples the text generation process from personalized preferences, facilitating the generation of generalizable token-level personalized rewards. The PAD algorithm leverages these rewards to guide the decoding process, dynamically tailoring the base model’s predictions to personalized preferences. Extensive experimental results demonstrate that PAD not only outperforms existing training-based alignment methods in terms of aligning with diverse preferences but also shows significant generalizability to preferences unseen during training and scalability across different base models. This work advances the capability of LLMs to meet user needs in real-time applications, presenting a substantial step forward in personalized LLM alignment.","Ruizhe Chen, Xiaotian Zhang, Meng Luo, Wenhao Chai, Zuozhu Liu","~Ruizhe_Chen1, ~Xiaotian_Zhang1, ~Meng_Luo2, ~Wenhao_Chai1, ~Zuozhu_Liu1","Alignment, personalization","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=e7AUJpP8bV,https://openreview.net/forum?id=e7AUJpP8bV,,
EcbUaXJb9s,MARWA: Multi-agent retrieval-augmented framework for reliable bioinformatics workflow automation,"The rapid growth of multi-omics data has driven the expansion of bioinformatics analysis tools. Common bioinformatics tasks often rely on workflows, which link multiple tools into structured pipelines for reproducibility and scalability. Yet, building workflows manually is slow and error-prone, motivating efforts toward automation. However, bioinformatics workflow automation remains difficult due to the need to clarify vague analytical objectives, coordinate heterogeneous tools, and generate intricate tool commands. Despite the potential of large language models (LLMs) to aid bioinformatics workflow recommendation through advanced semantic understanding and logical reasoning, current agent frameworks often rely on one-shot generation, weak tool retrieval solution, and limited evaluation scheme, resulting in fragile workflow automation. We propose MARWA, a Multi-Agent Retrieval-augmented framework for reliable bioinformatics Workflow Automation. The framework emphasizes a step-by-step generation process with error handling at each stage to ensure robustness. We introduce a retrieval-augmented framework to strengthen tool command accuracy, which incorporates multi-perspective LLM-augmented descriptions and employs contrastive learning. We further design a two-stage evaluation framework, combining expert-verified execution on 40 curated tasks with large-scale benchmarking on 2,270 tasks using LLM-based evaluation. Our experiments demonstrate that MARWA consistently outperforms baselines in pass rate, workflow quality and scalability. Our work provides a foundation for trustworthy bioinformatics workflow automation. Project Page: https://anonymous.4open.science/r/MARWA-7D30.",,,Bioinformatics; Workflow Automation; Multi-Agent Systems; Retrieval-Augmented Generation; Large Language Models,"applications to physical sciences (physics, chemistry, biology, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=EcbUaXJb9s,https://openreview.net/forum?id=EcbUaXJb9s,,
EJ680UQeZG,Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers,"We introduce an output layer for neural networks that ensures satisfaction of convex constraints. Our approach, $\Pi$net, leverages operator splitting for rapid and reliable projections in the forward pass, and the implicit function theorem for backpropagation. We deploy $\Pi$net as a feasible-by-design optimization proxy for parametric constrained optimization problems and obtain modest-accuracy
solutions faster than traditional solvers when solving a single problem, and significantly faster for a batch of problems. 
We surpass state-of-the-art learning approaches by orders of magnitude in terms of training time, solution quality, and robustness to hyperparameter tuning, while maintaining similar inference times. Finally, we tackle multi-vehicle motion planning with non-convex trajectory preferences and provide $\Pi$net as a GPU-ready package implemented in JAX.",,,"hard constrained neural networks, network architecture, implicit layers, operator splitting, optimization",optimization,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=EJ680UQeZG,https://openreview.net/forum?id=EJ680UQeZG,,
EO6WtJ0q6G,Do Large Language Models Know What They Are Capable Of?,"We investigate whether large language models (LLMs) can predict whether they will succeed on a given task, and whether their predictions improve as they progress through multi-step tasks. We also investigate whether LLMs can learn from in-context experiences to make better decisions about whether to pursue a task in scenarios where failure is costly. All LLMs we tested are overconfident, but most predict their success with better-than-random discriminatory power. We find that newer and larger LLMs generally do not have greater discriminatory power. On multi-step agentic tasks, the overconfidence of several frontier LLMs worsens as they progress through the tasks, and reasoning LLMs perform comparable to or worse than non-reasoning LLMs. With in-context experiences of failure, most LLMs only slightly reduce their overconfidence, though in a resource acquisition scenario several LLMs (Claude Sonnet models and GPT-4.5) improve their performance by increasing their risk aversion. These results suggest that current LLM agents are hindered by their lack of awareness of their own capabilities. We discuss the implications of LLMs' awareness of their capabilities for AI misuse and misalignment risks.",,,"LLM Calibration, Decision Making, Overconfidence, In-context learning, LLM Agents, LLM self-knowledge, AI Safety","foundation or frontier models, including LLMs",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=EO6WtJ0q6G,https://openreview.net/forum?id=EO6WtJ0q6G,,
ERv8ptegFi,"GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS","Multi-agent learning algorithms have been successful at generating superhuman planning in various games but have had limited impact on the design of deployed multi-agent planners. A key bottleneck in applying these techniques to multi-agent planning is that they require billions of steps of experience. To enable the study of multi-agent planning at scale, we present GPUDrive, a GPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine capable of generating over a million simulation steps per second. Observation, reward, and dynamics functions are written directly in C++, allowing users to define complex, heterogeneous agent behaviors that are lowered to high-performance CUDA. Despite these low-level optimizations, GPUDrive is fully accessible through Python, offering a seamless and efficient workflow for multi-agent, closed-loop simulation. Using GPUDrive, we train reinforcement learning agents on the Waymo Open Motion Dataset, achieving efficient goal-reaching in minutes and scaling to thousands of scenarios in hours. We open-source the code and pre-trained agents at \url{www.github.com/Emerge-Lab/gpudrive}.","Saman Kazemkhani, Aarav Pandya, Daphne Cornelisse, Brennan Shacklett, Eugene Vinitsky","~Saman_Kazemkhani1, ~Aarav_Pandya1, ~Daphne_Cornelisse1, ~Brennan_Shacklett1, ~Eugene_Vinitsky1","Simulation, benchmark, multi-agent reinforcement learning, autonomous vehicles, planning",datasets and benchmarks,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=ERv8ptegFi,https://openreview.net/forum?id=ERv8ptegFi,,
EURAfiUpVJ,MARS-SQL: A Multi-Agent Reinforcement Learning Framework for Text-to-SQL,"Translating natural language to SQL remains a significant challenge for complex queries requiring environmental interaction and self-correction. To address this, we introduce MARS-SQL, a novel multi-agent framework that combines principled task decomposition and interactive reinforcement learning (RL). Our system comprises three specialized agents: a Grounding Agent for schema linking, a Generation Agent for query generation, and a Validation Agent for final selection. The core of our framework is the Generator agent, which is trained via a multi-turn RL policy. Adopting a ReAct-style Think-Act-Observe loop, the agent iteratively generates thoughts, executes SQL actions against a live database, and revises its strategy based on execution feedback, enabling dynamic, stateful reasoning and self-correction. At inference time, we generate multiple interaction trajectories to explore diverse reasoning paths. The Verifier agent, then selects the optimal trajectory by modeling verification as a next-token prediction task and choosing the solution with the highest generation probability. This structured workflow, which pipelines specialized agents and combines interactive RL for generation with generative modeling for verification, proves highly effective for robust and accurate SQL generation. Experiments show that **MARS-SQL** achieves state-of-the-art Execution Accuracy of 77.84\% on the BIRD dev set and 89.75\% on the Spider test set.",,,"Text2SQL, LLM, Reinforcement Learning, Multi-Agent","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=EURAfiUpVJ,https://openreview.net/forum?id=EURAfiUpVJ,,
fBlHaSGKNg,Unleashing the Power of Annotation: Enhancing Semi-Supervised Learning through Unsupervised Sample Selection,"With large volumes of unlabeled data and limited annotation budgets, Semi-Supervised Learning (SSL) has become a preferred approach in many deep learning tasks. However, most previous studies have primarily focused on  utilizing labeled and unlabeled data for model training to improve performance, while the efficient selection of samples for annotation under budgetary constraints has often been overlooked.To fill this gap, we propose an efficient sample selection methodology named Unleashing the Power of Annotation (UPA). By adopting a modified Frank-Wolfe algorithm to minimizing a novel criterion $\alpha$-Maximum Mean Discrepancy ($\alpha$-MMD), UPA selects a representative and diverse subset for annotation from the unlabeled data. Furthermore, we demonstrate that minimizing $\alpha$-MMD enhances the generalization ability of low-budget learning. Experiments show that UPA consistently improves the performance of several popular SSL methods, surpassing various prevailing Active Learning (AL) and Semi-Supervised Active Learning (SSAL) methods even under constrained annotation budgets.","Qian Shao, Jiangrui Kang, Qiyuan Chen, Hongxia Xu, Yiwen Cao, JIAJUAN LIANG, Jian Wu","~Qian_Shao2, ~Jiangrui_Kang1, ~Qiyuan_Chen1, ~Hongxia_Xu1, ~Yiwen_Cao2, ~JIAJUAN_LIANG1, ~Jian_Wu6","semi-supervised learning, unsupervised sample selection","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=fBlHaSGKNg,https://openreview.net/forum?id=fBlHaSGKNg,,
fDZumshwym,Leveraging Hierarchical Feature Sharing for Efficient Dataset Condensation,"Given a real-world dataset, data condensation (DC) aims to synthesize a significantly smaller dataset that captures the knowledge of this dataset for model training with high performance. Recent works propose to enhance DC with data parameterization, which condenses data into parameterized data containers rather than pixel space. The intuition behind data parameterization is to encode shared features of images to avoid additional storage costs. In this paper, we recognize that images share common features in a hierarchical way due to the inherent hierarchical structure of the classification system, which is overlooked by current data parameterization methods.
To better align DC with this hierarchical nature and encourage more efficient information sharing inside data containers, we propose a novel data parameterization architecture, Hierarchical Memory Network (HMN). HMN stores condensed data in a three-tier structure, representing the dataset-level, class-level, and instance-level features. Another helpful property of the hierarchical architecture is that HMN naturally ensures good independence among images despite achieving information sharing. This enables instance-level pruning for HMN to reduce redundant information, thereby further minimizing redundancy and enhancing performance. We evaluate HMN on four public datasets (SVHN, CIFAR10, CIFAR100, and Tiny-ImageNet) and compare HMN with eight DC baselines. The evaluation results show that our proposed method outperforms all baselines, even when trained with a batch-based loss consuming less GPU memory.","Haizhong Zheng, Jiachen Sun, Shutong Wu, Bhavya Kailkhura, Zhuoqing Mao, Chaowei Xiao, Atul Prakash","~Haizhong_Zheng1, ~Jiachen_Sun1, ~Shutong_Wu1, ~Bhavya_Kailkhura1, ~Zhuoqing_Mao1, ~Chaowei_Xiao2, ~Atul_Prakash1",Data condensation; Data distillation; Data parameterization,"general machine learning (i.e., none of the above)",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=fDZumshwym,https://openreview.net/forum?id=fDZumshwym,,
feZcpZbbqL,Finding Second-order Stationary Points for Generalized-Smooth Nonconvex Minimax Optimization via Gradient-based Algorithm,"Nonconvex minimax problems have received intense interest in many machine learning applications such as generative adversarial network, robust optimization and adversarial 
Recently, a variety of minimax optimization algorithms based on Lipschitz smoothness 
for finding first-order or second-order stationary points have been proposed.
However, the standard Lipschitz continuous gradient or Hessian assumption could fail to hold even in some classic minimax problems,
rendering conventional minimax optimization algorithms fail to converge in practice.
To address this challenge, we demonstrate a new gradient-based method for nonconvex-strongly-concave minimax optimization 
under a generalized smoothness assumption.
Motivated by the important application of escaping saddle points, we propose a generalized Hessian smoothness condition, 
under which our gradient-based method can achieve the complexity of $\mathcal{O}(\epsilon^{-1.75}\log n)$ 
to find a second-order stationary point with only gradient calls involved, 
which improves the state-of-the-art complexity results for the nonconvex minimax optimization 
even under standard Lipschitz smoothness condition.
To the best of our knowledge, this is the first work to show convergence 
for finding second-order stationary points on nonconvex minimax optimization with generalized smoothness.
The experimental results on the application of domain adaptation confirm the superiority of our algorithm compared with existing methods.","Qi Zhu, Yuanyuan Liu, Fanhua Shang, Hongying Liu, Zhouchen Lin","~Qi_Zhu15, ~Yuanyuan_Liu1, ~Fanhua_Shang2, ~Hongying_Liu2, ~Zhouchen_Lin1","Minimax Optimization, Nonconvex Optimization, Generalized Smoothness, Second-order Stationary Point",optimization,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=feZcpZbbqL,https://openreview.net/forum?id=feZcpZbbqL,,
FjifPJV2Ol,SOLVING SCHRODINGER BRIDGE PROBLEM VIA STOCHASTIC ACTION MINIMIZATION,"The Schrodinger bridge problem is a classical entropy-regularized optimal transport problem that seeks to find optimal diffusion trajectories that transform one probability distribution into another. Although mathematical theory has reached
a mature stage, the ongoing research in algorithmic advancements remains a dynamic field, driven by recent innovations in diffusion models. We introduce stochastic Lagrangian and stochastic action as viable alter-
native for serving as a direct loss function. We demonstrate the feasibility of incorporating all the vital physical constraints necessary to solve the problem directly into the Lagrangian,  providing an intuitive grasp of the loss function and streamlining the training process.","Mykola Bordyuh, Daniel Wong, Robert Moccia, Djork-Arné Clevert","~Mykola_Bordyuh1, daniel.wong@pfizer.com, robert.moccia@pfizer.com, ~Djork-Arné_Clevert2","Schrodinger bridge, optimal transport, single-cell, trajectories",generative models,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=FjifPJV2Ol,https://openreview.net/forum?id=FjifPJV2Ol,,
FJWT0692hw,SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling with Backtracking,"In many domains, autoregressive models can attain high likelihood on the task of predicting the next observation. However, this maximum-likelihood (MLE) objective does not necessarily match a downstream use-case of autoregressively generating high-quality sequences. The MLE objective weights sequences proportionally to their frequency under the data distribution, with no guidance for the model's behaviour out of distribution (OOD): leading to compounding error during autoregressive generation. In order to address this compounding error problem, we formulate sequence generation as an imitation learning (IL) problem. This allows us to minimize a variety of divergences between the distribution of sequences generated by an autoregressive model and sequences from a dataset, including divergences with weight on OOD generated sequences. The IL framework also allows us to incorporate backtracking by introducing a backspace action into the generation process. This further mitigates the compounding error problem by allowing the model to revert a sampled token if it takes the sequence OOD. Our resulting method, SequenceMatch, can be implemented without adversarial training or major architectural changes. We identify the SequenceMatch-χ2 divergence as a more suitable training objective for autoregressive models which are used for generation. We show that empirically, SequenceMatch training leads to improvements over MLE on text generation with language models and arithmetic","Chris Cundy, Stefano Ermon","~Chris_Cundy1, ~Stefano_Ermon1","Sequence Modelling, Imitiation Learning, Language Modelling",generative models,ICLR 2024 poster,2024,https://openreview.net/pdf?id=FJWT0692hw,https://openreview.net/forum?id=FJWT0692hw,,
FSkseQQgPu,Radio Frequency Ray Tracing via Stochastic Geometry,"Radio frequency (RF) propagation modeling is essential for the design, analysis, and optimization of modern wireless sensing and communication systems. However, accurately modeling RF propagation in electrically large and complex environments remains a long-standing challenge, owing to the intricate interactions between RF signals and surrounding objects (e.g., reflection, diffraction, and scattering). Unlike conventional ray-tracing pipelines that hand-engineer interaction rules, or black-box neural surrogates that do not explicitly model physical structure, we introduce RFSG, a novel framework that integrates neural representations with physics-based RF propagation modeling. Starting with a stochastic representation of objects via random indicator functions, we derive the attenuation coefficient as a functional of the probability distributions of the underlying indicator functions under an exponential transport model. This formulation inherently satisfies key physical constraints such as reciprocity and reversibility. Building on this foundation, we employ object-centric neural representations to capture complex RF–object interactions while preserving the composability of traditional ray tracing. Extensive elevations on real-world testbeds demonstrate that RFSG consistently outperforms state-of-the-art neural baselines in prediction accuracy, while requiring significantly fewer training samples.",,,"Radio Frequency, Neural Rendering, Neural Representation, Stochastic Geometry, Wireless Channel Modeling","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=FSkseQQgPu,https://openreview.net/forum?id=FSkseQQgPu,,
Fty0wTcemV,DELIFT: Data Efficient Language model Instruction Fine-Tuning,"Fine-tuning large language models (LLMs) is crucial for task specialization but often becomes resource-intensive due to redundant or uninformative data. Existing data selection methods typically rely either on computationally expensive gradient-based metrics or static embeddings that fail to adapt dynamically to the model’s evolving state, thus limiting their practical effectiveness. To address this,
we propose DELIFT (Data Efficient Language model Instruction Fine-Tuning), leveraging a novel, computationally efficient utility metric inspired by In-Context Learning (ICL). Our ICL-based metric measures the informational value of each data sample by quantifying its effectiveness as an in-context example in improving model predictions for other samples, reflecting its actual contribution relative to the model’s current state. Integrated with tailored submodular optimization methods, DELIFT systematically selects diverse, informative subsets optimized specifically for each fine-tuning stage: instruction tuning, task-specific adaptation, and continual fine-tuning. Experimental results across multiple datasets and model scales show DELIFT reduces fine-tuning data requirements by up to 70% without compromising performance, consistently outperforming existing methods by up to 26% in effectiveness and efficiency.","Ishika Agarwal, Krishnateja Killamsetty, Lucian Popa, Marina Danilevsky","~Ishika_Agarwal1, ~Krishnateja_Killamsetty1, ~Lucian_Popa1, ~Marina_Danilevsky1",Data Efficient Instruction Fine-Tuning;  Data Subset Selection; Submodular Functions,"unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=Fty0wTcemV,https://openreview.net/forum?id=Fty0wTcemV,,
g6syfIrVuS,Local Loss Optimization in the Infinite Width: Stable Parameterization of Predictive Coding Networks and Target Propagation,"Local learning, which trains a network through layer-wise local targets and losses, has been studied as an alternative to backpropagation (BP) in neural computation. However, its algorithms often become more complex or require additional hyperparameters due to the locality, making it challenging to identify desirable settings where the algorithm progresses in a stable manner.
To provide theoretical and quantitative insights, we introduce  maximal update parameterization ($\mu$P) in the infinite-width limit for two representative designs of local targets: predictive coding (PC) and target propagation (TP). We verify that $\mu$P enables hyperparameter transfer across models of different widths.
Furthermore, our analysis reveals unique and intriguing properties of $\mu$P that are not present in conventional BP. By analyzing deep linear networks, we find that PC's gradients interpolate between first-order and Gauss-Newton-like gradients, depending on the parameterization.  
We demonstrate that, in specific standard settings, PC in the infinite-width limit behaves more similarly to the first-order gradient.
For TP, even with the standard scaling of the last layer differing from classical $\mu$P, its local loss optimization favors the feature learning regime over the kernel regime.","Satoki Ishikawa, Rio Yokota, Ryo Karakida","~Satoki_Ishikawa1, ~Rio_Yokota1, ~Ryo_Karakida2","deep learning, feature learning, local learning, predictive coding, target propagation, infinite width, maximal update parameterization (muP)",optimization,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=g6syfIrVuS,https://openreview.net/forum?id=g6syfIrVuS,,
GBfYgjOfSe,Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms,"Building a generalist model for user interface (UI) understanding is challenging due to various foundational issues, such as platform diversity, resolution variation, and data limitation. In this paper, we introduce Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI understanding across a wide range of platforms, including iPhone, Android, iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI 2 introduces three key innovations: support for multiple platform types, high-resolution perception through adaptive scaling, and advanced task training data generation powered by GPT-4o with set-of-mark visual prompting. These advancements enable Ferret-UI 2 to perform complex, user-centered interactions, making it highly versatile and adaptable for the expanding diversity of platform ecosystems. Extensive empirical experiments on referring, grounding, user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDE next-action prediction dataset, and GUI-World multi-platform benchmark demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also shows strong cross-platform transfer capabilities.","Zhangheng LI, Keen You, Haotian Zhang, Di Feng, Harsh Agrawal, Xiujun Li, Mohana Prasad Sathya Moorthy, Jeffrey Nichols, Yinfei Yang, Zhe Gan","~Zhangheng_LI2, ~Keen_You1, ~Haotian_Zhang3, ~Di_Feng5, ~Harsh_Agrawal1, ~Xiujun_Li1, ~Mohana_Prasad_Sathya_Moorthy1, ~Jeffrey_Nichols1, ~Yinfei_Yang1, ~Zhe_Gan1","Multimodal LLM, UI Understanding","foundation or frontier models, including LLMs",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=GBfYgjOfSe,https://openreview.net/forum?id=GBfYgjOfSe,,
GfXMTAJaxZ,How to Verify Any (Reasonable) Distribution Property: Computationally Sound Argument Systems for Distributions,"As statistical analyses become more central to science, industry and society, there is a growing need to ensure correctness of their results. Approximate correctness can be verified by replicating the entire analysis, but can we verify without replication? We focus on distribution testing problems: verifying that an unknown distribution is close to having a  claimed property. Our main contribution is an interactive protocol between a verifier and an untrusted prover, which can be used to verify any distribution property that can be decided in polynomial time given a full and explicit description of the distribution. If the distribution is at statistical distance $\varepsilon$ from having the property, then the verifier rejects with high probability. This soundness property holds against any polynomial-time  strategy that a cheating prover might follow, assuming the existence of collision-resistant hash functions (a standard assumption in cryptography). For distributions over a domain of size $N$, the protocol consists of $4$ messages and the communication complexity and verifier runtime are roughly $\widetilde{O}\left(\sqrt{N} / \varepsilon^2 \right)$. The verifier's sample complexity is $\widetilde{O}\left(\sqrt{N} / \varepsilon^2 \right)$, and this is optimal up to $\text{polylog}(N)$ factors (for any protocol, regardless of its communication complexity). Even for simple properties, approximately deciding whether an unknown distribution has the property can require quasi-linear sample complexity and running time. For any such property, our protocol provides a quadratic speedup over replicating the analysis.","Tal Herman, Guy N. Rothblum","~Tal_Herman1, ~Guy_N._Rothblum1","property testing, distribution testing, interactive proofs, data science, verification","alignment, fairness, safety, privacy, and societal considerations",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=GfXMTAJaxZ,https://openreview.net/forum?id=GfXMTAJaxZ,,
GiHLTtfbB5,Adversarial Attacks on Cooperative Multi-agent Bandits,"Cooperative multi-agent multi-armed bandits (CMA2B) consider the collaborative efforts of multiple agents in a shared multi-armed bandit game. We study latent vulnerabilities exposed by this collaboration and consider adversarial attacks on a few agents with the goal of influencing the decisions of the rest. More specifically, we study adversarial attacks on CMA2B in both homogeneous settings, where agents operate with the same arm set, and heterogeneous settings, where agents may have distinct arm sets. In the homogeneous setting, we propose attack strategies that, by targeting just one agent, convince all agents to select a particular target arm $T-o(T)$ times while incurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we prove that a target arm attack requires linear attack costs and propose attack strategies that can force a maximum number of agents to suffer linear regrets while incurring sublinear costs and only manipulating the observations of a few target agents. Numerical experiments validate the effectiveness of our proposed attack strategies.","Jinhang Zuo, Zhiyao Zhang, Xuchuang Wang, Cheng Chen, Shuai Li, John C.S. Lui, Mohammad Hajiesmaili, Adam Wierman","~Jinhang_Zuo1, ~Zhiyao_Zhang2, ~Xuchuang_Wang1, ~Cheng_Chen9, ~Shuai_Li3, ~John_C.S._Lui2, ~Mohammad_Hajiesmaili1, ~Adam_Wierman1","multi-agent bandits, adversarial attacks",learning theory,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=GiHLTtfbB5,https://openreview.net/forum?id=GiHLTtfbB5,,
gqmELEp3lZ,OpenReviewer: Mitigating Challenges in LLM Reviewing,"Human reviews of research papers are slow and of variable quality. Hence there is increasing interest in using large language models (LLMs) such as GPT to review research papers. This paper develops a proof-of-concept LLM review process that shows LLMs offer consistently high-quality reviews almost instantly. However, many challenges and limitations remain: risk of misuse, inflated review scores, overconfident ratings, skewed score distributions, and limited prompt length. We mitigate these issues without prompt engineering by using LLM watermarking to mark LLM-generated reviews; classifying and detection errors and shortcomings of papers; and using long-context windows that include the review form, entire paper, reviewer guidelines, code of ethics and conduct, area chair guidelies, and previous year statistics; and a blind human evaluation of reviews. We aim to use OpenReviewer to review and revise research papers, improving their quality. This work identifies and addresses drawbacks associated with GPT as a reviewer and enhances the quality of the reviewing process based on a randomized human blind evaluation. Making OpenReviewer available as an open online service that generates reviews will allow the use of scalable human feedback to learn and improve.","Keith Tyser, Jason Lee, Avi Shporer, Madeleine Udell, Dov Te'eni, Iddo Drori","~Keith_Tyser1, ~Jason_Lee6, ~Avi_Shporer1, ~Madeleine_Udell1, teeni@tauex.tau.ac.il, ~Iddo_Drori1","ChatGPT, reviewing research papers, LLM watermarking, long context windows, fine-tuning, randomized human blind evaluation",datasets and benchmarks,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=gqmELEp3lZ,https://openreview.net/forum?id=gqmELEp3lZ,,
gVbPYihQag,Stochastic Diffusion: A Diffusion Based Model for Stochastic Time Series Forecasting,"Recent successes in diffusion probabilistic models have demonstrated their strength in modelling and generating different types of data, paving the way for their application in generative time series forecasting. However, most existing diffusion based approaches rely on sequential models and unimodal latent variables to capture global dependencies and model entire observable data, resulting in difficulties when it comes to highly stochastic time series data. In this paper, we propose a novel **Stoch**astic **Diff**usion (StochDiff) model that integrates the diffusion process into time series modelling stage and utilizes the representational power of the stochastic latent spaces to capture the variability of the stochastic time series data. Specifically, the model applies diffusion module at each time step within the sequential framework and learns a step-wise, data-driven prior for generative diffusion process. These features enable the model to effectively capture complex temporal dynamics and the multi-modal nature of the highly stochastic time series data. Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our proposed model for probabilistic time series forecasting, particularly in scenarios with high stochasticity. Additionally, with a real-world surgical use case, we highlight the model's potential in medical application.","Yuansan Liu, Sudanthi Wijewickrema, Dongting Hu, Christofer Bester, Stephen O'Leary, James Bailey","~Yuansan_Liu1, ~Sudanthi_Wijewickrema1, ~Dongting_Hu1, ~Christofer_Bester1, ~Stephen_O'Leary1, ~James_Bailey1","diffusion probabilistic model, stochastic time series forecasting, data-driven prior",learning on time series and dynamical systems,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=gVbPYihQag,https://openreview.net/forum?id=gVbPYihQag,,
gXfKPj4s7C,Object2Scene: Putting Objects in Context for Open-Vocabulary 3D Detection,"Point cloud-based open-vocabulary 3D object detection aims to detect 3D categories that do not have ground-truth annotations in the training set. It is extremely challenging because of the limited data and annotations (bounding boxes with class labels or text descriptions) of 3D scenes. Previous approaches leverage large-scale richly-annotated image datasets as a bridge between 3D and category semantics but require an extra alignment process between 2D images and 3D points, limiting the open-vocabulary ability of 3D detectors. Instead of leveraging 2D images, we propose Object2Scene, the first approach that leverages large-scale large-vocabulary 3D object datasets to augment existing 3D scene datasets for open-vocabulary 3D object detection. Object2Scene inserts objects from different sources into 3D scenes to enrich the vocabulary of 3D scene datasets and generates text descriptions for the newly inserted objects. We further introduce a framework that unifies 3D detection and visual grounding, named L3Det, and propose a cross-domain object-level contrastive learning approach to mitigate the domain gap between 3D objects from different datasets. Extensive experiments on existing open-vocabulary 3D object detection benchmarks show that Object2Scene obtains superior performance over existing methods. We further verify the effectiveness of Object2Scene on a new benchmark OV-ScanNet-200, by holding out all rare categories as novel categories not seen during training.","Chenming Zhu, Wenwei Zhang, Tai Wang, Xihui Liu, Kai Chen","~Chenming_Zhu1, ~Wenwei_Zhang1, ~Tai_Wang2, ~Xihui_Liu1, ~Kai_Chen4","open vocabulary 3d detection, 3d detection, contrastive learning","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=gXfKPj4s7C,https://openreview.net/forum?id=gXfKPj4s7C,,
hdcTQ4eEVJ,Multi-Objective Markov Games: Theoretic Foundations and Learning Algorithms,"In practical multi-agent systems, agents often have diverse objectives, which makes the system more complex, as each agent's performance across multiple criteria depends on the joint actions of all agents, creating intricate strategic trade-offs. To address this, we introduce the  Multi-Objective Markov Game (MOMG), a framework for multi-agent reinforcement learning with multiple objectives. We propose the Pareto-Nash Equilibrium (PNE) as the primary solution concept, where no agent can unilaterally improve one objective without sacrificing performance on another. We prove existence of PNE, and establish an equivalence between the PNE and the set of Nash Equilibria of MOMG's corresponding linearly scalarized games, enabling solutions of MOMG by transferring to a standard single-objective Markov game. However, we note that computing a PNE is theoretically and computationally challenging, thus we propose and study weaker but more tractable solution concepts. Building on these foundations, we develop online learning algorithm that identify a single solution to MOMGs. Furthermore, we propose a novel two-phase, preference-free algorithm that decouples exploration from planning. Our algorithm enables computation of a PNE for any given preference profile without collecting new samples, providing an efficient methodological characterization of the entire Pareto-Nash front.",,,"Multi-objective learning, Markov games, reinforcement leaning",reinforcement learning,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=hdcTQ4eEVJ,https://openreview.net/forum?id=hdcTQ4eEVJ,,
HFhyCyln4X,Elastic Mixture of Rank-Wise Experts for Knowledge Reuse in Federated Fine-Tuning,"Federated fine-tuning offers a promising solution for adapting Large Language Models (LLMs) to downstream tasks while safeguarding data privacy. However, its high computational and communication demands hinder its deployment on resource-constrained devices. In this paper, we propose SmartFed, a resource-efficient federated fine-tuning framework. SmartFed intelligently reuses knowledge embedded in existing LoRA modules, eliminating the need for expensive training from scratch when adapting LLMs to new tasks. To effectively exploit this knowledge and ensure scalability, we introduce the Mixture of Rank-Wise Experts (MoRE). MoRE decomposes LoRA modules into fine-grained rank-level experts. These experts are selectively activated and combined based on input semantics and resource budgets. Moreover, to optimize resource utilization, we present the Elastic Expert Quota Allocation (EEQA). EEQA adaptively allocates expert capacity across parameter matrices based on their contribution to model performance,  focusing computing resources on the critical experts. Extensive evaluations across multiple benchmarks demonstrate that SmartFed significantly outperforms existing methods in model performance and training efficiency.",,,"Federated Fine-Tuning, Large Language Model, Knowledge Reuse","transfer learning, meta learning, and lifelong learning",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=HFhyCyln4X,https://openreview.net/forum?id=HFhyCyln4X,,
hfPUieLcQw,Efficient Diffusion Models under Nonconvex Equality and Inequality constraints via Landing,"The generative modeling of data in constrained sets is central to scientific and engineering applications with physical, geometric, or safety constraints (e.g., molecular generation, robotics). This article constructs constrained diffusion models on a generic nonconvex feasible sets $\Sigma$, by introducing a unified framework that simultaneously enforces both equality and inequality constraints throughout the diffusion process. Our theory and implementations encompass both overdamped and underdamped dynamics for the forward and backward sampling. The key algorithmic ingredient is a computationally efficient landing mechanism that replaces costly and not-always-well-defined projections onto $\Sigma$, maintaining feasibility without Newton solves and avoiding projection failures. Leveraging underdamped dynamics whose faster mixing reduces the steps needed to reach the prior distribution, the commonly-believed unavoidable heavy forward simulation cost in the constrained diffusion is alleviated. Empirically, this reduces function evaluations, enabling more efficient inference and training while preserving sample quality and substantially lowering memory usage. On equality-only and mixed (equality and inequality) benchmarks, our method shows reasonable sample quality, while substantially reducing computational cost and function evaluations. These results indicate that landing-based enforcement combined with underdamped dynamics provides a practical and scalable recipe for constrained diffusion on nonconvex feasible sets.",,,"constrained diffusion models, nonconvex manifold, underdamped Langevin dynamics, landing mechanism",generative models,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=hfPUieLcQw,https://openreview.net/forum?id=hfPUieLcQw,,
hS9FLRBf7v,Network of Patterns: Time Series Forecasting with Pattern Passing,"Time series contain diverse pattern information, and many studies have leveraged these patterns to enhance representations for more accurate forecasting. A key challenge lies in how to organize multi-scale patterns for effective information aggregation. Previous studies typically partition sequences into multi-scale pattern segments and organize them into chain or tree structures, employing neural networks to aggregate features and improve predictive performance. However, information transmission in chain structures is strictly linear and accumulative, while tree structures can aggregate multiple patterns but remain constrained by hierarchical limitations. Moreover, segments at the same or neighboring scales do not necessarily exhibit strong dependencies.

To overcome these limitations, we propose the Network of Patterns (NoP), which flexibly connects all relevant pattern segments to enable interactions between any nodes. We further introduce a Pattern Passing strategy to efficiently propagate and aggregate pattern information across this network, achieving more comprehensive integration. Experimental results demonstrate that NoP not only effectively encapsulates informative pattern signals but also establishes new state-of-the-art performance on multiple time series forecasting benchmarks, surpassing chain- and tree-based methods.",,,"Time Series Forecasting, Decomposition, Multi-scale",learning on time series and dynamical systems,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=hS9FLRBf7v,https://openreview.net/forum?id=hS9FLRBf7v,,
HuNIgYhBoy,Benchmarking World-Model Learning,"Model-learning agents should gather information to learn world models that support many downstream tasks and inferences, such as predicting unobserved states, estimating near- and far-term consequences of actions, planning action sequences, and detecting changes in dynamics. Current methods for learning and evaluating world models diverge from this goal: training and evaluation are anchored to next-frame prediction, and success is scored by reward maximization in the same environment. We propose _WorldTest_, a protocol for evaluating model-learning agents that separates reward-free interaction from a scored test phase in a different, related
environment. WorldTest is open-ended—models should support many different tasks unknown ahead of time—and agnostic to model representation, allowing comparison across approaches. We instantiated WorldTest with _AutumnBench_, a suite of 43 interactive grid-world environments and 129 tasks across three families: masked-frame prediction, planning, and predicting changes to the causal dynamics. We compared 517 human participants and three frontier models on AutumnBench. We found that humans outperform the models, and scaling compute improves performance only in some environments but not others. WorldTest provides a novel template—reward-free exploration, derived tests, and behavior-based scoring—for evaluating what agents learn about environment dynamics, and AutumnBench exposes significant headroom in world-model learning.",,,"world model learning, benchmark, representation-agnostic evaluation, reward-free learning",datasets and benchmarks,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=HuNIgYhBoy,https://openreview.net/forum?id=HuNIgYhBoy,,
HxHrRUHMOD,Accurate Differential Operators for Neural Fields,"Neural fields have become widely used in various fields, from shape representation to neural rendering, and for solving partial differential equations (PDEs). With the advent of hybrid neural field representations like Instant NGP that leverage small MLPs and explicit representations, these models train quickly and can fit large scenes. Yet in many applications like rendering and simulation, hybrid neural fields can cause noticeable and unreasonable artifacts. This is because they do not yield accurate spatial derivatives needed for these downstream applications. In this work, we propose two ways to circumvent these challenges. Our first approach is a post hoc operator that uses local polynomial-fitting to obtain more accurate derivatives from pre-trained hybrid neural fields. Additionally, we also propose a self-supervised fine-tuning approach that refines the neural field to yield accurate derivatives directly while preserving the initial signal. We show the application of our method on rendering, collision simulation, and solving PDEs. We observe that using our approach yields more accurate derivatives, reducing artifacts and leading to more accurate simulations in downstream applications.","Aditya Chetan, Guandao Yang, Zichen Wang, Steve Marschner, Bharath Hariharan","~Aditya_Chetan1, ~Guandao_Yang1, ~Zichen_Wang10, ~Steve_Marschner1, ~Bharath_Hariharan3","Neural Fields, Deep Learning","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=HxHrRUHMOD,https://openreview.net/forum?id=HxHrRUHMOD,,
i0VqD2KaYt,ViT-UWA: Vision Transformer Underwater-Adapter for Dense Predictions Beneath the Water Surface,"Vision Transformer (ViT) and its variants have witnessed a significant success in computer vision. However, they do not perform well in underwater dense prediction tasks due to challenges like complex underwater environments, quality degradation, and light scattering in underwater images. To solve this problem, we propose the  Vision Transformer Underwater-Adapter (ViT-UWA), the first detail-focused and adapted ViT backbone for underwater dense prediction tasks, without requiring task-specific pretraining. In ViT-UWA, we first introduce High-frequency Components Prior (HFCP) to add high-frequency information of underwater images to the plain ViT, which can help recover and capture lost high-frequency information of underwater images. Then, we propose an Detail Aware Module (DAM) to obtain a detail-focused multi-scale convolutional feature pyramid, which can be used in kinds of dense prediction tasks. Through the ViT-CNN Interaction Module (VCIM), we achieve bidirectional feature fusion between ViT and CNN. We evaluate ViT-UWA on multiple underwater dense prediction tasks, including semantic segmentation, instance segmentation, and object detection. Notably, with only ImageNet-22K pretraining, our ViT-UWA-B yields state-of-the-art 46.4 box AP and 44.2 mask AP on USIS10K dataset. We hope ViT-UWA could provide a new backbone for future research on underwater dense prediction tasks.","Qirui LIN, Hua Li, Yuheng Jia, Yutong Li, Shijie Lian, Huazhong Liu, Sam Kwong, Runmin Cong","~Qirui_LIN1, ~Hua_Li8, ~Yuheng_Jia1, ~Yutong_Li4, ~Shijie_Lian1, ~Huazhong_Liu1, ~Sam_Kwong1, ~Runmin_Cong1","Underwater Image Dense Prediction, Adapted ViT Backbone","applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=i0VqD2KaYt,https://openreview.net/forum?id=i0VqD2KaYt,,
i8PjQT3Uig,Locality Sensitive Sparse Encoding for Learning World Models Online,"Acquiring an accurate world model $\textit{online}$ for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs). From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round. Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents. In this paper, we revisit models that can achieve FTL with incremental updates. Specifically, our world model is a linear regression model supported by nonlinear random features. The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments. To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features. We validate the representation power of our encoding and verify that it allows efficient online learning under data covariate shift. We also show, in the Dyna MBRL setting, that our world models learned online using a $\textit{single pass}$ of trajectory data either surpass or match the performance of deep world models trained with replay and other continual learning methods.","Zichen Liu, Chao Du, Wee Sun Lee, Min Lin","~Zichen_Liu1, ~Chao_Du1, ~Wee_Sun_Lee1, ~Min_Lin1","model-based rl, online learning, incremental learning, catastrophic forgetting",reinforcement learning,ICLR 2024 poster,2024,https://openreview.net/pdf?id=i8PjQT3Uig,https://openreview.net/forum?id=i8PjQT3Uig,,
IBACinPJG5,MIRAGE: Modelling Interpretable Multivariate Time Series Forecasts with Actionable Ground Explanations,"Multi-variate Time Series (MTS) forecasting has made large strides (with very negligible errors) through recent advancements in neural networks, e.g., Trans- formers. However, in critical situations like predicting a death in an ICU or sudden gaming overindulgence; an accurate prediction without a contributing evidence is irrelevant. It is important to have model driven Interpretability, allowing proactive comprehension of trajectory to an extremity; and an associated Explainability, al- lowing for preventive steps; e.g., controlling BP to avoid death, or nudging players to take breaks to prevent overplay. We introduce a novel deep neural network, MI- RAGE, which overcomes the inter-dependent challenges of—(a) temporally non- smooth data trajectories for interpretability; (b) highly multi-dimensional tempo- ral space for explainability; and (c) improving forecasting accuracy—all at once. MIRAGE: (i) achieves over 85% improvement on the MSE of the forecasts on the most relevant SOM-VAE based SOTA networks; and (ii) unravels the intricate multi-variate relationships and temporal trajectories contributing to any sudden movement to criticalities on temporally chaotic datasets.","Hussain Jagirdar, Rukma Ameet Talwadker, Aditya Pareek, Pulkit Agrawal, Tridib Mukherjee","hussain.jagirdar@games24x7.com, ~Rukma_Ameet_Talwadker1, aditya.pareek@games24x7.com, pulkit.agrawal@games24x7.com, ~Tridib_Mukherjee1","Representation Learning, Interpretable Representations, Explainability, Forecasting, Markov Models, LSTM, Attention Networks, Clustering","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=IBACinPJG5,https://openreview.net/forum?id=IBACinPJG5,,
ICtXoEuZEV,Mitigating Spurious Correlations in LLMs via Causality-Aware Post-Training,"While large language models (LLMs) have demonstrated remarkable capabilities in language modeling, recent studies reveal that they often fail on out-of-distribution (OOD) samples due to spurious correlations acquired during pre-training. Here, we aim to mitigate such spurious correlations through causality-aware post-training (CAPT). By decomposing a biased prediction into two unbiased steps, known as \textit{event estimation} and \textit{event intervention}, we reduce LLMs' pre-training biases without incurring additional fine-tuning biases, thus enhancing the model's generalization ability. Experiments on the formal causal inference benchmark CLadder and the logical reasoning dataset PrOntoQA show that 3B-scale language models fine-tuned with CAPT can outperform both traditional SFT and larger LLMs on in-distribution (ID) and OOD tasks using only 100 ID fine-tuning samples, demonstrating the effectiveness and sample efficiency of CAPT.",,,"LLM, fine-tuning, spurious correlations, causal inference","foundation or frontier models, including LLMs",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=ICtXoEuZEV,https://openreview.net/forum?id=ICtXoEuZEV,,
ideKAUWvFE,OSCAR: Online Soft Compression for RAG,"Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating external knowledge, leading to improved accuracy and relevance. However, scaling RAG pipelines remains computationally expensive as context length grows. On one hand, hard compression methods have recently proposed to prune the retrieved text on-the-fly with a limited compression ration. On the other hand, soft compression method performs a costly offline compression thanks a dedicated LLM but with a higher compression rate. In this paper, we introduce OSCAR, a novel query-dependent online soft compression method for RAG. OSCAR bridges the gap between online hard and offline soft compression methods, bringing the best of both: OSCAR dynamically compresses retrieved information at inference time, eliminating storage overhead and enabling higher compression rates than existing methods. Our experiments demonstrate state-of-the-art performance with a 2-5x speed-up in inference and minimal, if any, accuracy loss, for LLMs ranging from 1B to 24B parameters.",,,"RAG, Compression, Embedding, Efficiency, Question Answering","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=ideKAUWvFE,https://openreview.net/forum?id=ideKAUWvFE,,
IhOeYKqnfp,Continual Memory Neurons,"Learning with neural networks by continuously processing a stream of data is very related to the way humans learn from perceptual information. However, when data is not i.i.d., it is largely known that it is very hard to find a good trade-off between plasticity and stability, frequently resulting in catastrophic forgetting issues. In this paper, to our best knowledge, we are the first to follow a significantly novel route, tackling the problem at the lowest level of abstraction. We propose a neuron model, referred to as Continual Memory Neuron (CMN), which does not only compute a response to an input pattern, but also diversifies computations to preserve what was previously learned, while being plastic enough to adapt to new knowledge. The values attached to weights are computed as a function of the neuron input, which acts as a query in a key-value map, with the goal of selecting and blending a set of learnable memory units. We show that this computational scheme is motivated by and strongly related to the ones of popular models that perform computations relying on a set of samples stored in a memory buffer, including Kernel Machines and Transformers. Experiments on class-and-domain incremental streams processed in online and single-pass manner support CMNs' capability to mitigate forgetting, while keeping competitive or better performance with respect to continual learning methods that explicitly store and replay data over time.","Matteo Tiezzi, Simone Marullo, Federico Becattini, Stefano Melacci","~Matteo_Tiezzi1, ~Simone_Marullo1, ~Federico_Becattini2, ~Stefano_Melacci1","Neuron Model, Online Continual Learning, Replay-buffer-free Learning, Self-organized Memories","transfer learning, meta learning, and lifelong learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=IhOeYKqnfp,https://openreview.net/forum?id=IhOeYKqnfp,,
iHQIacMKka,Risk-Sensitive Agent Compositions,"From software development to robot control, modern agentic systems decompose complex objectives into a sequence of subtasks and choose a set of specialized AI agents to complete them.
We formalize agentic workflows as directed acyclic graphs, called agent graphs, where edges represent AI agents and paths correspond to feasible compositions of agents.
Real-world deployment requires selecting agent compositions that not only maximize task success but also minimize violations of safety, fairness, and privacy requirements which demands a careful analysis of the low-probability (tail) behaviors of compositions of agents.
In this work, we consider risk minimization over the set of feasible agent compositions and seek to minimize the value-at-risk of the loss distribution of the agent composition where the loss quantifies violations of these requirements.
We introduce an efficient algorithm which traverses the agent graph and finds a near-optimal composition of agents.
It uses a dynamic programming approach to approximate the value-at-risk of agent compositions by exploiting a union bound.
Furthermore, we prove that the approximation is near-optimal asymptotically for a broad class of practical loss functions.
To evaluate our framework, we consider a suite of video game-like control benchmarks that require composing several agents trained with reinforcement learning and demonstrate our algorithm's effectiveness in approximating the value-at-risk and identifying the optimal agent composition.",,,"Agentic systems, agent composition, safety, risk-sensitive planning, planning","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=iHQIacMKka,https://openreview.net/forum?id=iHQIacMKka,,
ijEi63QLsr,Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods,"Prior human-object interaction (HOI) detection methods have integrated early vision-language models (VLMs) such as CLIP, but only as supporting components within their frameworks. In contrast, recent advances in large, generative VLMs suggest that these models may already possess strong ability to understand images involving HOI. This naturally raises an important question: can general-purpose standalone VLMs effectively solve HOI detection, and how do they compare with specialized HOI methods? Answering this requires a benchmark that can accommodate both paradigms. However, existing HOI benchmarks such as HICO-DET were developed before the emergence of modern VLMs, and their evaluation protocols require exact matches to annotated HOI classes. This is poorly aligned with the generative nature of VLMs, which often yield multiple valid interpretations in ambiguous cases. For example, a static image may capture a person mid-motion with a frisbee, which can plausibly be interpreted as either ""throwing"" or ""catching"". When only ""catching"" is annotated, the other, though equally plausible for the image, is marked incorrect when exact matching is used. As a result, correct predictions might be penalized, affecting both VLMs and HOI-specific methods. To avoid penalizing valid predictions, we introduce a new benchmark that reformulates HOI detection as a multiple-answer multiple-choice task, where each question includes only ground-truth positive options and a curated set of negatives that are constructed to reduce ambiguity (e.g., when ""catching"" is annotated, ""throwing"" is not selected as a negative to avoid penalizing valid predictions). The proposed evaluation protocol is the first of its kind for both VLMs and HOI methods, enabling direct comparison and offering new insight into the current state of progress in HOI understanding.",,,Human-Object Interaction; Vision-Language Model,datasets and benchmarks,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=ijEi63QLsr,https://openreview.net/forum?id=ijEi63QLsr,,
iKBmp3i3M2,RF Prior: Preserving Global-Context Priors for Efficient Instance Segmentation Transfer,"We present an efficient transfer-learning framework that reparameterizes a state-of-the-art detector backbone—instantiated with a YOLO-family model—for polygon based instance segmentation. Our key idea is a Receptive-Field Prior: the largest-receptive-field block (P5) of the backbone, pretrained for detection, is kept fixed to preserve global object context, while intermediate low- level blocks (P3–P4) are fine-tuned for boundary precision. We formalize this with a block-diagonal Gaussian prior on backbone weights, yielding a MAP objective that acts as implicit adaptation. Multi-scale features from P3–P5 are fused in a attentive decoder to predict per-instance polygons. Experiments show strong and stable performance compared with scratch training or naïve tuning strategy. This approach\footnote{Our framework (code \& dataset) will be released upon acceptance as Ultralytics-compatible pipeline.} highlights that carefully constrained reuse of high-level detector features—guided by an explicit inductive bias—can yield strong segmentation.",,,"adaptive transfer, instance segmentation, receptive field, representation reuse, YOLO","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=iKBmp3i3M2,https://openreview.net/forum?id=iKBmp3i3M2,,
ISfY3YMXxU,INRet: A General Framework for Accurate Retrieval of INRs for Shapes,"Implicit neural representations (INRs) have become an important representation for encoding various data types, such as 3D objects/scenes, videos, and audio. They have proven to be particularly effective at generating 3D content, e.g., 3D scene reconstruction from 2D images, novel content creation, as well as the representation, interpolation and completion of 3D shapes. With the widespread generation of 3D data in an INR format, there is a need to support effective organization and retrieval of INRs saved in a data store. A key aspect of retrieval and clustering of INRs in a data store is the formulation of similarity between INRs that would, for example, enable retrieval of similar INRs using a query INR. In this work, we propose INRet (INR Retrieve), a method for determining similarity between INRs that represent shapes, thus enabling accurate retrieval of similar shape INRs from an INR data store. INRet flexibly supports different INR architectures such as INRs with octree grids and hash grids, as well as different implicit functions including signed/unsigned distance function and occupancy field. We demonstrate that our method is more general and accurate than the existing INR retrieval method, which only supports simple MLP INRs and requires the same architecture between the query and stored INRs. Compared to 3D shape retrieval by converting INRs to other representations like point clouds or multi-view images, INRet achieves higher retrieval accuracy while avoiding the overhead of conversion.","Gavin Guan, Yuchen Chen, Haoze Deng, Daniel Kwan, Ruofan Liang, Selvakumar Panneer, Nilesh Jain, Nandita Vijaykumar","~Gavin_Guan1, ~Yuchen_Chen3, ~Haoze_Deng1, ~Daniel_Kwan1, ~Ruofan_Liang1, ~Selvakumar_Panneer1, ~Nilesh_Jain1, ~Nandita_Vijaykumar1",INRet: A General Framework for Accurate Retrieval of INRs for Shapes,"unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=ISfY3YMXxU,https://openreview.net/forum?id=ISfY3YMXxU,,
j84WR5ORsC,Latent Visual Reasoning,"Multimodal Large Language Models (MLLMs) have achieved notable gains in various tasks by incorporating Chain-of-Thought (CoT) reasoning in language spaces. Recent work extends this direction by leveraging external tools for visual editing, thereby enhancing the visual signal along the reasoning trajectories. Nevertheless, these approaches remain fundamentally constrained: reasoning is still confined to the language space, with visual information treated as static preconditions. We introduce Latent Visual Reasoning (LVR), a new paradigm that enables autoregressive reasoning directly in the visual embedding space. A visual encoder first projects images into visual tokens within a joint semantic space shared with the language model. The language model is then trained to generate latent states that reconstruct key visual tokens critical for answering the query, constituting the process of latent visual reasoning. By interleaving LVR with standard text generation, our model achieves substantial gains on perception-intensive visual question answering tasks. In addition, we adapt the GRPO algorithm to conduct reinforcement learning on latent reasoning, further balancing LVR and textual generation.  We show that LVR substantially improves fine-grained visual understanding and perception, achieving 71.67\% on MMVP compared to 66.67\% with Qwen2.5-VL. Code base and model weights will be released later.",,,"multimodal large language models, vision Language Models, multimodal reasoning","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=j84WR5ORsC,https://openreview.net/forum?id=j84WR5ORsC,,
JjMRdXPpKQ,Can Diffusion Models Disentangle? A Theoretical Perspective,"This paper introduces a novel theoretical framework to understand how diffusion models can learn disentangled representations under the assumption of an $\normltwo$ score approximation. We also provide sufficient conditions under which such representations are beneficial for domain adaptation. Our theory offers new insights into how existing diffusion models disentangle latent variables across general distributions and suggests strategies to enhance their disentanglement capabilities. To validate our theory, we perform experiments using both synthetic data generated from latent subspace models and real speech data for non-parallel voice conversion - a canonical disentanglement problem. Across various classification tasks, we found voice conversion-based adaptation methods achieve significant improvements in classification accuracy, demonstrating their effectiveness as domain adaptors. Code will be released upon acceptance.","Liming Wang, Yuan Gong, Marco Vilela, James R. Glass","~Liming_Wang3, ~Yuan_Gong3, ~Marco_Vilela1, ~James_R._Glass1","diffusion model, disentanglement, voice conversion",learning theory,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=JjMRdXPpKQ,https://openreview.net/forum?id=JjMRdXPpKQ,,
jRpD8VfGRf,Multi-interest Disentangled Representation Learning for Multimodal Recommendation,"In recent years, multimodal recommendation systems have been widely used in e-commerce and short video platforms. How to effectively utilize multimodal data and avoid the interference of multimodal noise information has become the key research direction of researchers. Many studies add multimodal data as auxiliary features to the model, which brings positive effects. Pictures, text and audio signals in short videos are more likely to attract users' interest than basic attributes. The user's multiple personalized interests largely determine the user's behavioral preferences. In order to effectively utilize user interest to improve model effect, We propose a new Multi-interest Disentangled Representation Learning method for multimodal recommendation (MIDR). Specifically, we first introduce the expected maximum to describe the relationship between interest and predicted target, and establish the optimization object based on multi-interest recommendation. Then, considering the relationship between user interest and multiple modalities, we introduce disentangled representation learning to extract modal sharing and modal specific interest representations. Furthermore, we introduce multi-interest contrast module to help model learning interest representation based on self-supervised learning. We conducted experiments on three real-world data sets, and our proposed MIDR outperformed other state-of-art models. The effectiveness of the disentangled interest representation module and interest contrast module was verified by the ablation experiment.","Wei Yang, Qingchen Yang, Yiqun Chen, Chi Lu","~Wei_Yang10, ~Qingchen_Yang1, ~Yiqun_Chen2, ~Chi_Lu2","Multiple Interests, Disentangled Representation, Multimodal Recommendation","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=jRpD8VfGRf,https://openreview.net/forum?id=jRpD8VfGRf,,
jZffxvubJ9,Treatment Rule Optimization Under Counterfactual Temporal Point Processes with Latent States,"In high-stakes areas like healthcare, retrospective counterfactual analysis—such as evaluating what might have happened if treatments were administered earlier, later, or differently—is vital for refining treatment strategies. This paper proposes a counterfactual treatment optimization framework using temporal point processes to model outcome event sequences. By sampling potential outcome events under new treatment decision rules, our approach seeks to optimize treatment strategies in a counterfactual setting. To achieve accurate counterfactual evaluation of new decision rules, we explicitly introduce latent states into the modeling of temporal point processes. Our method first infers the latent states and associated noise, followed by counterfactual sampling of outcome events. This approach rigorously addresses the complexities introduced by latent states, effectively removing biases in the evaluation of treatment strategies. By proving the identifiability of model parameters in the presence of these states, we provide theoretical guarantees that enhance the reliability and robustness of the counterfactual analysis. By incorporating latent states and proving identifiability, our framework not only improves the accuracy and robustness of treatment decision rules but also offers actionable insights for optimizing healthcare interventions. This method holds significant potential for improving treatment strategies, particularly in healthcare scenarios where patient symptoms are complex and high-dimensional.","Xinye Chen, Gegenduolan Zhang, Yinghao Fu, Chao Yang, Shuang Li","~Xinye_Chen2, ~Gegenduolan_Zhang1, ~Yinghao_Fu1, ~Chao_Yang9, ~Shuang_Li3","counterfactual reasoning, temporal point processes, latent confounder, rule learning",interpretability and explainable AI,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=jZffxvubJ9,https://openreview.net/forum?id=jZffxvubJ9,,
K1mcPiDdOJ,Conditional Information Bottleneck Approach for Time Series Imputation,"Time series imputation presents a significant challenge because it requires capturing the underlying temporal dynamics from partially observed time series data. Among the recent successes of imputation methods based on generative models, the information bottleneck (IB) framework offers a well-suited theoretical foundation for multiple imputations, allowing us to account for the uncertainty associated with the imputed values. However, directly applying the IB framework to time series data without considering their temporal context can lead to a substantial loss of temporal dependencies, which, in turn, can degrade the overall imputation performance. To address such a challenge, we propose a novel conditional information bottleneck (CIB) approach for time series imputation, which aims to mitigate the potentially negative consequences of the regularization constraint by focusing on reducing the redundant information conditioned on the temporal context. We provide a theoretical analysis of its effect by adapting variational decomposition. We use the resulting insight and propose a novel deep learning method that can approximately achieve the proposed CIB objective for time series imputation as a combination of evidence lower bound and novel temporal kernel-enhanced contrastive optimization. Our experiments, conducted on multiple real-world datasets, consistently demonstrate that our method significantly improves imputation performance (including both interpolation and extrapolation), and also enhances classification performance based on the imputed values.","MinGyu Choi, Changhee Lee","~MinGyu_Choi1, ~Changhee_Lee1",time series imputation; time series interpolation; information bottleneck,"general machine learning (i.e., none of the above)",ICLR 2024 poster,2024,https://openreview.net/pdf?id=K1mcPiDdOJ,https://openreview.net/forum?id=K1mcPiDdOJ,,
k3DrCkpCok,COMPOL: A Unified Neural Operator Framework for Scalable Multi-Physics Simulations,"Multi-physics simulations play an essential role in accurately modeling complex interactions across diverse scientific and engineering domains. Although neural operators, especially the Fourier Neural Operator (FNO), have significantly improved computational efficiency, they often fail to effectively capture intricate correlations inherent in coupled physical processes. To address this limitation, we introduce COMPOL, a novel coupled multi-physics operator learning framework. COMPOL extends conventional operator architectures by incorporating sophisticated recurrent and attention-based aggregation mechanisms, effectively modeling interdependencies among interacting physical processes within latent feature spaces. Our approach is architecture-agnostic and seamlessly integrates into various neural operator frameworks that involve latent space transformations. Extensive experiments on diverse benchmarks—including biological reaction-diffusion systems, pattern-forming chemical reactions, multiphase geological flows, and thermo-hydro-mechanical processes — demonstrate that COMPOL consistently achieves superior predictive accuracy compared to state-of-the-art methods.",,,"operator learning, physical simulations, coupled and multi-physics simulations","applications to physical sciences (physics, chemistry, biology, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=k3DrCkpCok,https://openreview.net/forum?id=k3DrCkpCok,,
K7SdrTobcY,VidBridge-R1: Bridging QA and Captioning for RL-based Video Understanding Models with Intermediate Proxy Tasks,"The ""Reason-Then-Respond"" paradigm, enhanced by Reinforcement Learning, has shown great promise in advancing Multimodal Large Language Models. However, its application to the video domain has led to specialized models that excel at either question answering (QA) or captioning tasks, but struggle to master both. Naively combining reward signals from these tasks results in mutual performance degradation, which we attribute to a conflict between their opposing task natures. To address this challenge, we propose a novel training framework built upon two intermediate proxy tasks: DarkEventInfer, which presents videos with masked event segments, requiring models to infer the obscured content based on contextual video cues; and MixVidQA, which presents interleaved video sequences composed of two distinct clips, challenging models to isolate and reason about one while disregarding the other. These proxy tasks compel the model to simultaneously develop both holistic, divergent understanding and precise, convergent reasoning capabilities. Embodying this framework, we present VidBridge-R1, the first versatile video reasoning model that effectively bridges the paradigm conflict. Extensive experiments show that VidBridge-R1 achieves significant performance gains on both QA and captioning within one model, demonstrating the efficacy of our approach in fostering more generalizable and powerful video understanding models. All code, models, and data will be made publicly available.",,,"video-qa, captioning, RL","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=K7SdrTobcY,https://openreview.net/forum?id=K7SdrTobcY,,
K9j6iggdGX,A$^2$SG: Adaptive and Asymmetric Surrogate Gradients for Training Deep Spiking Neural Network,"Training deep spiking neural networks (SNNs) remains challenging due to sharp loss landscapes and temporal inconsistency caused by surrogate gradients.
To address these challenges, we propose a unified framework: adaptive and asymmetric surrogate gradients ($\textit{A$^2$SG}$).
The adaptive gradients adjust an effective window for spatio-temporal adaptation, reducing spatial gradient variation and maintaining directional consistency of gradients over time.
The asymmetric gradients reflect neuronal dynamics by assigning larger gradients to neurons with higher membrane potentials, and we prove that they yield lower variation than symmetric surrogates.
Our analysis further establishes a direct connection between local gradient variation and the curvature of the loss landscape, providing a principled explanation for how $\textit{A$^2$SG}$ promotes convergence to flatter minima and improves generalization.
We conduct extensive experiments on diverse models, including CNN-based and Transformer-based SNNs, across various tasks such as image classification using both static and neuromorphic datasets, as well as segmentation.
The results demonstrate that $\textit{A$^2$SG}$ consistently improves accuracy and energy efficiency, establishing it as a general and reliable solution for training deep SNNs.",,,"deep spiking neural networks, surrogate gradients, adaptive, asymmetric","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=K9j6iggdGX,https://openreview.net/forum?id=K9j6iggdGX,,
kcmK2utDhu,MV-Adapter: Multi-view Consistent Image Generation Made Easy,"Generating multi-view images of an object has important applications in content creation and perception. Existing methods achieved this by making invasive changes to pre-trained text-to-image (T2I) models and performing full-parameter training, leading to three main limitations: (1) High computational costs, especially for high-resolution outputs; (2) Incompatibility with derivatives and extensions of the base model, such as personalized models, distilled few-step models, and plugins like ControlNets; (3) Limited versatility, as they primarily serve a single purpose and cannot handle diverse conditioning signals such as text, images, and geometry. In this paper, we present MV-Adapter to address all the above limitations. MV-Adapter is designed to be a plug-and-play module working on top of pre-trained T2I models. This enables efficient training for high-resolution synthesis while maintaining full compatibility with all kinds of derivatives of the base T2I model. MV-Adapter provides a unified implementation for generating multi-view images from various conditions, facilitating applications such as text- and image-based 3D generation and texturing. We demonstrate that MV-Adapter sets a new quality standard for multi-view image generation, and opens up new possibilities due to its adaptability and versatility.","Zehuan Huang, Yuan-Chen Guo, Haoran Wang, Ran Yi, Lizhuang Ma, Yan-Pei Cao, Lu Sheng","~Zehuan_Huang1, ~Yuan-Chen_Guo1, ~Haoran_Wang17, ~Ran_Yi1, ~Lizhuang_Ma1, ~Yan-Pei_Cao1, ~Lu_Sheng1","Multi-view Image Generation, 3D Generation, Diffusion Models",generative models,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=kcmK2utDhu,https://openreview.net/forum?id=kcmK2utDhu,,
KmphHE92wU,"Towards Stable, Globally Expressive Graph Representations with Laplacian Eigenvectors","Graph neural networks (GNNs) have achieved remarkable success in a variety of machine learning tasks over graph data. Existing GNNs usually rely on message passing, i.e., computing node representations by gathering information from the neighborhood, to build their underlying computational graphs. Such an approach has been shown fairly limited in expressive power, and often fails to capture global characteristics of graphs. To overcome the issue, a popular solution is to use Laplacian eigenvectors as additional node features, as they are known to contain global positional information of nodes, and can serve as extra node identifiers aiding GNNs to separate structurally similar nodes. Since eigenvectors naturally come with symmetries---namely, $O(p)$-group symmetry for every $p$ eigenvectors with equal eigenvalue, properly handling such symmetries is crucial for the stability and generalizability of Laplacian eigenvector augmented GNNs. However, using a naive $O(p)$-group invariant encoder for each $p$-dimensional eigenspace may not keep the full expressivity in the Laplacian eigenvectors. Moreover, computing such invariants inevitably entails a hard split of Laplacian eigenvalues according to their numerical identity, which suffers from great instability when the graph structure has small perturbations. In this paper, we propose a novel method exploiting Laplacian eigenvectors to generate *stable* and globally *expressive* graph representations. The main difference from previous works is that (i) our method utilizes **learnable** $O(p)$-invariant representations for each Laplacian eigenspace of dimension $p$, which are built upon powerful orthogonal group equivariant neural network layers already well studied in the literature, and that (ii) our method deals with numerically close eigenvalues in a **smooth** fashion, ensuring its better robustness against perturbations. Experiments on various graph learning benchmarks witness the competitive performance of our method, especially its great potential to learn global properties of graphs.","Junru Zhou, Cai Zhou, Xiyuan Wang, Pan Li, Muhan Zhang","~Junru_Zhou1, ~Cai_Zhou2, ~Xiyuan_Wang1, ~Pan_Li2, ~Muhan_Zhang1","graph neural networks, graph Laplacian eigenvectors",learning on graphs and other geometries & topologies,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=KmphHE92wU,https://openreview.net/forum?id=KmphHE92wU,,
kQCHCkNk7s,AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data,"The site conditions that make astronomical observatories in space and on the ground so desirable---cold and dark---demand a physical remoteness that leads to limited data transmission capabilities. Such transmission limitations directly bottleneck the amount of data acquired and in an era of costly modern observatories, any improvements in lossless data compression has the potential scale to billions of dollars worth of additional science that can be accomplished on the same instrument. Traditional lossless methods for compressing astrophysical data are manually designed. Neural data compression, on the other hand, holds the promise of learning compression algorithms end-to-end from data and outperforming classical techniques by leveraging the unique spatial, temporal, and wavelength structures of astronomical images. This paper introduces [AstroCompress](https://huggingface.co/AstroCompress): a neural compression challenge for astrophysics data, featuring four new datasets (and one legacy dataset) with 16-bit unsigned integer imaging data in various modes: space-based, ground-based, multi-wavelength, and time-series imaging. We provide code to easily access the data and benchmark seven lossless compression methods  (three neural and four non-neural, including all practical state-of-the-art algorithms).
Our results on lossless compression indicate that lossless neural compression techniques can enhance data collection at observatories, and provide guidance on the adoption of neural compression in scientific applications. Though the scope of this paper is restricted to lossless compression, we also comment on the potential exploration of lossy compression methods in future studies.","Tuan Truong, Rithwik Sudharsan, Yibo Yang, Peter Xiangyuan Ma, Ruihan Yang, Stephan Mandt, Joshua S. Bloom","~Tuan_Truong3, ~Rithwik_Sudharsan1, ~Yibo_Yang1, ~Peter_Xiangyuan_Ma1, ~Ruihan_Yang1, ~Stephan_Mandt1, ~Joshua_S._Bloom1","astronomy, physics, astrophysics, compression, neural compression, computer vision, remote sensing","applications to physical sciences (physics, chemistry, biology, etc.)",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=kQCHCkNk7s,https://openreview.net/forum?id=kQCHCkNk7s,,
KTyMKIHbg3,A UCB-type of Approach for Nonstationary MDPs with General Function Approximation,"Function approximation has experienced significant success in the field of reinforcement learning (RL). Despite a handful of progress on developing theory for Nonstationary RL with function approximation under structural assumptions, existing work for nonstationary RL with general function approximation \citet{Feng:nonstationary:ICML:2023} studied the confidence-set based algorithm relying on an oracle to select the optimistic state-action value function within the confidence set, which is computationally inefficient. To mitigate the drawback of confidence-set based algorithm, in this work, we propose a popular UCB-type of algorithm for nonstationary RL with general function approximation. Our algorithm features the restart mechanism and a new design of bonus term to handle nonstationarity. We then establish a dynamic regret upper bound for the proposed algorithm, and demonstrate the dynamic regret bound for the examples of nonstationary tabular MDPs and nonstationary linear MDPs. To the best of our knowledge, this is the first UCB-type of algorithm for non-stationary RL with general function approximation. Our theory contributes to the recent progress on RL with general function approximation.","Songtao Feng, Ming Yin, Jie Fu, Jing Yang, Yingbin Liang","~Songtao_Feng1, ~Ming_Yin4, ~Jie_Fu5, ~Jing_Yang3, ~Yingbin_Liang1","nonstationary MDP, general function approximation, eluder dimension",reinforcement learning,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=KTyMKIHbg3,https://openreview.net/forum?id=KTyMKIHbg3,,
Ky02MLYr2r,MLBF-PRS: A MACHINE LEARNING MODEL DE- VELOPMENT AND BENCHMARKING FRAMEWORK FOR POLYGENIC RISK SCORES,"In contrast to other genomic tasks, the development of machine learning-based individual-level, genome-wide predictive models, typically termed polygenic risk scores (PRS), have shown little improvement from the use of complex machine learning (ML) methods. This disparity can be attributed to challenges in accessibility, comparability across studies, and a lack of development and evaluation guidelines that enable reproducibility. Sequence-based genomic tasks benefit from benchmarks, which have proven to be fruitful in the advancement of machine learning model development across domains. 

To overcome the challenges present in the development of ML-based PRS models, we introduce MLBF-PRS, a novel framework as a catalyst to promote and accelerate the development of ML-based solutions. The framework provides flexible Nextflow DSL2 pipelines that enable parallel comparison of ML models (SVMs, random forests, neural networks) against established statistical PRS methods, comprehensive quality control and data preparation modules following PRS-specific best practices, and automated tracking of model parameters, trained weights, and configurations to ensure full reproducibility. 

We describe the usage of MLBF-PRS to showcase how this framework provides accessibility, where, in most cases, the setup and evaluation of PRS models can be time-consuming and require navigation of multiple software tools. The standardised and reproducible dataset-specific benchmarking through MLBF-PRS offers a practical alternative to traditional open benchmarks. We make our framework openly available and continue expanding its capabilities.",,,"Machine Learning, PRS, PGS, Benchmarks, Nextflow, Pipeline, Polygenic score, Polygenic risk score","infrastructure, software libraries, hardware, systems, etc.",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=Ky02MLYr2r,https://openreview.net/forum?id=Ky02MLYr2r,,
LDu822E45Q,EEVEE and GATE: Finding the right benchmarks and how to run them seamlessly,"Model evaluation is a cornerstone of machine learning, guiding model design and progress measurement. Designing generalizable evaluation processes remains a challenge, however, partly due to the vast number of possible domain, task and modality combinations and lack of knowledge of how informative they are. In this paper, we propose EEVEE (Efficient Evaluation process Evolution Engine) - pronounced as \textipa{/'i:vi:/} EE-vee - a method that frames evaluation process design as a learning problem. By analyzing a large number of evaluation metrics from diverse benchmarks and models, EEVEE identifies a smaller subset of tasks with high predictive power over the full set of evaluation metrics, reducing evaluation time. To find the optimal subset maximizing signal while minimizing GPU hours, EEVEE evaluates pre-trained models of various architectures, pretraining schemes, and modalities on diverse downstream tasks and datasets including image classification, segmentation, relational reasoning, zero-shot image-to-text tasks, medical classification and segmentation, video classification, and regression. Our results identify three subsets of benchmarks, with 8, 15 and 21 tasks, providing high quality signal for model generalization. Key benchmarks selected include iWildCam, CLEVR-Math, ACDC, WinoGround, CIFAR100, Fungi, and ADE20K. We structure the subsets into three tiers for 12, 24, and 36 GPU-hour budgets and package them into a unified, efficient, and user-friendly Python framework that we built with the researcher in mind -- which we refer to as the GATE engine. Our experiments reveal ConvNextV2, SigLIP and CLIP as top-performing model encoders, with EfficientNetV2 and ResNext50 excelling in medical tasks and challenging image classification, in particular in Happy Whale Individual classification, ConvNet based models seem to outperform transformer models by a factor of 2.5x, which is surprising. The top performing encoder being ConvNextV2 followed by CLIP seems to agree with other recent large scale evaluations. We also demonstrate the framework's versatility in fine-tuning models from text and audio modalities, paving the way for future cross-modal evaluations.","Antreas Antoniou, Eleni Triantafillou, Hugo Larochelle, Fady Rezk, Sebastien Montella, Kiyoon Kim, Linus Ericsson, Pavlos Vougiouklis, Justin Engelmann, Elliot J. Crowley, Srihari Humbarwadi, Yi Liu, Guang Yang, Jeff Z. Pan, Amos Storkey","~Antreas_Antoniou3, ~Eleni_Triantafillou1, ~Hugo_Larochelle1, ~Fady_Rezk1, ~Sebastien_Montella1, ~Kiyoon_Kim2, ~Linus_Ericsson1, ~Pavlos_Vougiouklis1, ~Justin_Engelmann1, ~Elliot_J._Crowley1, ~Srihari_Humbarwadi1, ~Yi_Liu35, ~Guang_Yang5, ~Jeff_Z._Pan1, ~Amos_Storkey1","multi-modal, benchmarks, machine learning, model evaluation, benchmark frameworks","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=LDu822E45Q,https://openreview.net/forum?id=LDu822E45Q,,
lNIj5FdXsC,Recurrent Distance-Encoding Neural Networks for Graph Representation Learning,"Graph neural networks based on iterative one-hop message-passing have been shown to struggle in harnessing information from distant nodes effectively. Conversely, graph transformers allow each node to attend to all other nodes directly, but suffer from high computational complexity and have to rely on ad-hoc positional encodings to bake in the graph inductive bias. In this paper, we propose a new architecture to reconcile these challenges. Our approach stems from the recent breakthroughs in long-range modeling provided by deep state-space models on sequential data: for a given target node, our model aggregates nodes at different distances and uses a parallelizable linear recurrent network over the chain of distances to provide a natural encoding of its neighborhood structure. With no need for positional encoding, we empirically show that the performance of our model is competitive compared with that of state-of-the-art graph transformers on various benchmarks, at a drastically reduced computational complexity. In addition, we show that our model is theoretically more expressive than one-hop message-passing neural networks.","Yuhui Ding, Antonio Orvieto, Bobby He, Thomas Hofmann","~Yuhui_Ding1, ~Antonio_Orvieto3, ~Bobby_He1, ~Thomas_Hofmann1","Recurrent Neural Networks, Graph Neural Networks",learning on graphs and other geometries & topologies,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=lNIj5FdXsC,https://openreview.net/forum?id=lNIj5FdXsC,,
LnKLT5apxB,SignAligner: Harmonizing Complementary Pose Modalities for Coherent Sign Language Generation,"Sign language generation faces the challenge of producing natural and expressive results due to the complexity of sign language, which involves hand gestures, facial expressions, and body movements. In this work, we propose a novel method called SignAligner for realistic sign language generation. The framework consists of three stages: text-driven multimodal co-generation, online collaborative correction, and realistic video synthesis. First, a joint generator incorporating a Transformer-based text encoder and cross-modal attention simultaneously produces posture, gesture, and body movements from text. Next, an online correction module refines the generated modalities using dynamic loss weighting and cross-modal attention to resolve spatiotemporal conflicts and enhance semantic consistency. Finally, the corrected poses are input into a pre-trained video generation network to synthesize high-fidelity sign language videos. Additionally, we introduce a dataset extension scheme that derives three new landmark representations (i.e., Pose, Hamer, and Smplerx) via pre-trained models, validated on PHOENIX14T and CSL-daily. Extensive experiments show that SignAligner significantly improves the accuracy and expressiveness of generated sign videos.",,,"sign language generation, sign language production","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=LnKLT5apxB,https://openreview.net/forum?id=LnKLT5apxB,,
lYRkGZZi9D,Analysis of Linear Mode Connectivity via Permutation-Based Weight Matching: With Insights into Other Permutation Search Methods,"Recently, Ainsworth et al. (2023) showed that using weight matching (WM) to minimize the $L^2$ distance in a permutation search of model parameters effectively identifies permutations that satisfy linear mode connectivity (LMC), where the loss along a linear path between two independently trained models with different seeds remains nearly constant. This paper analyzes LMC using WM, which is useful for understanding stochastic gradient descent's effectiveness and its application in areas like model merging. We first empirically show that permutations found by WM do not significantly reduce the $L^2$ distance between two models, and the occurrence of LMC is not merely due to distance reduction by WM itself. We then demonstrate that permutations can change the directions of the singular vectors, but not the singular values, of the weight matrices in each layer. This finding shows that permutations found by WM primarily align the directions of singular vectors associated with large singular values across models. This alignment brings the singular vectors with large singular values, which determine the model's functionality, closer between the original and merged models, allowing the merged model to retain functionality similar to the original models, thereby satisfying LMC. This paper also analyzes activation matching (AM) in terms of singular vectors and finds that the principle of AM is likely the same as that of WM. Finally, we analyze the difference between WM and the straight-through estimator (STE), a dataset-dependent permutation search method, and show that WM can be more advantageous than STE in achieving LMC among three or more models.","Akira Ito, Masanori Yamada, Atsutoshi Kumagai","~Akira_Ito1, ~Masanori_Yamada1, ~Atsutoshi_Kumagai2","linear mode connectivity, deep learning, permutation symmetry","other topics in machine learning (i.e., none of the above)",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=lYRkGZZi9D,https://openreview.net/forum?id=lYRkGZZi9D,,
M0czNtnviA,PRIVET: PRIVacy metric based on Extreme value Theory,"Deep generative models are often trained on sensitive data, such as genetic sequences, health data, or more broadly, any copyrighted, licensed or protected content. This raises critical concerns around privacy-preserving synthetic data, and more specifically around privacy leakage, an issue closely tied to overfitting. Existing methods almost exclusively rely on global criteria to estimate the risk of privacy failure associated to a model, offering only quantitative non interpretable insights. The absence of rigorous evaluation methods for data privacy at the sample-level may hinder the practical deployment of synthetic data in real-world applications. Using extreme value statistics on nearest-neighbor distances, we propose PRIVET, a generic sample-based, modality-agnostic algorithm that assigns an individual privacy leak score to each synthetic sample. We empirically demonstrate that PRIVET reliably detects instances of memorization and privacy leakage across diverse data modalities, including settings with very high dimensionality, limited sample sizes such as genetic data and even under underfitting regimes. We compare our method to existing approaches under controlled settings and show its advantage in providing both dataset level and sample level assessments through qualitative and quantitative outputs. Additionally, our analysis reveals limitations in existing computer vision embeddings to yield perceptually meaningful distances when identifying near-duplicate samples.",,,"Generative modeling, privacy, extreme value statistics","alignment, fairness, safety, privacy, and societal considerations",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=M0czNtnviA,https://openreview.net/forum?id=M0czNtnviA,,
m6W5SfQXrT,High-Fidelity and Generalizable Neural Surface Reconstruction with Sparse Scene Representations,"Generalizable neural surface reconstruction has become a compelling technique at reconstructing 3D scenes from sparse input views without per-scene optimization. In these methods, dense 3D feature volumes has proven very effective as a global scene representation. Unfortunately, this representation severely limits their high-resolution modeling abilities and reconstruction accuracies because memory requirements scale cubically with voxel resolution. In this paper, we propose a novel sparse-representation approach that dramatically improves memory efficiency and allows for more accurate surface reconstructions. Our method employs a two-stage pipeline: We first train a neural network to predict voxel occupancy probabilities from the given posed images, then we restrict feature computation and volume rendering to the sparse voxels with sufficiently high occupancy estimates. To support this sparse representation, we develop specialized algorithms for efficient sampling, feature aggregation, and spatial querying that overcome the dense-volume assumptions of existing approaches. Extensive experiments on standard benchmarks demonstrate that our sparse representation enables scene reconstruction at a $512^3$ resolution, compared to the typical $128^3$ resolution possible with existing methods on similar hardware. We also achieve superior reconstruction accuracy compared to current state-of-the-art approaches. Our work establishes sparse neural representations as a promising direction for scalable, high-quality 3D reconstruction.",,,"neural surface reconstruction, neural radiance fields, multi-view stereo, 3D reconstruction","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=m6W5SfQXrT,https://openreview.net/forum?id=m6W5SfQXrT,,
M7CblLwJB8,"AutoCustomization: A Unified Framework for Effortless, Selective LLM Bias and Style Finetuning","Large language models are transforming the landscape of applications, with their influence poised to expand. One important practical challenge is how to selectively customize models to align with specific expectations, such as tone, formality, or underlying biases. To solve this task, we develop AutoCustomization. The key to our approach is leveraging the vast knowledge encoded in modern language models to construct fine-tuning datasets focused on a specific customization axis in contrast to prior methods, which depend primarily on tediously constructed libraries of prompts. AutoCustomization demonstrates several desirable properties. It is universally applicable to any bias axis (e.g., political, stylistic). It is efficient with small automatically generated datasets and short fine-tuning. It allows for precise monitoring of the resulting bias change with our BiasShift evaluation metric proven to be alligned with human perception, generalizable to held-out aspects, and selective in preserving other model capabilities. We verify AutoCustomization through human evaluation and show that it outperforms existing prompting techniques while being simpler.","Jaroslaw Kochanowicz, Mateusz Olko, Gracjan Góral, Konrad Szewczyk, Krzysztof Dziedzic, Piotr Miłoś","~Jaroslaw_Kochanowicz1, ~Mateusz_Olko1, ~Gracjan_Góral1, ~Konrad_Szewczyk1, ~Krzysztof_Dziedzic1, ~Piotr_Miłoś1","large language models, model customization","other topics in machine learning (i.e., none of the above)",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=M7CblLwJB8,https://openreview.net/forum?id=M7CblLwJB8,,
mEBSeSk49H,On the Convergence of Adam under Non-uniform Smoothness: Separability from SGDM and Beyond,"This paper aims to clearly distinguish between Stochastic Gradient Descent with Momentum (SGDM) and Adam in terms of their convergence rates. We demonstrate that Adam achieves a faster convergence compared to SGDM under the condition of non-uniformly bounded smoothness. Our findings reveal that: (1) in deterministic environments, Adam can attain the known lower bound for the convergence rate of deterministic first-order optimizers, whereas the convergence rate of Gradient Descent with Momentum (GDM) has higher order dependence on the initial function value; (2) in stochastic setting, Adam's convergence rate upper bound matches the lower bounds of stochastic first-order optimizers, considering both the initial function value and the final error, whereas there are instances where SGDM fails to converge with any learning rate. These insights distinctly differentiate Adam and SGDM regarding their convergence rates. Additionally, by introducing a novel stopping-time based technique, we further prove that if we consider the minimum gradient norm during iterations, the corresponding convergence rate can match the lower bounds across all problem hyperparameters. The technique can also help proving that Adam with a specific hyperparameter scheduler is parameter-agnostic, which hence can be of independent interest.","Bohan Wang, Huishuai Zhang, Qi Meng, Ruoyu Sun, Zhi-Ming Ma, Wei Chen","~Bohan_Wang1, ~Huishuai_Zhang3, ~Qi_Meng1, ~Ruoyu_Sun1, ~Zhi-Ming_Ma1, ~Wei_Chen1","Adam, Convergence, Separability, Non-uniform Smoothness",learning theory,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=mEBSeSk49H,https://openreview.net/forum?id=mEBSeSk49H,,
mMLI1u1UvQ,Estimating structural shifts in graph domain adaptation via pairwise likelihood maximization,"Graph domain adaptation (GDA) emerges as an important problem in graph machine learning when the distribution of the source graph data used for training is different from that of the target graph data used for testing. While much of the prior work on GDA has focused on the idea of aligning node representations across source and target domains, recent studies show that such approaches can be suboptimal in the presence of conditional structure shift (CSS), where the distribution of graph edges conditioned on labels changes across domains. In this work, we develop a unified framework to solve CSS and show that existing GDA methods for CSS arise as special cases of our framework. This framework further allows us to develop a new method, Pairwise-Likelihood maximization for graph Structure Alignment (PLSA), which uses rich information from pairwise nodes and edges to improve the estimation of target connection probabilities. We establish conditions under which our method is identifiable and introduce a simple edge reweighting scheme based on importance weights to align the source and target graphs. Theoretically, under the contextual stochastic block model (CSBM), we derive finite-sample guarantees using recent results in matrix concentration inequalities for U-statistics. We complement our theoretical results with empirical studies that demonstrate the effectiveness of our method.",,,"Graph domain adaptation, node classification, graph structure shift, distribution matching, U-statistics","transfer learning, meta learning, and lifelong learning",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=mMLI1u1UvQ,https://openreview.net/forum?id=mMLI1u1UvQ,,
N1E7rFZJGH,Route Before Retrieve: Activating Latent Routing Abilities of LLMs for RAG vs. Long Context Selection,"Recent advances in large language models (LLMs) have expanded the context window to beyond 128K tokens, enabling long-document understanding and multi-source reasoning. A key challenge, however, lies in choosing between **retrieval-augmented generation (RAG)** and **long-context (LC)** strategies: RAG is efficient but constrained by retrieval quality, while LC supports global reasoning at higher cost and with position sensitivity. Existing methods such as *Self-Route* adopt failure-driven fallback from RAG to LC, but remain passive, inefficient, and hard to interpret. We propose **Pre-Route**, a proactive routing framework that performs structured reasoning *before* answering. Using lightweight metadata (e.g., document type, length, initial snippet), Pre-Route enables task analysis, coverage estimation, and information-need prediction, producing explainable and cost-efficient routing decisions. Our study shows three key findings: (i) LLMs possess latent routing ability that can be reliably activated with guidelines, allowing single-sample performance to approach that of multi-sample (Best-of-N) results; (ii) linear probes reveal that structured prompts sharpen the separability of the ""optimal routing dimension"" in representation space; and (iii) distillation transfers this reasoning structure to smaller models for lightweight deployment. Experiments on LaRA (in-domain) and LongBench-v2 (OOD) confirm that Pre-Route outperforms Always-RAG, Always-LC, and Self-Route baselines, achieving superior overall cost-effectiveness.",,,"Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), Long-Context, Context Selection, Structured Reasoning","foundation or frontier models, including LLMs",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=N1E7rFZJGH,https://openreview.net/forum?id=N1E7rFZJGH,,
nGLefuWScZ,FITS: Conditional Diffusion Model for Irregular Time Series Forecasting with Pseudo-future Exogenous Covariates,"Irregular multivariate time series (IMTS) present unique challenges due to non-uniform intervals and different sampling rates. While existing methods struggle to capture both long-term dynamics and cross-channel dependencies under such irregularities, we tackle this by formulating time series forecasting as a conditional generation problem and introducing FITS, a conditional diffusion model for IMTS forecasting that leverages pseudo-future exogenous covariates. Our approach incorporates two key innovations. First, we propose a novel density-aware adaptive patching scheme that generates data-driven segments with dynamic boundaries determined by the information density. This scheme overcomes the limitations of traditional fixed-length or fixed-span segmentation in preserving continuous local semantics and modeling inter-time series correlations. Second, we develop a transformer-based prior knowledge extractor that captures forward-looking covariate dependencies via a novel cross-variate attention mechanism. The transformer structure is integrated into the conditional diffusion generative process as a unified framework, enabling precise distributional forecasting for IMTS. Extensive experiments on six datasets with four evaluation metrics validate the effectiveness of FITS.",,,time series forecasting,learning on time series and dynamical systems,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=nGLefuWScZ,https://openreview.net/forum?id=nGLefuWScZ,,
nkp4LdWDOr,DiffuDETR: Rethinking Detection Transformers with Diffusion Process,"In this paper, we present DiffuDETR, a novel approach that formulates object detection as a conditional object query generation task, conditioned on the image and a set of noisy reference points. We integrate DETR-based models with denoising diffusion training to generate object queries' reference points from a prior gaussian distribution. We propose two variants: DiffuDETR, built on top of the Deformable DETR decoder, and DiffuDINO, based on DINO’s decoder with contrastive denoising queries (CDNs). To improve inference efficiency, we further introduce a lightweight sampling scheme that requires only multiple forward passes through the decoder. Our method demonstrates consistent improvements across multiple backbones and datasets, including COCO2017, LVIS, and V3Det, surpassing the performance of their respective baselines, with notable gains in complex and crowded scenes. Using ResNet-50 backbone we observe a +1.0 in COCO-val reaching 51.9 mAP on DiffuDINO compared to 50.9 mAP of the DINO. We also observe similar improvements on LVIS and V3DET datasets with +2.4 and +2.2 respectively. Code will be released upon acceptance.",,,"Object Detection, Diffusion Models, DETR, Query Generation, Deep Learning","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=nkp4LdWDOr,https://openreview.net/forum?id=nkp4LdWDOr,,
NnSLujLSfn,Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence,"Large Language Models (LLMs) are intensively used to assist security analysts in counteracting the rapid exploitation of cyber threats, wherein LLMs offer cyber threat intelligence (CTI) to support vulnerability assessment and incident response. While recent work has shown that LLMs can support a wide range of CTI tasks such as threat analysis, vulnerability detection, and intrusion defense, significant performance gaps persist in practical deployments. In this paper, we investigate the intrinsic vulnerabilities of LLMs in CTI, focusing on challenges that arise from the nature of the threat landscape itself rather than the model architecture. Using large-scale evaluations across multiple CTI benchmarks and real-world threat reports, we introduce a novel categorization methodology that integrates stratification, autoregressive refinement, and human-in-the-loop supervision to reliably analyze failure instances. Through extensive experiments and human inspections, we reveal three fundamental vulnerabilities: spurious correlations, contradictory knowledge, and constrained generalization, that limit LLMs in effectively supporting CTI. Subsequently, we provide actionable insights for designing more robust LLM-powered CTI systems to facilitate future research.",,,"Large Language Model, Cybersecurity, Cyber Threat Intelligence (CTI), Failure Analysis, LLM Robustness","alignment, fairness, safety, privacy, and societal considerations",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=NnSLujLSfn,https://openreview.net/forum?id=NnSLujLSfn,,
nNYA7tcJSE,ViBiDSampler: Enhancing Video Interpolation Using Bidirectional Diffusion Sampler,"Recent progress in large-scale text-to-video (T2V) and image-to-video (I2V) diffusion models has greatly enhanced video generation, especially in terms of keyframe interpolation. However, current image-to-video diffusion models, while powerful in generating videos from a single conditioning frame, need adaptation for two-frame (start \& end) conditioned generation, which is essential for effective bounded interpolation. Unfortunately, existing approaches that fuse temporally forward and backward paths in parallel often suffer from off-manifold issues, leading to artifacts or requiring multiple iterative re-noising steps. In this work, we introduce a novel, bidirectional sampling strategy to address these off-manifold issues without requiring extensive re-noising or fine-tuning. Our method employs sequential sampling along both forward and backward paths, conditioned on the start and end frames, respectively, ensuring more coherent and on-manifold generation of intermediate frames. Additionally, we incorporate advanced guidance techniques, CFG++ and DDS, to further enhance the interpolation process. By integrating these, our method achieves state-of-the-art performance, efficiently generating high-quality, smooth videos between keyframes. On a single 3090 GPU, our method can interpolate 25 frames at 1024$\times$576 resolution in just 195 seconds, establishing it as a leading solution for keyframe interpolation.
Project page: https://vibidsampler.github.io/","Serin Yang, Taesung Kwon, Jong Chul Ye","~Serin_Yang1, ~Taesung_Kwon1, ~Jong_Chul_Ye1","Keyframe interpolation, Stable video diffusion, Bidirectional diffusion sampling",generative models,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=nNYA7tcJSE,https://openreview.net/forum?id=nNYA7tcJSE,,
Ny150AblPu,Exposing Text-Image Inconsistency Using Diffusion Models,"In the battle against widespread online misinformation, a growing problem is text-image inconsistency, where images are misleadingly paired with texts with different intent or meaning. Existing classification-based methods for text-image inconsistency can identify contextual inconsistencies but fail to provide explainable justifications for their decisions that humans can understand. Although more nuanced, human evaluation is impractical at scale and susceptible to errors. To address these limitations, this study introduces D-TIIL (Diffusion-based Text-Image Inconsistency Localization), which employs text-to-image diffusion models to localize semantic inconsistencies in text and image pairs. These models, trained on large-scale datasets act as ``omniscient"" agents that filter out irrelevant information and incorporate background knowledge to identify inconsistencies. In addition, D-TIIL uses text embeddings and modified image regions to visualize these inconsistencies. To evaluate D-TIIL's efficacy, we introduce a new TIIL dataset containing 14K consistent and inconsistent text-image pairs. Unlike existing datasets, TIIL enables assessment at the level of individual words and image regions and is carefully designed to represent various inconsistencies. D-TIIL offers a scalable and evidence-based approach to identifying and localizing text-image inconsistency, providing a robust framework for future research combating misinformation.","Mingzhen Huang, Shan Jia, Zhou Zhou, Yan Ju, Jialing Cai, Siwei Lyu","~Mingzhen_Huang2, ~Shan_Jia1, ~Zhou_Zhou4, ~Yan_Ju1, ~Jialing_Cai1, ~Siwei_Lyu1","inconsistency detection, multi-modal learning, diffusion models","societal considerations including fairness, safety, privacy",ICLR 2024 poster,2024,https://openreview.net/pdf?id=Ny150AblPu,https://openreview.net/forum?id=Ny150AblPu,,
o4XNuQ5qft,Optimum Shifting to Stabilize Training and Improve Generalization of Deep Neural Networks,"Recent studies have shown that generalization is correlated with the sharpness of the loss landscape and flat minima suggests a better generalization ability than sharp minima.
In this paper, we introduce a method called optimum shifting (OS), which changes the parameters of a neural network from sharper minima to a flatter one while maintaining the same training loss.
Our approach is based on the observation that when the input and output of a neural network are fixed, the matrix multiplications within the network can be treated as systems of under-determined linear equations, enabling adjustment of parameters in solution space.
This can be accomplished by solving a constrained optimization problem, which is easy to implement.
We prove that the minima we move to will be flatter than the original one. 
Furthermore, we introduce a practical stochastic optimum shifting (SOS) technique utilizing neural collapse theory to reduce computational costs and provide more degrees of freedom for optimum shifting. 
In our experiments, we present various DNNs (e.g., VGG, ResNet, DenseNet and Vit) on the Cifar 10/100 and Tiny-Imagenet datasets to validate the effectiveness of our method.","Zhou Yuyan, Ye Li, Sheng-Jun Huang","~Zhou_Yuyan2, ~Ye_Li6, ~Sheng-Jun_Huang1",Deep Networks; Optimization; Generalization;,optimization,Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=o4XNuQ5qft,https://openreview.net/forum?id=o4XNuQ5qft,,
ogKE7LcvW6,"Loss Landscape of Shallow ReLU-like Neural Networks: Stationary Points, Saddle Escape, and Network Embedding","In this paper, we study the loss landscape of one-hidden-layer neural networks with ReLU-like activation functions trained with the empirical squared loss using gradient descent (GD). We identify the stationary points of such networks, which significantly slow down loss decrease during training. To capture such points while accounting for the non-differentiability of the loss, the stationary points that we study are directional stationary points, rather than other notions like Clarke stationary points. We show that, if a stationary point does not contain ""escape neurons"", which are defined with first-order conditions, it must be a local minimum. Moreover, for the scalar-output case, the presence of an escape neuron guarantees that the stationary point is not a local minimum. Our results refine the description of the *saddle-to-saddle* training process starting from infinitesimally small (vanishing) initialization for shallow ReLU-like networks: By precluding the saddle escape types that previous works did not rule out, we advance one step closer to a complete picture of the entire dynamics. Moreover, we are also able to fully discuss how network embedding, which is to instantiate a narrower network with a wider network, reshapes the stationary points.","Frank Zhengqing Wu, Berfin Simsek, François Gaston Ged","~Frank_Zhengqing_Wu1, ~Berfin_Simsek1, ~François_Gaston_Ged1","loss landscape, non-smooth, training dynamics, network embedding, over-parameterization, neural network",optimization,ICLR 2025 Poster,2025,https://openreview.net/pdf?id=ogKE7LcvW6,https://openreview.net/forum?id=ogKE7LcvW6,,
Pa7oHHhqFa,Language Models as Noisy Experts for Sequential Causal Discovery,"Causal discovery from observational data typically assumes access to complete data and availability of domain experts. In practice, data often arrive in batches, are subject to sampling bias, and expert knowledge is scarce. Language Models (LMs) offer a surrogate for expert knowledge but suffer from hallucinations, inconsistencies, and bias. We present a hybrid framework that bridges these gaps by adaptively integrating sequential batch data with LM-derived noisy, expert knowledge while accounting for both *data-induced* and *LM-induced* biases. We propose a representation shift from Directed Acyclic Graph (DAG) to Partial Ancestral Graph (PAG), that accommodates ambiguities within a coherent framework, allowing grounding the *global* LM knowledge in *local* observational data. To guide LM interactions, we use a sequential optimization scheme that adaptively queries the most informative edges. Across varied datasets, we outperform prior work in structural accuracy and extend to parameter estimation, showing robustness to LM noise.",,,"Causal Discovery, Sequential Data, Noisy Expert, Language Model","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=Pa7oHHhqFa,https://openreview.net/forum?id=Pa7oHHhqFa,,
PBXhT2pdvs,EWE: An Agentic Framework for Extreme Weather Analysis,"Extreme weather events pose escalating risks to global society, underscoring the urgent need to unravel their underlying physical mechanisms. Yet the prevailing expert-driven, labor-intensive diagnostic paradigm has created a critical analytical bottleneck, stalling scientific progress. While AI for Earth Science has achieved notable advances in prediction, the equally essential challenge of automated diagnostic reasoning remains largely unexplored. We present the Extreme Weather Expert (EWE), the first intelligent agent framework dedicated to this task. EWE emulates expert workflows through knowledge-guided planning, closed-loop reasoning, and a domain-tailored meteorological toolkit. It autonomously produces and interprets multimodal visualizations from raw meteorological data, enabling comprehensive diagnostic analyses. To catalyze progress, we introduce the first benchmark for this emerging field, comprising a curated dataset of 103 high-impact events and a novel step-wise evaluation metric. EWE marks a step toward automated scientific discovery and  offers the potential to democratize expertise and intellectual resources, particularly for developing nations vulnerable to extreme weather.",,,"Extreme Weather Analysis, AI for Science","applications to physical sciences (physics, chemistry, biology, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=PBXhT2pdvs,https://openreview.net/forum?id=PBXhT2pdvs,,
pcqyhDvG0i,Curvature Meets Bispectrum: A Correspondence Theory for Transformer Gauge Invariants,"Transformers contain substantial parameter redundancies: many weight settings compute the same function. Characterizing these equivalences is key for model comparison and optimization. We prove a quantitative correspondence linking differential-geometric and harmonic-analytic invariants for neural network symmetries. We prove that Fisher-Rao curvature on the parameter-to-function quotient for multi-head attention provides a lower bound for permutation-bispectral energy in a linearized regime, revealing these two invariants as complementary aspects of the same underlying structure. Empirical validation across model scales from 4 to 24 heads demonstrates 98.9% validity of the theoretical bound, with the correspondence persisting through 10,000 training steps. By bridging differential geometry and harmonic analysis, we provide both theoretical insight into Transformer symmetries and a practical geometric framework for identifying functionally equivalent models. We report correspondence in native units, with curvature as a squared Frobenius norm throughout.",,,"Transformer, Diffusion, Gauge Symmetry, Fisher-Rao curvature, Bispectral invariants, Multi-head attention",learning theory,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=pcqyhDvG0i,https://openreview.net/forum?id=pcqyhDvG0i,,
pkwq3F7gUp,MILPnet: A Multi-Scale Architecture with Geometric Feature Sequence Representations for Advancing MILP Problems,"We propose MILPnet, a multi-scale hybrid attention framework that models Mixed Integer Linear Programming (MILP) problems as geometric sequences rather than graphs. This approach directly addresses the challenge of Foldable MILP instances, a class of problems that graph-based models, specifically Graph Neural Networks (GNNs), fail to distinguish due to expressiveness limits imposed by the Weisfeiler-Lehman test. By representing MILPs through sequences of constraint and objective features, MILPnet captures both local and global geometric structure using a theoretically grounded multi-scale attention mechanism. We theoretically prove that MILPnet can approximate feasibility, optimal objective value, and optimal solution mappings over a measurable topological space with arbitrarily small error. Empirically, MILPnet outperforms graph-based methods by multiple orders of magnitude in feasibility prediction accuracy and convergence speed on Foldable MILPs, while using significantly fewer parameters. It also generalizes effectively across problem scales and demonstrates strong performance on real-world MILP benchmarks when integrated into an end-to-end solver pipeline.Our code is available with the https://anonymous.4open.science/r/MILPnet-2BD1/",,,MILP;optimal,optimization,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=pkwq3F7gUp,https://openreview.net/forum?id=pkwq3F7gUp,,
PRR120c01e,Interpreting LLM-as-a-Judge Policies via Verifiable Global Explanations,"Using LLMs to evaluate text, that is, LLM-as-a-judge, is increasingly being used at scale to augment or even replace human annotations. As such, it is imperative that we understand the potential biases and risks of doing so. In this work, we propose an approach for extracting high-level concept-based global policies from LLM-as-a-Judge. Our approach consists of two algorithms: 1) CLoVE (Contrastive Local
Verifiable Explanations), which generates verifiable, concept-based, contrastive local explanations and 2) GloVE (Global Verifiable Explanations), which uses iterative clustering, summarization and verification to condense local rules into a global policy. We evaluate GloVE on seven standard benchmarking datasets for content harm detection. We find that the extracted global policies are highly faithful
to decisions of the LLM-as-a-Judge. Additionally, we evaluated the robustness of global policies to text perturbations and adversarial attacks. Finally, we conducted a user study to evaluate user understanding and satisfaction with global policies.",,,"LLM-as-a-Judge, Interpretability, Global Explanations, Local Explanations",interpretability and explainable AI,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=PRR120c01e,https://openreview.net/forum?id=PRR120c01e,,
pX6B28ynNh,CMT-Benchmark: A Benchmark for Condensed Matter Theory Built by Expert Researchers,"Large language models (LLMs) have demonstrated remarkable progress in coding and mathematical problem-solving; however, evaluation on advanced research-level problems in the hard sciences remains scarce. 
To fill this gap, we present \cmt, a dataset of 50 original problems covering condensed matter theory (CMT) at the level of an expert researcher. The topics cover analytical and computational approaches commonly used in quantum many-body physics as well as classical statistical mechanics. This dataset was designed and verified by a panel of expert researchers from around the world. 
We built the dataset through a collaborative environment that challenges the panel to write and refine difficult problems that the panel would like their research assistants to be able to solve, with topics including Hartree-Fock mean-field theory, exact diagonalization, quantum Monte Carlo, density matrix renormalization group, quantum statistical mechanics, classical statistical mechanics, and model building. We evaluate different LLMs by programmatically checking LLM-generated solutions against expert-supplied ground truth. 
For this, we developed machine-grading mechanisms that are suitable for advanced physics research problems. 
For example, we handle non-commuting operators that are essential for quantum many-body problems by symbolic manipulation and normal ordering. 
Our evaluations show that frontier models struggle with all of the problems in the dataset, highlighting a gap in the physical reasoning skills of current LLMs. Notably, experts identified strategies for creating increasingly difficult problems by interacting with the LLMs and exploiting common failure modes. 
While the highest-performing model, GPT5, correctly solves 30\% of the problems, average performance across 17 models (GPT, Gemini, Claude, DeepSeek, and Llama classes) is only 11.4$\pm$2.1\%.  Moreover, our benchmark contains 18 problems that {\it not a single one} of the 17 models can correctly solve, and 26 problems that are solved by {\it at most} one model. 
These currently unsolvable problems span the fields of Quantum Monte Carlo, Variational Monte Carlo, and Density Matrix Renormalization Group. 
The answers sometimes violate fundamental symmetries or have unphysical scaling dimensions. We believe that this benchmark set provides valuable guidance for the future development of language models, aiming to achieve the goal of AI research assistants and tutors.",,,"large language model, statistical mechanics, benchmark, evaluation, numerical methods, scientific problem solving, condensed matter physics, quantum physics",datasets and benchmarks,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=pX6B28ynNh,https://openreview.net/forum?id=pX6B28ynNh,,
q8fTgw8e5E,Translation Heads: Unveiling Attention's Role in LLM Multilingual Translation,"Recently, large language models (LLMs) have made remarkable progress, with multilingual capability emerging as a core foundational strengths. However, the internal mechanisms by which these models perform translation remain incompletely understood. In this paper, we elucidate the relationship between the attention mechanism in LLMs and their translation abilities. We find that certain attention heads, which we term translation heads, are specifically responsible for mapping tokens from the source language to the target language during inference. Through a systematic investigation across various models, we confirm that these translation heads exhibit several key characteristics: (1) Universality: They are present in all LLMs we studied. (2) Sparsity: They constitute only a small fraction of all attention heads. (3) Consistency: The set of translation heads activated by the model shows strong consistency across different language pairs. (4) Causality: Interventionally removing these heads leads to a sharp decline in the model's translation performance, while randomly removing non-translation heads has little impact on translation ability. (5) Functional Specificity: Ablating translation heads disproportionately harms translation but has a varied impact on other multilingual tasks. We also traced the formation of translation heads during pre-training, revealing an evolutionary path of rapid proliferation, stabilization, and eventual pruning. Furthermore we leverage these translation heads to filter multilingual training data, and our experiments show that these datas significantly enhance translation capabilities of the models.",,,"LLM, Multilinguistic, Interpretability","foundation or frontier models, including LLMs",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=q8fTgw8e5E,https://openreview.net/forum?id=q8fTgw8e5E,,
QDmoLEJifR,Behavioral Embeddings of Programs: A Quasi-Dynamic Approach for Optimization Prediction,"Learning effective numerical representations, or embeddings, of programs is a fundamental prerequisite for applying machine learning to automate and enhance compiler optimization. Prevailing paradigms, however, present a dilemma. Static representations, derived from source code or intermediate representation (IR), are efficient and deterministic but offer limited insight into how a program will behave or evolve under complex code transformations. Conversely, dynamic representations, which rely on runtime profiling, provide profound insights into performance bottlenecks but are often impractical for large-scale tasks due to prohibitive overhead and inherent non-determinism. This paper transcends this trade-off by proposing a novel quasi-dynamic framework for program representation. The core insight is to model a program's optimization sensitivity. We introduce the Program Behavior Spectrum, a new representation generated by probing a program's IR with a diverse set of optimization sequences and quantifying the resulting changes in its static features. To effectively encode this high-dimensional, continuous spectrum, we pioneer a compositional learning approach. Product Quantization is employed to discretize the continuous reaction vectors into structured, compositional sub-words. Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to learn the deep contextual grammar of these behavioral codes. Comprehensive experiments on two representative compiler optimization tasks---Best Pass Prediction and -Oz Benefit Prediction---demonstrate that our method outperforms state-of-the-art static baselines. Our code is publicly available at https://anonymous.4open.science/r/PREP-311F/.",,,"Program Representation, Compiler Optimization, Behavioral Embedding","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=QDmoLEJifR,https://openreview.net/forum?id=QDmoLEJifR,,
QiUitwJDKI,InnateCoder: Learning Programmatic Options with Foundation Models,"Outside of transfer learning settings, reinforcement learning agents start their learning process from a clean slate. As a result, such agents have to go through a slow process to learn even the most obvious skills required to solve a problem. In this paper, we present InnateCoder, a system that leverages human knowledge encoded in foundation models to provide programmatic policies that encode ""innate skills"" in the form of temporally extended actions, or options. In contrast to existing approaches to learning options, InnateCoder learns them from the general human knowledge encoded in foundation models in a zero-shot setting, and not from the knowledge the agent gains by interacting with the environment. Then, InnateCoder searches for a programmatic policy by combining the programs encoding these options into a larger and more complex program. We hypothesized that InnateCoder's scheme of learning and using options could improve the sampling efficiency of current methods for synthesizing programmatic policies. We evaluated our hypothesis in MicroRTS and Karel the Robot, two challenging domains. Empirical results support our hypothesis, since they show that InnateCoder is more sample efficient than versions of the system that do not use options or learn the options from experience. The policies InnateCoder learns are competitive and often outperform current state-of-the-art agents in both domains.","Rubens O. Moraes, Quazi Asif Sadmine, Hendrik Baier, Levi Lelis","~Rubens_O._Moraes2, ~Quazi_Asif_Sadmine1, ~Hendrik_Baier2, ~Levi_Lelis1","programmatic policies, reinforcement learning, options",reinforcement learning,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=QiUitwJDKI,https://openreview.net/forum?id=QiUitwJDKI,,
qO1cJBh5BX,Probabilistic DiffusionNet: A geometry informed probabilistic generative surrogate for PDEs,"We propose a probabilistic generative extension of the DiffusionNet architecture, widely used for surface learning tasks, by introducing latent random variables derived from a stochastic reformulation of the underlying diffusion process. The resulting probabilistic model can be used as a resolution-invariant and uncertainty-aware surrogate for the trace solution map of PDEs whose boundary conditions are determined by surface geometry. Such a surrogate can expedite and inform typical engineering design and optimisation processes that require computationally burdensome computational fluid dynamics (CFD) analysis pipelines. We demonstrate that the proposed architecture produces superior uncertainty quantification (UQ) performance on standard CFD datasets without sacrificing predictive accuracy, while enjoying lower computational cost compared to other prevalent geometry-informed PDE surrogates endowed with UQ capabilities.",,,"SPDE, DiffusionNet, PDE, CFD, UQ, Variational Inference, VAE, Generative Models, Stochastic Process, Gaussian Process, Neural Operators","probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=qO1cJBh5BX,https://openreview.net/forum?id=qO1cJBh5BX,,
qSak1Hjfdq,All-day Multi-scenes Lifelong Vision-and-Language Navigation with Tucker Adaptation,"Deploying vision-and-language navigation (VLN) agents requires adaptation across diverse scenes and environments, but fine-tuning on a specific scenario often causes catastrophic forgetting in others, which severely limits flexible long-term deployment. We formalize this challenge as the all-day multi-scenes lifelong VLN (AML-VLN) problem. Existing parameter-efficient adapters (e.g., LoRA and its variants) are limited by their two-dimensional matrix form, which fails to capture the multi-hierarchical navigation knowledge spanning multiple scenes and environments. To address this, we propose Tucker Adaptation (TuKA), which represents the multi-hierarchical navigation knowledge as a high-order tensor and leverages Tucker decomposition to decouple the knowledge into shared subspaces and scenario-specific experts. We further introduce a decoupled knowledge incremental learning strategy to consolidate shared subspaces while constraining specific experts for decoupled lifelong learning. Building on TuKA, we also develop a VLN agent named AlldayWalker, which continually learns across multiple navigation scenarios, achieving all-day multi-scenes navigation. Extensive experiments show that AlldayWalker consistently outperforms state-of-the-art baselines.",,,"Tensor Decomposition, Vision-and-Language Navigation, Lifelong Learning","applications to robotics, autonomy, planning",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=qSak1Hjfdq,https://openreview.net/forum?id=qSak1Hjfdq,,
RM8JAy8wmP,ChainInfer: A Joint Method for Inferring Missing AI Supply Chain Information,"The modern AI ecosystem forms an intricate AI supply chain, where models, datasets, and software components are deeply interconnected. Incomplete or inconsistent metadata on platforms such as Hugging Face and Kaggle leaves critical gaps in provenance, hindering reproducibility, risk management, and governance. To address this, we formalize AI supply chain inference as a coupled graph learning problem: link prediction to recover missing dependencies and edge classification to determine their semantic types. We propose ChainInfer, a hybrid architecture that integrates graph neural networks for local structural reasoning with graph transformers for global context, trained end-to-end on attributed supply chain graphs. Using a benchmark of 200K models from Hugging Face, ChainInfer outperforms GNN-, Transformer-, and ensemble baselines, achieving 0.93 joint accuracy while remaining efficient. Moreover, ChainInfer generalizes inductively to Kaggle, retaining 0.90 accuracy without retraining. These results demonstrate ChainInfer as a practical framework for scalable, accurate, and transferable AI supply chain provenance inference.",,,"AI supply chain, graph neural network, graph transformer, link prediction, edge classification",learning on graphs and other geometries & topologies,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=RM8JAy8wmP,https://openreview.net/forum?id=RM8JAy8wmP,,
RZ8esDBqMJ,A tale of two tails: Preferred and anti-preferred natural stimuli in visual cortex,"A fundamental quest in neuroscience is to find the preferred stimulus of a sensory neuron. This search lays the foundation for understanding how selectivity emerges in the primate visual stream---from simple edge-detecting neurons to highly-selective ""grandmother"" neurons---as well as for the architectures and activation functions of deep neural networks. The prevailing notion is that a visual neuron primarily responds to a single preferred visual feature like an oriented edge or object identity, resulting in a ""one-tailed"" distribution of responses to natural images. However, surprisingly, we instead find ""two-tailed"" response distributions of neurons in higher-order visual cortex (macaque V4), suggesting that V4 neurons have both preferred and anti-preferred stimuli. We ran further experiments to validate the existence of anti-preferred stimuli in V4. We find that these anti-preferred stimuli help to shape a neuron's tuning: Only a small number of preferred and anti-preferred images are needed to estimate the rest of a neuron's tuning. Moreover, in a psychophysics task, humans rely on anti-preferred images to interpret and predict V4 stimulus tuning; this was not the case for hidden units from a deep neural network. We find that the preferred and anti-preferred visual features, while clearly distinguishable for individual neurons, are not easily distinguishable across neurons. Thus, the V4 population seemingly encodes anti-preferred stimuli to double its capacitity for feature selectivity. To encourage future experiments searching for anti-preferred stimuli, we release a tool called ImageBeagle to efficiently ""hunt"" for a neuron's preferred and anti-preferred stimuli by traversing the nearest neighbor graph of 30 million natural images. Overall, we establish anti-preferred stimuli as an important encoding property of V4 neurons. Our work embarks on a new quest in neuroscience to search for anti-preferred stimuli along the visual stream as well as update our deep neural network models of visual cortex to account for the two-tailed response distributions of neurons.",,,"computational neuroscience, neuronal tuning, stimulus selectivity, higher-order visual cortex, human psychophysics, stimulus optimization, deep neural networks",applications to neuroscience & cognitive science,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=RZ8esDBqMJ,https://openreview.net/forum?id=RZ8esDBqMJ,,
S1hTxWE7cJ,"X-SHOT: A Single System to Handle Frequent, Few-shot and Zero-shot Labels in Classification","In recent years, few-shot and zero-shot learning, which focus on labels with limited annotated instances, have garnered significant attention. Traditional approaches often treat freq-shot (labels with numerous instances), few-shot, and zero-shot learning as distinct challenges, optimizing systems for just one of these scenarios. Yet, in real-world settings, label occurrences vary greatly. Some labels might appear thousands of times, while others might only appear sporadically or not at all. Ideally, a system should accommodate any label, regardless of its training frequency. Notably, while few-shot systems often falter on zero-shot tasks, zero-shot systems don't leverage available annotations when certain downstream labels possess them. For practical deployment, it's crucial that a system can adapt to any label occurrence. We introduce a novel classification challenge: $X$-shot, reflecting a real-world context where freq-shot, few-shot, and zero-shot labels emerge without predefined limits. Here, $X$ can span from 0 to positive infinity. The crux of $X$-shot centers on open-domain generalization and devising a system versatile enough to manage various label scenarios. Our solution leverages Instruction Learning, bolstered by data autonomously generated by pre-trained Language Models (PLMs). Our unified system, $X$-shot, surpasses preceding state-of-the-art techniques on three benchmark datasets across diverse domains in both single-label and multi-label classifications. This is the first work addressing $X$-shot learning, where $X$ remains variable.","Hanzi Xu, Slobodan Vucetic, Wenpeng Yin","~Hanzi_Xu1, ~Slobodan_Vucetic1, ~Wenpeng_Yin1","Natural Language Processing, Few-shot Learning, Zero-shot Learning","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=S1hTxWE7cJ,https://openreview.net/forum?id=S1hTxWE7cJ,,
s3IBHTTDYl,Language Models Need Inductive Biases to Count Inductively,"Counting constitutes a core skill underlying a wide range of tasks, such as formal language recognition, multi-hop reasoning and simulating algorithms. Generaliz- ing counting inductively is central to task success on out-of-distribution (OOD) instances where testing inputs are longer than those seen in training. While there is a large body of literature reporting poor length generalization in language models, few papers have tried to distill the “reasoning” failure to the simplest case of count- ing failure. We aim to provide a broader picture on whether various language model architectures can a) learn to count, and b) generalize counting inductively. This work provides extensive empirical results on architectures ranging from RNNs, Transformers, State-Space Models and RWKV. We present carefully-designed task formats, auxiliary tasks and positional embeddings to avoid limitations in general- ization with OOD-position and OOD-vocabulary. We find that while traditional RNNs trivially achieve inductive counting, Transformers have to rely on positional embeddings (PEs) to count OOD. Further analyses on interpreting the learned solution reveal that different PEs encode different inductive biases that facilitate counting in different task formats. As counting is the basis for many arguments concerning the expressivity of Transformers, our finding calls for the community to reexamine the application scope of primitive functions defined in formal charac- terizations. Finally, modern RNNs also largely underperform traditional RNNs in generalizing counting inductively, hinting at the tradeoff modern RNNs struggle to balance between parallelized training and maintaining their recurrent nature.","Yingshan Chang, Yonatan Bisk","~Yingshan_Chang1, ~Yonatan_Bisk1","Language Model Architecture, Inductive bias, Expressivity, Counting, Inductive Generalization","foundation or frontier models, including LLMs",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=s3IBHTTDYl,https://openreview.net/forum?id=s3IBHTTDYl,,
ScwthqGzyt,LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization,"Retrieval-augmented generation (RAG) has become a popular approach to improving large language models (LLMs), yet trustworthiness remains a central challenge: models may produce fluent but incorrect answers, and retrieved context can amplify errors when irrelevant or misleading. To address this, we study how model internals reflect the interplay between parametric knowledge and external context during generation. Specifically, we ask: (1) can the correctness of a model’s output be inferred directly from its internal activations, and (2) do these internals reveal whether external context is helpful, harmful, or irrelevant? We introduce metrics grounded in intermediate activations to capture both dimensions. Across six models, a simple classifier trained on hidden states of the first output token predicts output correctness with nearly 75% accuracy, enabling early auditing. Moreover, our internals-based metric substantially outperforms prompting baselines at distinguishing between correct and incorrect context, guarding against polluted retrieval. These findings highlight model activations as a promising lens for understanding and improving the reliability of RAG systems.",,,"Calibration, Uncertainty, Knowledge Tracing, Probing",interpretability and explainable AI,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=ScwthqGzyt,https://openreview.net/forum?id=ScwthqGzyt,,
SdUMIXCG2a,Accelerated Methods with Complexity Separation Under Data Similarity for Federated Learning Problems,"Heterogeneity within data distribution is an issue encountered in many modern federated learning tasks. We formalize it as an optimization problem with a computationally heavy composite under data similarity. Using different sets of assumptions, we present several approaches to construct communication-efficient methods. An optimal algorithm is proposed for a convex composite. The constructed theory is validated through a series of experiments on various problems such as classification of CIFAR-10 with ResNet-18.",,,"Convex optimization, Data similarity, Composite optimization, Stochastic optimization",optimization,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=SdUMIXCG2a,https://openreview.net/forum?id=SdUMIXCG2a,,
SIE9fNq8lk,Text2Grad: Reinforcement Learning from Natural Language Feedback,"Traditional RLHF optimizes language models with coarse, scalar rewards that mask the fine-grained reasons behind success or failure, leading to slow and opaque learning. Recent work augments RL with textual critiques through prompting or reflection, improving interpretability but leaving model parameters untouched. We introduce Text2Grad, a reinforcement-learning paradigm that turns free-form textual feedback into span-level gradients. Given human (or programmatic) critiques, \name aligns each feedback phrase with the relevant token spans, converts these alignments into differentiable reward signals, and performs gradient updates that directly refine the offending portions of the model’s policy. This yields precise, feedback-conditioned adjustments instead of global nudges. Text2Grad is realized through three components: (1) a high-quality feedback–annotation pipeline that pairs critiques with token spans; (2) a fine-grained reward model that predicts span-level reward on answer while generating explanatory critiques; and (3) a span-level policy optimizer that back-propagates natural-language gradients. Across summarization, code generation, and question answering, Text2Grad consistently surpasses scalar-reward RL and prompt-only baselines, providing both higher task metrics and richer interpretability. Our results demonstrate that natural-language feedback, when converted to gradients, is a powerful signal for fine-grained policy optimization. The code for our method is available in the supplementary ZIP file.",,,"Natural Language Feedback, Fine-Grained Policy Optimization, Reinforcement Learning for Language Models",reinforcement learning,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=SIE9fNq8lk,https://openreview.net/forum?id=SIE9fNq8lk,,
SLjqdj3LPk,CHAMMI-75: pre-training multi-channel models with heterogeneous microscopy images,"Quantifying cell morphology using images and machine learning models has proven to be a powerful tool to study the response of cells to treatments. However, the models used to quantify cellular morphology are typically trained with a single microscopy imaging type and under controlled experimental conditions. This results in specialized models that cannot be reused across biological studies because the technical specifications do not match (e.g., different number of channels), or because the target experimental conditions are out of distribution. Here, we present CHAMMI-75, a dataset of heterogeneous, multi-channel microscopy images with more than 1.8B single cells from 75 diverse biological studies. We curated this resource from publicly available sources to investigate cellular morphology models that are channel-adaptive and can process any microscopy image type. Our experiments show that training with CHAMMI-75 can improve performance in multi-channel bioimaging tasks, opening the way to create the next generation of cellular morphology models for biological studies.",,,"microscopy, representation learning, multi-channel imaging, self-supervised learning, biology",datasets and benchmarks,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=SLjqdj3LPk,https://openreview.net/forum?id=SLjqdj3LPk,,
slTQdWWQI9,Contrastive Learning with Quantum Projection Heads and Kernels,"Self-supervised contrastive learning is sensitive to architectural choices and to how similarity is defined. Motivated by claims that quantum circuits can induce useful non-classical geometries, we present a systematic empirical analysis of two natural drop-in quantum components for the projection/similarity stage: (i) variational quantum circuits (VQCs) as projection heads and (ii) fixed quantum feature maps whose state fidelities act as similarity measures (``quantum kernels''). Within a controlled SimCLR pipeline on STL-10 (ResNet18 encoder) using mainstream \emph{analytic} simulators, we report three findings. First, under realistic resource constraints (low qubit count, shallow depth), a tuned classical MLP head consistently matches or outperforms VQC heads. Second, fidelity-based quantum kernels largely mirror cosine similarity without a clear uplift. Third, increasing circuit size rapidly incurs prohibitive latency, exposing scaling bottlenecks that restrict current explorability. These results constitute a useful null baseline for hybrid quantum-classical contrastive learning and point to concrete directions: batching-friendly simulators for higher throughput, lower-variance/better-conditioned feature maps to avoid similarity collapse, and modest, low-latency hardware as a realistic near-term testbed. We release anonymized code and consolidated hyperparameters to facilitate replication and future extensions.",,,"Contrastive learning, Self-supervised learning, quantum meachine learning, variational quantum circuits, quantum kernels, representation learning, InfoNCE loss, quantum fidelity","unsupervised, self-supervised, semi-supervised, and supervised representation learning",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=slTQdWWQI9,https://openreview.net/forum?id=slTQdWWQI9,,
sqVgpiCoKU,IBEX: Information-Bottleneck-EXplored Coarse-to-Fine Molecular Generation under Limited Data,"The potential of three-dimensional molecular generation for structure-based drug discovery is hampered by the scarcity of public protein-ligand complexes, which causes models to overfit and fail to learn generalizable geometric priors. To address this challenge, we employ the PAC-Bayes information bottleneck framework to systematically quantify the information density of three generation paradigms: Scaffold Hopping (SH), Side-Chain Decoration (SC), and De Novo Design (DN). Our analysis reveals that SH possesses the highest information density, which tightens the model's generalization bound and enhances its transferability compared to conventional de novo generation. Motivated by this finding, we propose IBEX, a novel decoupled generation framework. IBEX is trained exclusively on the information-rich SH task to structure its latent representation of chemical space, which is then directly applied to de novo generation in a zero-shot transfer setting. Subsequently, a rapid physical refinement module utilizes the L-BFGS algorithm to optimize each conformer's geometry and binding compatibility by adjusting five short-range interaction terms and six degrees of freedom. Evaluated in a rigorous zero-shot setting on the CBGBench CrossDocked2020-based dataset, IBEX demonstrates substantial improvements over the TargetDiff baseline. It increases the docking success rate from 53% to 64% and improves the average Dock score from -7.41 to -8.09 kcal/mol. Notably, IBEX achieves a superior median Vina energy in 57 out of 100 binding pockets. Furthermore, IBEX enhances drug-likeness by approximately 25% while maintaining state-of-the-art validity and diversity, all corresponding to a demonstrably reduced generalization error. Our results validate that this decoupled approach, which synergizes information-dense pre-training with physical refinement, enables robust zero-shot structure generation and cross-pocket generalization in data-limited regimes.",,,"Molecular Generation, Diffusion Model, Information Bottleneck","applications to physical sciences (physics, chemistry, biology, etc.)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=sqVgpiCoKU,https://openreview.net/forum?id=sqVgpiCoKU,,
sRdByVBvZq,A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs,"Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem of _Corrective Unlearning_. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method, ***Cognac***, which can unlearn the effect of the manipulation set even when only $5$\% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training.","Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru","~Varshita_Kolipaka1, ~Akshit_Sinha2, ~Debangan_Mishra1, ~Sumit_Kumar6, ~Arvindh_Arun1, ~Shashwat_Goel1, ~Ponnurangam_Kumaraguru3","Unlearning, Graphs, Graph Neural Networks, GNN, Attacks, Manipulations, Removal",learning on graphs and other geometries & topologies,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=sRdByVBvZq,https://openreview.net/forum?id=sRdByVBvZq,,
sVbFE6xz82,MFN: Metadata-Free Real-World Noisy Image Generation,"Real-world noise poses a significant challenge in signal processing, especially for denoising tasks.
Although end-to-end denoising approaches have achieved exceptional performance, they are constrained to scenarios with abundant noisy-clean image pairs, which can be technically challenging and resource-intensive to collect.
To address this issue, several generative methods have been developed to synthesize realistic noisy images from limited real-world datasets.
While prior studies require camera metadata during training or testing to handle various real-world noise, the absence of metadata or variations in the information across different capturing devices is common in real-world scenarios, such as medical or microscope imaging, which limits their applicability.
Thus, we aim to eliminate the need for explicit camera-related labels in both stages, enhancing applicability in real-world scenarios.
To achieve this, we propose a novel framework called the Metadata-Free Noise Model (MFN), which extracts prompt features that encode input noise characteristics and generates diverse noisy images that adhere to the distribution of the input noise.
Extensive experimental results demonstrate the superior performance of our model in real-world noise generation and denoising across various benchmark datasets.","Jaekyun Ko, Dongjin Kim, Guanghui Wang, Tae Hyun Kim","~Jaekyun_Ko1, ~Dongjin_Kim3, ~Guanghui_Wang8, ~Tae_Hyun_Kim2","real noise modeling, prompt learning, consistency models, low-level vision","applications to computer vision, audio, language, and other modalities",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=sVbFE6xz82,https://openreview.net/forum?id=sVbFE6xz82,,
SwIkknEqmt,Dealing with Frequency Collapse in Time Series Embeddings by Post-Embedding reMapping,"Transformer-based methods have made significant strides in time series forecasting tasks in recent years. However, we observe underfitting in numerous samples, e.g., pattern shifts or excessive deviation in extreme value regions when testing the transform-based model that converges on the training set. Through the proposed spectral analysis of adjacent embedding sequences, we identify a frequency collapse issue in the embedding features generated by the top layer of the transformer backbone. To address this, we propose the Post-Embedding ReMapping (PErM) strategy that improves the frequency-domain representation of embeddings using fixed non-linear functions. Both two kinds of PErM functions that we insert into the model can effectively resolve the frequency collapse issue and lead to significant improvements in prediction performance. Experimental results show that our method outperforms state-of-the-art algorithms across multiple datasets. We will release our code after the review phase.","Haotian Si, Changhua Pei, Haiming Zhang, Dan Pei, Gaogang Xie, Jianhui li","~Haotian_Si1, ~Changhua_Pei2, ~Haiming_Zhang2, ~Dan_Pei1, ~Gaogang_Xie2, ~Jianhui_li4","Time Series Forcasting, deep learning, spectral analysis",learning on time series and dynamical systems,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=SwIkknEqmt,https://openreview.net/forum?id=SwIkknEqmt,,
tiWCvwi4b8,Hystar: Hypernetwork-driven Style-adaptive Retrieval via Dynamic SVD Modulation,"Query-based image retrieval (QBIR) requires retrieving relevant images given diverse and often stylistically heterogeneous queries, such as sketches, artworks, or low-resolution previews. While large-scale vision--language models (VLMs) like CLIP offer strong zero-shot retrieval performance, they struggle with distribution shifts caused by unseen query styles. In this paper, we propose the Hypernetwork-driven Style-adaptive Retrieval (Hystar), a lightweight framework that dynamically adapts model weights to each query’s style. Hystar employs a hypernetwork to generate singular-value perturbations ($\Delta S$) for attention layers, enabling flexible per-input adaptation, while static singular-value offsets on MLP layers ensure cross-style stability.    To better handle semantic confusions across styles, we design StyleNCE as part of Hystar, an optimal-transport-weighted contrastive loss that emphasizes hard cross-style negatives. Extensive experiments on multi-style retrieval and cross-style classification benchmarks demonstrate that Hystar consistently outperforms strong baselines, achieving state-of-the-art performance while being parameter-efficient and stable across styles.",,,"Image Retrieval, Vision–Language Models, Hypernetworks, Style Adaptation, Contrastive Learning","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=tiWCvwi4b8,https://openreview.net/forum?id=tiWCvwi4b8,,
TvGPP8i18S,MELODI: Exploring Memory Compression for Long Contexts,"We present MELODI, a novel memory architecture designed to efficiently process long documents using short context windows. The key principle behind MELODI is to represent short-term and long-term memory as a hierarchical compression scheme across both transformer layers and context windows. Specifically, the short-term memory is achieved through recurrent compression of context windows across multiple layers, ensuring smooth transitions between windows. In contrast, the long-term memory performs further compression within a single middle layer and aggregates information across context windows, effectively consolidating crucial information from the entire history. Compared to a strong baseline - the Memorizing Transformer employing dense attention over a large long-term memory (64K key-value pairs) - our method demonstrates superior performance on various long-context datasets while remarkably reducing the memory footprint by a factor of 8.","Yinpeng Chen, DeLesley Hutchins, Aren Jansen, Andrey Zhmoginov, David Racz, Jesper Sparre Andersen","~Yinpeng_Chen1, ~DeLesley_Hutchins1, ~Aren_Jansen2, ~Andrey_Zhmoginov1, ~David_Racz1, ~Jesper_Sparre_Andersen1","Memory, Compression, Long Context","applications to computer vision, audio, language, and other modalities",ICLR 2025 Poster,2025,https://openreview.net/pdf?id=TvGPP8i18S,https://openreview.net/forum?id=TvGPP8i18S,,
uik3mfqaBE,On alignment of unified multimodal large language models,"Unified Multi-Modal Large Language Models (U-MLLMs) have demonstrated remarkable capabilities in text-to-image (T2I) generation, yet their safety alignment remains under-explored. As these models become increasingly powerful, the potential for generating toxic or harmful content grows correspondingly. Current T2I alignment methods primarily focus on enhancing image quality while neglecting safety considerations. Moreover, the reward signals employed in existing approaches are typically sparse, providing only a single score per image, which limits the granularity of feedback. This paper introduces a novel approach that integrates dense rewards into a Group Relative Policy Optimization (GRPO) framework for improving image quality, incorporating safety-specific reward signals to enhance safety alignment. Our method transforms dense reward into token-level weights that modulate the training process, enabling fine-grained optimization that suppresses problematic regions while focusing learning on well-aligned image regions. Experiments demonstrate strong performance: our method achieves competitive quality metrics (WISE: 0.50) while reducing unsafe content generation by 59.4\% on the MMDT benchmark. This work advances both the quality and safety of U-MLLMs demonstrating a comprehensive approach for U-MLLM alignment.",,,"unified multimodal large language models, alignment","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=uik3mfqaBE,https://openreview.net/forum?id=uik3mfqaBE,,
UPEwYJn2mm,Wavelet Predictive Representations for Non-Stationary Reinforcement Learning,"The real world is inherently non-stationary, with ever-changing factors, such as weather conditions and traffic flows, making it challenging for agents to adapt to varying environmental dynamics. Non-Stationary Reinforcement Learning (NSRL) addresses this challenge by training agents to adapt rapidly to sequences of distinct Markov Decision Processes (MDPs). However, existing NSRL approaches often focus on tasks with regularly evolving patterns, leading to limited adaptability in highly dynamic settings. Inspired by the success of Wavelet analysis in time series modeling, specifically its ability to capture signal trends at multiple scales, we propose WISDOM to leverage wavelet-domain predictive task representations to enhance NSRL. WISDOM captures these multi-scale features in evolving MDP sequences by transforming task representation sequences into the wavelet domain, where wavelet coefficients represent both global trends and fine-grained variations of non-stationary changes. In addition to the auto-regressive modeling commonly employed in time series forecasting, we devise a wavelet temporal difference (TD) update operator to enhance tracking and prediction of MDP evolution. We theoretically prove the convergence of this operator and demonstrate policy improvement with wavelet task representations. Experiments on diverse benchmarks show that WISDOM significantly outperforms existing baselines in both sample efficiency and asymptotic performance, demonstrating its remarkable adaptability in complex environments characterized by non-stationary and stochastically evolving tasks.",,,"Non-Stationary Reinforcement Learning, Representation Learning",reinforcement learning,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=UPEwYJn2mm,https://openreview.net/forum?id=UPEwYJn2mm,,
uXBIfzhu9T,The Blessings of Multiple Treatments and Outcomes in Treatment Effect Estimation,"Assessing causal effects in the presence of unobserved confounding is a challenging problem. Existing studies leveraged proxy variables or multiple treatments to adjust for the confounding bias. In particular, the latter approach attributes the impact on a single outcome to multiple treatments, allowing estimating latent variables for confounding control. Nevertheless, these methods primarily focus on a single outcome, whereas in many real-world scenarios, there is greater interest in studying the effects on multiple outcomes. Besides, these outcomes are often coupled with multiple treatments. Examples include the intensive care unit (ICU), where health providers evaluate the effectiveness of therapies on multiple health indicators. To accommodate these scenarios, we consider a new setting dubbed as *multiple treatments and multiple outcomes*. We then show that parallel studies of multiple outcomes involved in this setting can assist each other in causal identification, in the sense that we can exploit other treatments and outcomes as proxies for each treatment effect under study. We proceed with a causal discovery method that can effectively identify such proxies for causal estimation. The utility of our method is demonstrated in synthetic data and sepsis disease.","Yong Wu, Mingzhou Liu, Jing Yan, Yanwei Fu, Shouyan Wang, Yizhou Wang, Xinwei Sun","~Yong_Wu9, ~Mingzhou_Liu1, ~Jing_Yan2, ~Yanwei_Fu2, ~Shouyan_Wang1, ~Yizhou_Wang1, ~Xinwei_Sun1","multiple treatments, multiple outcomes, proximal causal leaning, hypothetical test",causal reasoning,ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=uXBIfzhu9T,https://openreview.net/forum?id=uXBIfzhu9T,,
v0QOVSVPtq,Exploring Diverse Generation Paths via Inference-time Stiefel Activation Steering,"Language models often default to a narrow set of high-probability outputs, leaving their generation paths homogeneous and prone to mode collapse. Sampling-based strategies inject randomness but still struggle to guarantee diversity across multiple concurrent generation runs. We address this limitation by introducing STAR (**St**iefel-based **A**ctivation Steering for Diverse **R**easoning), a training-free, inference-time intervention method that transforms activation steering into an exploration engine. At each token, STAR collects the hidden activations of concurrent generation runs and optimizes multiple additive steering directions jointly on the Stiefel manifold. STAR maximizes the geometric volume of the steered activations, while the Stiefel manifold induces orthogonality of the steering interventions. This formulation explicitly promotes divergent activation vectors of concurrent generation runs, and implicitly promotes divergent generation trajectories. This manifold optimization formulation can be solved using a Riemannian gradient descent algorithm with convergence guarantees, but this algorithm is too time-consuming for real-time inference. To guarantee low latency, we further design a lightweight one-step update with an aggressive, closed-form stepsize. For test case generation and scientific discovery benchmarks, STAR consistently outperforms standard sampling methods, achieving greater diversity without sacrificing qualitative performance.",,,"activation steering, generation diversity, manifold opimization",optimization,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=v0QOVSVPtq,https://openreview.net/forum?id=v0QOVSVPtq,,
VaUy5GZO3f,Q-Bench-Video: Benchmarking the Video Quality Understanding of LMMs,"With the rising interest in research on Large Multi-modal Models (LMMs) for video understanding, many studies have emphasized general video comprehension capabilities, neglecting the **systematic exploration into video quality understanding**. To address this oversight, we introduce **Q-Bench-Video** in this paper, a new benchmark specifically designed to evaluate LMMs' proficiency in discerning video quality. **a)** To ensure the diversity of video sources, Q-Bench-Video encompasses videos from natural scenes, computer graphics (CG), and AI-generated content (AIGC). **b)** Building on the traditional multiple-choice questions format with the *Yes-or-No* and *What-How* categories, we include *Open-ended* questions to better evaluate complex scenarios. Additionally, we incorporate the **video pair quality comparison** question to enhance comprehensiveness. **c)** Beyond the traditional *Technical*, *Aesthetic*, and *Temporal* distortions, we have expanded our evaluation aspects to include the dimension of *AIGC* distortions, which addresses the increasing demand for video generation. Finally, we collect a total of 2,378 question-answer pairs and test them on 12 open-source & 5 proprietary LMMs. Our findings indicate that while LMMs have a foundational understanding of video quality, their performance remains incomplete and imprecise, with a notable discrepancy compared to human-level performance. Through **Q-Bench-Video**, we seek to catalyze community interest, stimulate further research, and unlock the untapped potential of LMMs to close the gap in video quality understanding.","Zicheng Zhang, Ziheng Jia, Haoning Wu, Chunyi Li, Zijian Chen, Yingjie Zhou, Wei Sun, Xiaohong Liu, Xiongkuo Min, Weisi Lin, Guangtao Zhai","~Zicheng_Zhang7, ~Ziheng_Jia1, ~Haoning_Wu1, ~Chunyi_Li1, ~Zijian_Chen1, ~Yingjie_Zhou1, ~Wei_Sun12, ~Xiaohong_Liu2, ~Xiongkuo_Min1, ~Weisi_Lin1, ~Guangtao_Zhai1","Large multi-modal model, benchmark, video quality assessment",datasets and benchmarks,ICLR 2025 Conference Withdrawn Submission,2025,https://openreview.net/pdf?id=VaUy5GZO3f,https://openreview.net/forum?id=VaUy5GZO3f,,
VB2WkqvFwF,The Underlying Scaling Laws and Universal Statistical Structure of Complex Datasets,"We study universal traits which emerge both in real-world complex datasets, as well as in artificially generated ones. Our approach is to analogize data to a physical system and employ tools from statistical physics and Random Matrix Theory (RMT) to reveal their underlying structure. We focus on the feature-feature covariance matrix, analyzing both its local and global eigenvalue statistics. Our main observations are: (i) The power-law scalings that the bulk of its eigenvalues exhibit are vastly different for uncorrelated normally distributed data compared to real-world data, (ii) this scaling behavior can be completely modeled by generating gaussian data with long range correlations, (iii) both generated and real-world datasets lie in the same universality class from the RMT perspective, as chaotic rather than integrable systems, (iv) the expected RMT statistical behavior already manifests for empirical covariance matrices at dataset sizes significantly smaller than those conventionally used for real-world training, and can be related to the number of samples required to approximate the population power-law scaling behavior, (v) the Shannon entropy is correlated with local RMT structure and eigenvalues scaling, and substantially smaller in strongly correlated datasets compared to uncorrelated synthetic data, and requires fewer samples to reach the distribution entropy. These findings show that with sufficient sample size, the Gram matrix of natural image datasets can be well approximated by a Wishart random matrix with a simple covariance structure, opening the door to rigorous studies of neural network dynamics and generalization which rely on the data Gram matrix.","Noam Itzhak Levi, Yaron Oz","~Noam_Itzhak_Levi1, ~Yaron_Oz1","Random Matrix Theory, Data Structure, Universality, Random Feature Models, Empirical Data Estimation, Neural Scaling Laws","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=VB2WkqvFwF,https://openreview.net/forum?id=VB2WkqvFwF,,
vNZ420zDte,DREAM: Decoupled Reinforcement Learning with Reward Measurement for Large Language Model Test-time Training,"This paper studies the problem of large language model (LLM) test-time training, which aims to enhance the reasoning ability of LLMs via unlabeled test data. Recent works usually utilize majority voting to infer the labels of samples to guide the reinforcement learning process, which could be inaccurate and biased with potential error accumulation. Towards this end, we propose a novel approach named Decoupled Reinforcement Learning with Reward Measurement (DREAM) for LLM test-time training. The core of our proposed DREAM is to decouple the reward estimation from reinforcement learning with enhanced calibration. In particular, our DREAM trains an LLM-based calibration model which takes both questions and answers as input, and outputs the calibration scores. To mitigate overconfident results, the judge model is trained by simulating on an independent reference dataset with positive and negative pairs. The reference-based calibration scores would be incorporated into voting-based reward estimation to reduce the potential biases, which enhance reliable test-time training. Extensive experiments on benchmark datasets validate the superiority of the proposed DREAM in comparison with competing baselines.",,,"Reinforcement Learning, Test-Time Training, Large Language Model",reinforcement learning,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=vNZ420zDte,https://openreview.net/forum?id=vNZ420zDte,,
vuvG5rNBra,Spurious Privacy Leakage in Neural Networks,"Neural networks are vulnerable to privacy attacks aimed at stealing sensitive data. When trained on real-world datasets, these models can also inherit latent biases, which may further increase privacy risks. In this work, we investigate the impact of spurious correlation bias on privacy vulnerability, identifying several key challenges. We introduce _spurious privacy leakage_, a phenomenon where spurious groups can be up to 100 times more vulnerable to privacy attacks than non-spurious groups, and demonstrate how this leakage is connected to task complexity. Furthermore, while robust training methods can mitigate the performance disparity across groups, they fail to reduce privacy vulnerability, and even differential privacy is ineffective in protecting the most vulnerable spurious group in practice. Finally, we compare model architectures in terms of both performance and privacy, revisiting prior research with novel insights.","Chenxiang Zhang, Jun Pang, Sjouke Mauw","~Chenxiang_Zhang1, ~Jun_Pang1, ~Sjouke_Mauw1","spurious correlation, membership inference, privacy, robustness, safety","alignment, fairness, safety, privacy, and societal considerations",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=vuvG5rNBra,https://openreview.net/forum?id=vuvG5rNBra,,
vvD4ilobth,TCL-VS: Temporal Contrastive Learning for Self-Supervised Video Summarization,"The goal of video summarization is to extract the most important parts from the original video. 
Most existing methods are based on supervised learning and they have demonstrated superior performance. 
However, the scarcity of annotated data is a major obstacle in the video summarization task. 
To reduce the impact of the scarcity, some weakly-supervised and unsupervised methods were proposed. 
Although they manifested positive results, existing methods ignore the intrinsic association between video clips. 
To address it, we introduce a new self-supervised learning method called TCL-VS. Our main insight is that 
a excellent summary requires not only maintaining the original video content but also eliminating redundant information.
Inspired by the observation, this work consists of two separate modules that respectively conduct 
temporal consistency and diversity assessment of video clips. Each module predicts a sequence score by clip, 
and then we combine them using a weighted method. Extensive experiments demonstrate that 
our method achieves state-of-the-art performance on two video summarization benchmarks: SumMe and TVSum.","Jiajun Han, Xuran Yang, kun shen Xu, Hui Zhang, Kanle Shi","~Jiajun_Han1, ~Xuran_Yang1, ~kun_shen_Xu1, ~Hui_Zhang1, ~Kanle_Shi1","Video Summarization, Self-Supervised, Contrastive Learning","representation learning for computer vision, audio, language, and other modalities",ICLR 2024 Conference Withdrawn Submission,2024,https://openreview.net/pdf?id=vvD4ilobth,https://openreview.net/forum?id=vvD4ilobth,,
WMInu1V9av,AURA: Visually Interpretable Affective Understanding via Robust Archetypes,"Text-driven vision--language methods (e.g., CLIP variants) face three persistent hurdles in affective computing: (i) limited support for continuous regression (e.g., Valence--Arousal), (ii) brittle reliance on language prompts, and (iii) the absence of a unified paradigm across expression classification, action-unit detection, and affective regression. We introduce AURA, a prompt-free framework that operates directly in a frozen CLIP visual space via visual archetypes. AURA comprises two components: (1) self-organized archetype discovery, which adaptively allocates the number of archetypes per affective state, assigning denser archetype sets to complex or ambiguous states for fine-grained interpretability, and (2) archetype contextualization, which models interactions among the most relevant archetypes and semantic tokens to enhance structural consistency while suppressing redundancy. Inference reduces to cosine matching between projected features and fixed archetypes. Across six datasets, AURA consistently surpasses prior state-of-the-art while remaining highly efficient. Overall, AURA unifies classification, detection, and regression under a single visual-archetype paradigm, delivering strong accuracy, cognitively aligned interpretability, and excellent training/inference efficiency.",,,"valence-arousal, facial expressions, action units","applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=WMInu1V9av,https://openreview.net/forum?id=WMInu1V9av,,
X9JU2gKEkR,Arctic-SnowCoder: Demystifying High-Quality Data in Code Pretraining,"Recent studies have been increasingly demonstrating that high-quality data is crucial for effective pretraining of language models. However, the precise definition of ""high-quality"" remains underexplored. Focusing on the code domain, we introduce Arctic-SnowCoder-1.3B, a data-efficient base code model pretrained on 555B tokens through three phases of progressively refined data: (1) general pretraining with 500B standard-quality code tokens, preprocessed through basic filtering, deduplication, and decontamination, (2) continued pretraining with 50B high-quality tokens, selected from phase one by a BERT-style quality annotator trained to distinguish good code from random data, using positive examples drawn from high-quality code files, along with instruction data from Magicoder and StarCoder2-Instruct, and (3) enhanced pretraining with 5B synthetic data created by Llama-3.1-70B using phase two data as seeds, adapting the Magicoder approach for pretraining. Despite being trained on a limited dataset, Arctic-SnowCoder achieves state-of-the-art performance on BigCodeBench, a coding benchmark focusing on practical and challenging programming tasks, compared to similarly sized models trained on no more than 1T tokens, outperforming Phi-1.5-1.3B by 36%. Across all evaluated benchmarks, Arctic-SnowCoder-1.3B beats StarCoderBase-3B pretrained on 1T tokens. Additionally, it matches the performance of leading small base code models trained on trillions of tokens. For example, Arctic-SnowCoder-1.3B surpasses StarCoder2-3B, pretrained on over 3.3T tokens, on HumanEval+, a benchmark that evaluates function-level code generation, and remains competitive on BigCodeBench. Our evaluation presents a comprehensive analysis justifying various design choices for Arctic-SnowCoder. Most importantly, we find that the key to high-quality data is its consistency with the distribution of downstream applications.","Yuxiang Wei, Hojae Han, Rajhans Samdani","~Yuxiang_Wei2, ~Hojae_Han1, ~Rajhans_Samdani1","Large language models, Code generation, Pretraining, Data quality","foundation or frontier models, including LLMs",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=X9JU2gKEkR,https://openreview.net/forum?id=X9JU2gKEkR,,
xrwPLtSCM3,ProxyFL: A Proxy-Guided Framework for Federated Semi-Supervised Learning,"Federated Semi-Supervised Learning (FSSL) aims to collaboratively train a global model by leveraging unlabeled data and limited labeled data across clients in a privacy-preserving manner. In FSSL, data heterogeneity is a challenging issue, which exists both across clients (external heterogeneity) and within clients (internal heterogeneity). Most FSSL methods typically design fixed or dynamic weight aggregation strategy on the server (for external) or filter out low-confidence unlabeled samples directly by an empirical threshold to reduce mistakes in local client (for internal). But, the former is hard to precisely fit the real global category distribution due to external heterogeneity, and the latter results in fewer training participation of available samples in FL. To address these issues, we propose a proxy-guided framework called ProxyFL that focuses on simultaneously mitigating external and internal heterogeneity via a unified proxy. \emph{I.e.}, we consider the learnable weights of classifier as proxy to simulate the category distribution both locally and globally. For external, we explicitly optimize global proxy to better fit the category distribution across clients; for internal, we include the discarded samples together with other samples into training based upon a positive-negative proxy pool {without compromising wrong pseudo-labels.} Insight experiments \& theoretical analysis show that ProxyFL significantly boost the FSSL performance and convergence.",,,Federated Semi-Supervised Learning; Federated Learning,"other topics in machine learning (i.e., none of the above)",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=xrwPLtSCM3,https://openreview.net/forum?id=xrwPLtSCM3,,
Xy1Lf7uR9H,ANOVA-NODE: An identifiable neural network for the functional ANOVA model for better interpretability,"Interpretability for machine learning models is becoming more and more important as machine learning models become more complex. 
The functional ANOVA model, which decomposes a high-dimensional function into a sum of lower dimensional functions so called components, is one of the most popular tools for interpretable AI, and recently, various neural network models have been developed for estimating each component in the functional ANOVA model. 
However, such neural networks are highly unstable when estimating components since the components themselves are not uniquely defined. 
That is, there are multiple functional ANOVA decompositions for a given function. 
In this paper, we propose a novel interpretable model which guarantees a unique functional ANOVA decomposition and thus is able to estimate each component stably. 
We call our proposed model ANOVA-NODE since it is a modification of Neural Oblivious Decision Ensembles (NODE) for the functional ANOVA model. 
Theoretically, we prove that ANOVA-NODE can approximate a smooth function well.
Additionally, we experimentally show that ANOVA-NODE provides much more stable estimation of each component and thus much more stable interpretation when training data and initial values of the model parameters vary than existing neural network models do.","Seokhun Park, Insung Kong, yongchan Choi, Chanmoo Park, Yongdai Kim","~Seokhun_Park1, ~Insung_Kong1, ~yongchan_Choi1, ~Chanmoo_Park1, ~Yongdai_Kim1","Interpretability, Explianability, Trustworthy AI, Functional ANOVA model, Generalized additive models",interpretability and explainable AI,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=Xy1Lf7uR9H,https://openreview.net/forum?id=Xy1Lf7uR9H,,
Y4UliyX3LE,Learning Dispersed Embeddings on Hyperspheres,"Learning well-separated features in high-dimensional spaces, such as text or image $\textit{embeddings}$, is crucial for many machine learning applications. Achieving such separation can be effectively accomplished through the $\textit{dispersion}$ of embeddings, where unrelated vectors are pushed apart as much as possible. By constraining features to be on a $\textit{hypersphere}$, we can connect dispersion to well-studied problems in mathematics and physics, where optimal solutions are known for limited low-dimensional cases. However, in representation learning we typically deal with a large number of features in high-dimensional space, which makes leveraging existing theoretical and numerical solutions impossible. Therefore, we rely on gradient-based methods to approximate the optimal dispersion on a hypersphere. In this work, we first give an overview of existing methods from disconnected literature. Next, we propose new reinterpretations of known methods, namely Maximum Mean Discrepancy (MMD) and Lloyd’s relaxation algorithm. Finally, we derive a novel dispersion method that directly exploits properties of the hypersphere. Our experiments show the importance of dispersion in image classification and natural language processing tasks, and how algorithms exhibit different trade-offs in different regimes.","Evgeniia Tokarchuk, Hua Chang Bakker, Vlad Niculae","~Evgeniia_Tokarchuk1, ~Hua_Chang_Bakker1, ~Vlad_Niculae2","embeddings, dispersion, hypersphere, representation learning, separation","unsupervised, self-supervised, semi-supervised, and supervised representation learning",Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=Y4UliyX3LE,https://openreview.net/forum?id=Y4UliyX3LE,,
ye3NrNrYOY,Temporal Causal Mechanism Transfer for Few-shot Action Recognition,"The goal of few-shot action recognition is to recognize actions in video sequences for which there exists only a few training samples. The challenge is to adapt a base model effectively and efficiently when the base and novel data have significant distributional disparities. To this end, we learn a model of a temporal causal mechanism from the base data by variational inference. When adapting the model by training on the novel data set we hold certain aspects of the causal mechanism fixed, updating only auxiliary variables and a classifier. During this adapation phase, we treat as invariant the time-delayed causal relations between latent causal variables and the mixing function that maps causal variables to action representations. Our experimental evaluations across standard action recognition datasets validate our hypothesis that our proposed method of Temporal Causal Mechanism Transfer (TCMT) enables efficient few-shot action recognition in video sequences with notable performance improvements over leading benchmarks.","Yuke Li, Guangyi Chen, Ben Abramowitz, Stefano Anzellotti, Donglai Wei","~Yuke_Li1, ~Guangyi_Chen1, ~Ben_Abramowitz1, ~Stefano_Anzellotti1, ~Donglai_Wei1","few-shot action recognition, causal representation learning","representation learning for computer vision, audio, language, and other modalities",Submitted to ICLR 2024,2024,https://openreview.net/pdf?id=ye3NrNrYOY,https://openreview.net/forum?id=ye3NrNrYOY,,
YlDHsGqjCO,Perishable Online Inventory Control with Context-Aware Demand Distributions,"We study the online contextual inventory control problem with perishable goods. In this work, we propose and consider a more realistic---and more challenging---setting where both the expected demand and the (residual) noise distribution depend on the observable features. Surprisingly, little is known when the noise is context-dependent, which captures the heteroskedastic uncertainty in demand that is important in inventory control. The optimal inventory quantity in this general setting is no longer a linear function of features (unlike the case when the expected demand is linear and the noise is i.i.d.), making online gradient descent---the gold standard therein---inapplicable. We first propose an algorithm that achieves the near-optimal regret $\widetilde{O}(\sqrt{d T}+T^{\frac{p+1}{p+2}})$ under linear expected demand and context-aware noise. Here $d$ is the feature dimension, and $p \leq d$ is an underlying dimension that captures the intrinsic complexity of the noise distribution. When the expected demand is nonlinear, we propose to use neural networks to capture the nonlinearity, and prove a regret bound $\widetilde{O}(\sqrt{\alpha T}+T^{\frac{p+1}{p+2}})$ under over-parameterized networks, where $\alpha$ depends on the nonlinear demand complexity and the network architecture. Additionally, under mild regularity conditions on the noise, the exponential factor $T^{\frac{p+1}{p+2}}$ in these regret bounds is improved to $p\sqrt{T}$. Finally, we provide a matching minimax lower bound $\Omega(\sqrt{d T}+T^{\frac{p+1}{p+2}})$ under linear expected demand. To our best knowledge, our results provide the first minimax optimal characterization for online inventory control with context-dependent noise and the first theoretical guarantees when the expected demand is nonlinear in features.",,,"online learning, inventory control, kernel regression, contextual bandits, neural bandits",learning theory,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=YlDHsGqjCO,https://openreview.net/forum?id=YlDHsGqjCO,,
yrPiUpkXQh,Probabilistic Modeling of Multi-rater Medical Image Segmentation for Diversity and Personalization,"Medical image segmentation is inherently influenced by data uncertainty, arising from ambiguous boundaries in medical scans and subjective variations among expert annotators. To address this challenge, previous works formulated the multi-rater medical image segmentation task, where multiple experts provide separate annotations for each image. However, existing models are typically constrained to either generating diverse segmentations that lack expert specificity or producing personalized outputs that merely replicate individual annotators. We propose Probabilistic modeling of multi-rater medical image Segmentation (ProSeg) that simultaneously enables both diversification and personalization. Extensive experiments on both the nasopharyngeal carcinoma dataset (NPC) and the lung nodule dataset (LIDC-IDRI) demonstrate that our ProSeg achieves a new state-of-the-art performance, providing segmentation results that are both diverse and expert-personalized.",,,probabilistic modeling,"applications to computer vision, audio, language, and other modalities",ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=yrPiUpkXQh,https://openreview.net/forum?id=yrPiUpkXQh,,
zfAcPuIHkE,Logic Channel Validation and Enhancement of Zero-Shot Vision-Language Comprehension on Vision Language Models,"Frontier Large Vision-Language Models (LVLMs) exhibit remarkable capabilities in Visual-Language Comprehension (VLC) tasks, enabled by pretraining on vast visual-textual corpus. However, they are often deployed as zero-shot solution in a black-box manner, as retraining challenges remain due to data privacy or model inaccessibility. Validating and understanding the behavior of the models become important for generalization to new task. We propose a Logic Channel, in parallel with the black-box model channel, to perform explicit logic reasoning for validation and enhancement. The frontier LVLM, encapsulating latent vision-language knowledge, can be considered as an Implicit Logic Channel. The proposed Explicit Logic Channel, mimicking human logic reasoning, incorporates a Large Language Model (LLM), a Visual Foundation Model (VFM), and a logical reasoning module involving novel probabilistic inference for factual, counterfactual, relational, and causal condition reasoning over the extracted and grounded visual-textual facts. Cross-channel logic consistency analysis enables model validation and selection, even without ground-truth annotations. Additionally, cross-channel integration further improves performance in zero-shot tasks over SOTA models. Our experiments on three recent challenging VLC benchmarks, Neg- Bench, HC-RefCOCOg, and HC-RefLoCo, demonstrate the effectiveness of the proposed Logic Channel for logic-based model validation, selection and improvement on LVLM with enhanced explainability and trustworthiness.",,,"Vision-Language Model, Visual-Language Comprehension, logic reasoning, zero-shot",interpretability and explainable AI,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=zfAcPuIHkE,https://openreview.net/forum?id=zfAcPuIHkE,,
ZhXJNUEOr9,Sparling: Learning Latent Representations with Extremely Sparse Activations,"Real-world processes often contain intermediate state that can be modeled as an extremely sparse activation tensor. In this work, we analyze the identifiability of such sparse and local latent intermediate variables, which we call motifs.
We prove our Motif Identifiability Theorem, stating that under certain assumptions it is possible to precisely identify these motifs exclusively by reducing end-to-end error. Additionally, we provide the Sparling algorithm, which uses a new kind of informational bottleneck that enforces levels of activation sparsity unachievable using other techniques. We find that extreme sparsity is necessary to achieve good intermediate state modeling empirically. On our synthetic DigitCircle domain as well as the LaTeXOCR and AudioMNISTSequence domains, we are able to precisely localize the intermediate states up to feature permutation with >90% accuracy, even though we only train end-to-end.","Kavi Gupta, Osbert Bastani, Armando Solar-Lezama","~Kavi_Gupta1, ~Osbert_Bastani1, ~Armando_Solar-Lezama1","machine learning, sparsity, interpretability, optimization, identifiability",interpretability and explainable AI,Submitted to ICLR 2025,2025,https://openreview.net/pdf?id=ZhXJNUEOr9,https://openreview.net/forum?id=ZhXJNUEOr9,,
ZmhpqpKzAT,IGC-Net for conditional average potential outcome estimation over time,"Estimating potential outcomes for treatments over time based on observational data is important for personalized decision-making in medicine. However, many existing methods for this task fail to properly adjust for time-varying confounding and thus yield biased estimates. There are only a few neural methods with proper adjustments, but these have inherent limitations (e.g., division by propensity scores that are often close to zero), which result in poor performance. As a remedy, we introduce the iterative G-computation network (IGC-Net). Our IGC-Net is a novel, neural end-to-end model which adjusts for time-varying confounding in order to estimate conditional average potential outcomes (CAPOs) over time. Specifically, our IGC-Net is the first neural model to perform fully regression-based iterative G-computation for CAPOs in the time-varying setting. We evaluate the effectiveness of our IGC-Net across various experiments. In sum, this work represents a significant step towards personalized decision-making from electronic health records.",,,"causal inference, potential outcomes, treatment effects, healthcare",causal reasoning,ICLR 2026 Conference Submission,2026,https://openreview.net/pdf?id=ZmhpqpKzAT,https://openreview.net/forum?id=ZmhpqpKzAT,,
HCSgyPUfeDj,Learning and Evaluating Representations for Deep One-Class Classification,"We present a two-stage framework for deep one-class classification. We first learn self-supervised  representations from one-class data, and then build one-class classifiers on learned representations. The framework not only allows to learn better representations, but also permits building one-class classifiers that are faithful to the target task. We argue that classifiers inspired by the statistical perspective in generative or discriminative models are more effective than existing approaches, such as a normality score from a surrogate classifier. We thoroughly evaluate different self-supervised representation learning algorithms under the proposed framework for one-class classification. Moreover, we present a novel distribution-augmented contrastive learning that extends training distributions via data augmentation to obstruct the uniformity of contrastive representations. In experiments, we demonstrate state-of-the-art performance on visual domain one-class classification benchmarks, including novelty and anomaly detection. Finally, we present visual explanations, confirming that the decision-making process of deep one-class classifiers is intuitive to humans. The code is available at https://github.com/google-research/deep_representation_one_class.
","Kihyuk Sohn, Chun-Liang Li, Jinsung Yoon, Minho Jin, Tomas Pfister",,"deep one-class classification, self-supervised learning",,ICLR.cc/2021/Conference,2021,https://openreview.net/pdf?id=HCSgyPUfeDj,https://openreview.net/forum?id=HCSgyPUfeDj,"~Kihyuk_Sohn1, ~Chun-Liang_Li1, ~Jinsung_Yoon1, minhojin@google.com, ~Tomas_Pfister1",1.60E+12
a3OY2j9kJc-,MaSS: Multi-attribute Selective Suppression,"The recent rapid advances in the development and deployment of machine learning technologies largely depend on the vast richness of data available today, in terms of both the quantity and the rich content contained within. For example, biometric data such as images and voices could reveal people's attributes like age, gender, sentiment, and origin, whereas location/motion data could be used to infer people's activity levels, transportation modes, and life habits. Along with the new services and applications enabled by such technological advances, various governmental policies are put in place to regulate such data usage and protect people's privacy and rights. As a result, data owners often opt for simple data obfuscation (e.g., blur people's faces in images) or withholding data altogether, which leads to severe data quality degradation and greatly limits the data's potential utility.
Aiming for a sophisticated mechanism which gives data owners fine-grained control while retaining the maximal degree of data utility, we propose Multi-attribute Selective Suppression, or MaSS, a general framework for performing precisely targeted data surgery to simultaneously suppress any selected set of attributes while preserving the rest for downstream machine learning tasks. MaSS learns a data modifier through adversarial games between two sets of networks, where one is aimed at suppressing selected attributes, and the other ensures the retention of the rest of the attributes via general contrastive loss as well as explicit classification metrics. We carried out an extensive evaluation of our proposed method using multiple datasets from different domains including facial images, voice audio, and video clips, and obtained highly promising results in MaSS' generalizability and capability of drastically suppressing targeted attributes (e.g., reducing inference on such attributes to random guess) while imposing virtually no impact on the data's usability in other downstream ML tasks.","Chun-Fu Chen, Shaohan Hu, Zhonghao Shi, Prateek Gulati, Bill Moriarty, Marco Pistoia, Vincenzo Piuri, Pierangela Samarati",,"Multi-attribute, GAN, Attribute Suppression",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=a3OY2j9kJc-,https://openreview.net/forum?id=a3OY2j9kJc-,"~Chun-Fu_Chen1, shaohan.hu@jpmchase.com, zhonghas@usc.edu, ~Prateek_Gulati1, william.r.moriarty@jpmchase.com, marco.pistoia@jpmchase.com, vincenzo.piuri@unimi.it, pierangela.samarat@unimi.it",1.66E+12
UP_GHHPw7rP,Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game,"Offline reinforcement learning (RL) aims at learning an optimal strategy using a pre-collected dataset without further interactions with the environment. While various algorithms have been proposed for offline RL in the previous literature, the minimax optimality has only been (nearly) established for tabular Markov decision processes (MDPs). In this paper, we focus on offline RL with linear function approximation and propose a new pessimism-based algorithm for offline linear MDP. At the core of our algorithm is the uncertainty decomposition via a reference function, which is new in the literature of offline RL under linear function approximation. Theoretical analysis demonstrates that our algorithm can match the performance lower bound up to logarithmic factors. We also extend our techniques to the two-player zero-sum Markov games (MGs), and establish a new performance lower bound for MGs, which tightens the existing result, and verifies the nearly minimax optimality of the proposed algorithm. To the best of our knowledge, these are the first computationally efficient and nearly minimax optimal algorithms for offline single-agent MDPs and MGs with linear function approximation.","Wei Xiong, Han Zhong, Chengshuai Shi, Cong Shen, Liwei Wang, Tong Zhang",,RL theory,,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=UP_GHHPw7rP,https://openreview.net/forum?id=UP_GHHPw7rP,"~Wei_Xiong9, ~Han_Zhong1, ~Chengshuai_Shi1, ~Cong_Shen1, ~Liwei_Wang1, ~Tong_Zhang2",1.66E+12
HklCmaVtPS,UW-NET: AN INCEPTION-ATTENTION NETWORK FOR UNDERWATER IMAGE CLASSIFICATION,"The classification of images taken in special imaging environments except air is the first challenge in extending the applications of deep learning. We report on an UW-Net (Underwater Network), a new convolutional neural network (CNN) based network for underwater image classification. In this model, we simulate the visual correlation of background attention with image understanding for special environments, such as fog and underwater by constructing an inception-attention (I-A) module. The experimental results demonstrate that the proposed UW-Net achieves an accuracy of 99.3% on underwater image classification, which is significantly better than other image classification networks, such as AlexNet, InceptionV3, ResNet and Se-ResNet. Moreover, we demonstrate the proposed IA module can be used to boost the performance of the existing object recognition networks. By substituting the inception module with the I-A module, the Inception-ResnetV2 network achieves a 10.7% top1 error rate and a 0% top5 error rate on the subset of ILSVRC-2012, which further illustrates the function of the background attention in the image classifications.","Miao Yang and Ke Hu, Chongyi Li, Zhiqiang Wei",,"Underwater image, Convolutional neural network, Image classification, Inception module, Attention module",,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=HklCmaVtPS,https://openreview.net/forum?id=HklCmaVtPS,"lemonmiao@gmial.com, kexisibest@outlook.com, lichongyi@tju.edu.cn, weizhiqiang@ouc.edu.cn",1.57E+12
9OoFFWDPDQ,Delving into the Openness of CLIP,"Contrastive Language-Image Pre-training (CLIP) has demonstrated great potential in realizing open-vocabulary visual recognition in a matching style, due to its holistic use of natural language supervision that covers unconstrained real-world visual concepts. However, it is, in turn, also difficult to evaluate and analyze the openness of CLIP-like models, since they are in theory open to any vocabulary but the actual accuracy varies. To address the insufficiency of conventional studies on openness, we resort to an incremental perspective and define the extensibility, which essentially approximates the model's ability to deal with new visual concepts, by evaluating openness through vocabulary expansions. Our evaluation based on extensibility shows that CLIP-like models are hardly truly open and their performances degrade as the vocabulary expands to different degrees. Further analysis reveals that the over-estimation of openness is not because CLIP-like models fail to capture the general similarity of image and text features of novel visual concepts, but because of the confusion among competing text features, that is, they are not stable with respect to the vocabulary. In light of this, we propose to improve the openness of CLIP in feature space by enforcing the distinguishability of text features. Our method retrieves relevant texts from the pre-training corpus to enhance prompts for inference, which boosts the extensibility and stability of CLIP even without fine-tuning.","Shuhuai Ren, Lei Li, Xuancheng Ren, Guangxiang Zhao, Xu Sun",,"Contrastive Language-Image Pre-training, CLIP, Openness, Vision-and-Language",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=9OoFFWDPDQ,https://openreview.net/forum?id=9OoFFWDPDQ,"~Shuhuai_Ren1, ~Lei_Li14, ~Xuancheng_Ren1, ~Guangxiang_Zhao3, ~Xu_Sun1",1.66E+12
6Wl7-M2BC-,An Adaptive Policy to Employ Sharpness-Aware Minimization,"Sharpness-aware minimization (SAM), which searches for flat minima by min-max optimization, has been shown to be useful in improving model generalization. However, since each SAM update requires computing two gradients, its computational cost and training time are both doubled compared to standard empirical risk minimization (ERM). Recent state-of-the-arts reduce the fraction of SAM updates and thus accelerate SAM by switching between SAM and ERM updates randomly or periodically. In this paper, we design an adaptive policy to employ SAM based on the loss landscape geometry. Two efficient algorithms, AE-SAM and AE-LookSAM, are proposed. We theoretically show that AE-SAM has the same convergence rate as SAM. Experimental results on various datasets and architectures demonstrate the efficiency and effectiveness of the adaptive policy.","Weisen Jiang, Hansi Yang, Yu Zhang, James Kwok",,"Sharpness-aware minimization, model generalization, loss landscape",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=6Wl7-M2BC-,https://openreview.net/forum?id=6Wl7-M2BC-,"~Weisen_Jiang1, ~Hansi_Yang1, ~Yu_Zhang3, ~James_Kwok1",1.66E+12
ElI9znK_eUz,Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning,"Humans learn by interacting with their environments and perceiving the outcomes of their actions. A landmark in artificial intelligence has been the development of deep reinforcement learning (dRL) algorithms capable of doing the same in video games, on par with or better than humans. However, it remains unclear whether the successes of dRL models reflect advances in visual representation learning, the effectiveness of reinforcement learning algorithms at discovering better policies, or both. To address this question, we introduce the Learning Challenge Diagnosticator (LCD), a tool that separately measures the perceptual and reinforcement learning demands of a task. We use LCD to discover a novel taxonomy of challenges in the Procgen benchmark, and demonstrate that these predictions are both highly reliable and can instruct algorithmic development. More broadly, the LCD reveals multiple failure cases that can occur when optimizing dRL algorithms over entire video game benchmarks like Procgen, and provides a pathway towards more efficient progress.","Lakshmi Narasimhan Govindarajan, Rex G Liu, Drew Linsley, Alekh Karkada Ashok, Max Reuter, Michael Frank, Thomas Serre",,"Cognitive Science, Deep Reinforcement Learning, Perceptual Grouping, Neuroscience",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=ElI9znK_eUz,https://openreview.net/forum?id=ElI9znK_eUz,"~Lakshmi_Narasimhan_Govindarajan3, ~Rex_G_Liu1, ~Drew_Linsley1, ~Alekh_Karkada_Ashok1, ~Max_Reuter1, ~Michael_Frank2, ~Thomas_Serre1",1.66E+12
H7Edu1_IZgR,Transformers are Meta-Reinforcement Learners,"The transformer architecture and variants presented a remarkable success across many machine learning tasks in recent years. This success is intrinsically related to the capability of handling long sequences and the presence of context-dependent weights from the attention mechanism. We argue that these capabilities suit the central role of a Meta-Reinforcement Learning algorithm. Indeed, a meta-RL agent needs to infer the task from a sequence of trajectories. Furthermore, it requires a fast adaptation strategy to adapt its policy for a new task - which can be achieved using the self-attention mechanism. In this work, we present TrMRL (Transformers for Meta-Reinforcement Learning), a meta-RL agent that mimics the memory reinstatement mechanism using the transformer architecture. It associates the recent past of working memories to build an episodic memory recursively through the transformer layers. This memory works as a proxy to the current task, and we condition a policy head on it. We conducted experiments in high-dimensional continuous control environments for locomotion and dexterous manipulation. Results show that TrMRL achieves or surpasses state-of-the-art performance, sample efficiency, and out-of-distribution generalization in these environments.",Luckeciano Carvalho Melo,,"Reinforcement Learning, Meta-Reinforcement Learning, Transformers",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=H7Edu1_IZgR,https://openreview.net/forum?id=H7Edu1_IZgR,~Luckeciano_Carvalho_Melo1,1.63E+12
3RhuF8foyPW,Single-shot General Hyper-parameter Optimization for Federated Learning,"We address the problem of hyper-parameter optimization (HPO) for federated learning (FL-HPO). We introduce Federated Loss SuRface Aggregation (FLoRA), a general FL-HPO solution framework that can address use cases of tabular data and any Machine Learning (ML) model including gradient boosting training algorithms, SVMs, neural networks, among others and thereby further expands the scope of FL-HPO. FLoRA enables single-shot FL-HPO: identifying a single set of good hyper-parameters that are subsequently used in a single FL training. Thus, it enables FL-HPO solutions with minimal additional communication overhead compared to FL training without HPO. Utilizing standard smoothness assumptions, we theoretically characterize the optimality gap of FLoRA for any convex and non-convex loss functions, which explicitly accounts for the heterogeneous nature of the parties' local data distributions, a dominant characteristic of FL systems. Our empirical evaluation of FLoRA for multiple FL algorithms on seven OpenML datasets demonstrates significant model accuracy improvements over the baselines, and robustness to increasing number of parties involved in FL-HPO training.","Yi Zhou, Parikshit Ram, Theodoros Salonidis, Nathalie Baracaldo, Horst Samulowitz, Heiko Ludwig",,"Federated Learning, Hyperparameter Optimization, Optimality Gap Analysis",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=3RhuF8foyPW,https://openreview.net/forum?id=3RhuF8foyPW,"~Yi_Zhou13, ~Parikshit_Ram1, ~Theodoros_Salonidis1, ~Nathalie_Baracaldo1, ~Horst_Samulowitz1, ~Heiko_Ludwig1",1.66E+12
#NAME?,Task-Aware Information Routing from Common Representation Space in Lifelong Learning,"Intelligent systems deployed in the real world suffer from catastrophic forgetting when exposed to a sequence of tasks. Humans, on the other hand, acquire, consolidate, and transfer knowledge between tasks that rarely interfere with the consolidated knowledge.  Accompanied by self-regulated neurogenesis, continual learning in the brain is governed by the rich set of neurophysiological processes that harbor different types of knowledge which are then integrated by the conscious processing. Thus, inspired by Global Workspace Theory of conscious information access in the brain, we propose TAMiL, a continual learning method that entails task-attention modules to capture task-specific information from the common representation space. We employ simple, undercomplete autoencoders to create a communication bottleneck between the common representation space and the global workspace, allowing only the task-relevant information to the global workspace, thereby greatly reducing task interference. Experimental results show that our method outperforms state-of-the-art rehearsal-based and dynamic sparse approaches and bridges the gap between fixed capacity and parameter isolation approaches while being scalable. We also show that our method effectively mitigates catastrophic forgetting while being well-calibrated with reduced task-recency bias.","Prashant Shivaram Bhat, Bahram Zonooz, Elahe Arani",,"Continual learning, Lifelong learning, Representation learning, Global workspace theory, Task-specific attention",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=-M0TNnyWFT5,https://openreview.net/forum?id=-M0TNnyWFT5,"~Prashant_Shivaram_Bhat1, ~Bahram_Zonooz1, ~Elahe_Arani1",1.66E+12
QcA9iGaLpH4,What do large networks memorize?,"The success of modern neural models has prompted renewed study of the connection between memorisation and generalisation: such models typically generalise well, despite being able to perfectly fit (""memorise"") completely random labels.
To more carefully study this issue, Feldman (2019); Feldman & Zhang (2020) provided a simple metric to quantify the degree of memorisation of a specific training example, and empirically quantified the corresponding memorisation profile of a ResNet model on image classification benchmarks.
While an exciting first glimpse into how real-world models memorise, these studies leave open several questions about memorisation of practical networks.
In particular, how is memorisation affected by increasing model size, and by distilling a large model into a smaller one?
We present a systematic empirical analysis of these questions.
On standard image classification benchmarks, we find that training examples exhibit a diverse set of memorisation trajectories across model sizes, with some samples having increased memorisation under larger models.
Further, we find that distillation tends to inhibit memorisation of the student model, while also improving generalisation.
Finally, we show that computationally tractable measures of memorisation do not capture the properties we identify for memorisation in the sense of Feldman (2019), despite highly correlating to the latter.","Michal Lukasik, Aditya Krishna Menon, Ankit Singh Rawat, Vaishnavh Nagarajan, Sanjiv Kumar",,"memorization, overparameterization, example difficulty",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=QcA9iGaLpH4,https://openreview.net/forum?id=QcA9iGaLpH4,"~Michal_Lukasik1, ~Aditya_Krishna_Menon1, ~Ankit_Singh_Rawat1, ~Vaishnavh_Nagarajan3, ~Sanjiv_Kumar1",1.66E+12
SJl3h2EYvS,CLAREL: classification via retrieval loss for zero-shot learning,"We address the problem of learning fine-grained cross-modal representations. We propose an instance-based deep metric learning approach in joint visual and textual space. The key novelty of this paper is that it shows that using per-image semantic supervision leads to substantial improvement in zero-shot performance over using class-only supervision. On top of that, we provide a probabilistic justification for a metric rescaling approach that solves a very common problem in the generalized zero-shot learning setting, i.e., classifying test images from unseen classes as one of the classes seen during training. We evaluate our approach on two fine-grained zero-shot learning datasets: CUB and FLOWERS. We find that on the generalized zero-shot classification task CLAREL consistently outperforms the existing approaches on both datasets.","Boris N. Oreshkin, Negar Rostamzadeh, Pedro O. Pinheiro, Christopher Pal",,"zero-shot learning, representation learning, fine-grained classification",,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=SJl3h2EYvS,https://openreview.net/forum?id=SJl3h2EYvS,"boris@elementai.com, negar@elementai.com, pedro@elementai.com, christopher.pal@elementai.com",1.57E+12
R5sVzzXhW8n,Demystifying How Self-Supervised Features Improve Training from Noisy Labels,"The advancement of self-supervised learning (SSL) motivates researchers to apply SSL on other tasks such as learning with noisy labels. Recent literature indicates that methods built on SSL features can substantially improve the performance of learning with noisy labels. Nonetheless, the deeper reasons why (and how) SSL features benefit the training from noisy labels are less understood. In this paper, we study why and how self-supervised features help networks resist label noise using both theoretical analyses and numerical experiments. Our result shows that, given a quality encoder pre-trained from SSL, a simple linear layer trained by the cross-entropy loss is theoretically robust to symmetric label noise. Further, we provide insights for how knowledge distilled from SSL features can alleviate the over-fitting problem. We hope our work provides a better understanding for learning with noisy labels from the perspective of self-supervised learning and can potentially serve as a guideline for further research.","Hao Cheng, Zhaowei Zhu, Xing Sun, Yang Liu",,"Learning with noisy labels, Self-Supervised Learning",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=R5sVzzXhW8n,https://openreview.net/forum?id=R5sVzzXhW8n,"~Hao_Cheng5, ~Zhaowei_Zhu1, ~Xing_Sun1, ~Yang_Liu3",1.63E+12
ywAjQw-spmY,Formal Specifications from Natural Language,"We study the generalization abilities of language models when translating natural language into formal specifications with complex semantics. In particular, we fine-tune language models on three datasets consisting of English sentences and their corresponding formal representation: 1) regular expressions (regex), frequently used in programming and search; 2) First-order logic (FOL), commonly used in software verification and theorem proving; and 3) linear-time temporal logic (LTL), which forms the basis for industrial hardware specification languages. Our experiments show that, in these diverse domains, the language models maintain their generalization capabilities from pre-trained knowledge of natural language to generalize, e.g., to new variable names or operator descriptions. Additionally, they achieve competitive performance, and even outperform the state-of-the-art for translating into regular expressions, with the benefits of being easy to access, efficient to fine-tune, and without a particular need for domain-specific reasoning.","Christopher Hahn, Frederik Schmitt, Julia Janice Tillman, Niklas Metzger, Julian Siber, Bernd Finkbeiner",,"language models, natural language, formal specifications, first-order logic, temporal logic, regular expressions",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=ywAjQw-spmY,https://openreview.net/forum?id=ywAjQw-spmY,"~Christopher_Hahn1, ~Frederik_Schmitt1, ~Julia_Janice_Tillman1, ~Niklas_Metzger1, ~Julian_Siber1, ~Bernd_Finkbeiner1",1.66E+12
4RwkbKZhGV,A Time-Consistency Curriculum for Learning from Instance-Dependent Noisy Labels,"Many machine learning algorithms are known to be fragile on simple instance-independent noisy labels. However, noisy labels in real-world data are more devastating since they are produced by more complicated mechanisms in an instance-dependent manner. In this paper, we target this practical challenge of  \textit{Instance-Dependent Noisy Labels} by jointly training 
(1) a model reversely engineering the noise generating mechanism, which produces an \textit{instance-dependent mapping} between the clean label posterior and the observed noisy label; and (2) a robust classifier that produces clean label posteriors. Compared to previous methods, the former model is novel and enables end-to-end learning of the latter directly from noisy labels. An extensive empirical study indicates that the time-consistency of data is critical to the success of training both models and motivates us to develop a curriculum selecting training data based on their dynamics on the two models' outputs over the course of training. We show that the curriculum-selected data provide both clean labels and high-quality input-output pairs for training the two models. Therefore, it leads to promising and robust classification performance even in notably challenging settings of instance-dependent noisy labels where many SoTA methods could easily fail. Extensive experimental comparisons and ablation studies further demonstrate the advantages and significance of the time-consistency curriculum in learning from instance-dependent noisy labels on multiple benchmark datasets.","Songhua Wu, Tianyi Zhou, Yuxuan Du, Jun Yu, Bo Han, Tongliang Liu",,,,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=4RwkbKZhGV,https://openreview.net/forum?id=4RwkbKZhGV,"~Songhua_Wu1, ~Tianyi_Zhou1, ~Yuxuan_Du2, ~Jun_Yu3, ~Bo_Han1, ~Tongliang_Liu1",1.66E+12
Hklo5RNtwS,Behavior-Guided Reinforcement Learning,"We introduce a new approach for comparing reinforcement learning policies, using Wasserstein distances (WDs) in a newly defined latent behavioral space. We show that by utilizing the dual formulation of the WD, we can learn score functions over trajectories that can be in turn used to lead policy optimization towards (or away from) (un)desired behaviors. Combined with smoothed WDs, the dual formulation allows us to devise efficient algorithms that take stochastic gradient descent steps through WD regularizers. We incorporate these regularizers into two novel on-policy algorithms, Behavior-Guided Policy Gradient and Behavior-Guided Evolution Strategies, which we demonstrate can outperform existing methods in a variety of challenging environments. We also provide an open source demo.","Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang, Anna Choromanska, Krzysztof Choromanski, Michael I. Jordan",,"Reinforcement Learning, Optimal Transport, Evolution Strategies",,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=Hklo5RNtwS,https://openreview.net/forum?id=Hklo5RNtwS,"pacchiano@berkeley.edu, jh3764@columbia.edu, yt2541@columbia.edu, achoroma@gmail.com, kchoro@google.com, jordan@cs.berkeley.edu",1.57E+12
_tfLpF9mFiq,No Pairs Left Behind: Improving Metric Learning with Regularized Triplet Objective,"We propose a novel formulation of the triplet objective function that improves metric learning without additional sample mining or overhead costs. Our approach aims to explicitly regularize the distance between the positive and negative samples in a triplet with respect to the anchor-negative distance. As an initial validation, we show that our method (called No Pairs Left Behind [NPLB]) improves upon the traditional and current state-of-the-art triplet objective formulations on standard benchmark datasets. To show the effectiveness and potentials of NPLB on real-world complex data, we evaluate our approach on a large-scale healthcare dataset (UK Biobank), demonstrating that the embeddings learned by our model significantly outperform all other current representations on tested downstream tasks. Additionally, we provide a new model-agnostic single-time health risk definition that, when used in tandem with the learned representations, achieves the most accurate prediction of a patient's future health complications. Our results indicate that NPLB is a simple, yet effective framework for improving existing deep metric learning models, showcasing the potential implications of deep metric learning in more complex applications, especially in the biological and healthcare domains.","A. Ali Heydari, Naghmeh Rezaei, Daniel McDuff, Javier L Prieto",,"Deep Metric Learning, Representation Learning, Machine Learning for Healthcare, Triplet Loss",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=_tfLpF9mFiq,https://openreview.net/forum?id=_tfLpF9mFiq,"~A._Ali_Heydari1, ~Naghmeh_Rezaei1, ~Daniel_McDuff1, ~Javier_L_Prieto1",1.66E+12
zXM0b4hi5_B,On the relation between statistical learning and perceptual distances,"It has been demonstrated many times that the behavior of the human visual system is connected to the statistics of natural images. Since machine learning relies on the statistics of training data as well, the above connection has interesting implications when using perceptual distances (which mimic the behavior of the human visual system) as a loss function. In this paper, we aim to unravel the non-trivial relationships between the probability distribution of the data, perceptual distances, and unsupervised machine learning. To this end, we show that perceptual sensitivity is correlated with the probability of an image in its close neighborhood. We also explore the relation between distances induced by autoencoders and the probability distribution of the training data, as well as how these induced distances are correlated with human perception. Finally, we find perceptual distances do not always lead to noticeable gains in performance over Euclidean distance in common image processing tasks, except when data is scarce and the perceptual distance provides regularization. We propose this may be due to a double-counting effect of the image statistics, once in the perceptual distance and once in the training procedure.","Alexander Hepburn, Valero Laparra, Raul Santos-Rodriguez, Jona Ballé, Jesus Malo",,,,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=zXM0b4hi5_B,https://openreview.net/forum?id=zXM0b4hi5_B,"~Alexander_Hepburn2, ~Valero_Laparra1, ~Raul_Santos-Rodriguez1, ~Jona_Ballé1, ~Jesus_Malo1",1.63E+12
VGnOJhd5Q1q,Sparse Attention with Learning to Hash,"Transformer has become ubiquitous in sequence modeling tasks. As a key component of Transformer, self-attention does not scale to long sequences due to its quadratic time and space complexity with respect to the sequence length. To tackle this problem, recent work developed dynamic attention sparsification techniques based on Approximate Nearest Neighbor (ANN) methods, where similar queries and keys are allocated to the same hash bucket with high probability. However, the effectiveness of those ANN methods relies on the assumption that queries and keys should lie in the same space, which is not well justified. Besides, some of the ANN methods such as Locality-Sensitive Hashing (LSH) are randomized and cannot fully utilize the available real data distributions. To overcome these issues, this paper proposes a new strategy for sparse attention, namely LHA (Learning-to-Hash Attention), which directly learns separate parameterized hash functions for queries and keys, respectively. Another advantage of LHA is that it does not impose extra constraints for queries and keys, which makes it applicable to the wide range of pre-trained Transformer models. Our experiments on evaluation of the WikiText-103 dataset for language modeling, the GLUE benchmark for natural language understanding, and the Lang-Range-Arena benchmark for multiple tasks (text/image classification, retrieval, etc.) show the superior performance of LHA over other strong Transformer variants.","Zhiqing Sun, Yiming Yang, Shinjae Yoo",,"Sparse Attention, Transformer, Learning-to-Hash, Natural Language Processing",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=VGnOJhd5Q1q,https://openreview.net/forum?id=VGnOJhd5Q1q,"~Zhiqing_Sun1, ~Yiming_Yang1, ~Shinjae_Yoo1",1.63E+12
TUBpc5rqGA,Neural Design for Genetic Perturbation Experiments,"The problem of how to genetically modify cells in order to maximize a certain cellular phenotype has taken center stage in drug development over the last few years (with, for example, genetically edited CAR-T, CAR-NK, and CAR-NKT cells entering cancer clinical trials). Exhausting the search space for all possible genetic edits (perturbations) or combinations thereof is infeasible due to cost and experimental limitations. This work provides a theoretically sound framework for iteratively exploring the space of perturbations in pooled batches in order to maximize a target phenotype under an experimental budget. Inspired by this application domain, we study the problem of batch query bandit optimization and introduce the Optimistic Arm Elimination ($\mathrm{OAE}$) principle designed to find an almost optimal arm under different functional relationships between the queries (arms) and the outputs (rewards). We analyze the convergence properties of $\mathrm{OAE}$ by relating it to the Eluder dimension of the algorithm's function class and validate that $\mathrm{OAE}$ outperforms other strategies in finding optimal actions in experiments on simulated problems, public datasets well-studied in bandit contexts, and in genetic perturbation datasets when the regression model is a deep neural network. OAE also outperforms the benchmark algorithms in 3 of 4 datasets in the GeneDisco experimental planning challenge.","Aldo Pacchiano, Drausin Wulsin, Robert A Barton, Luis Voloch",,"genetiic perturbation experiments, gene disco, optimism, neural optimism",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=TUBpc5rqGA,https://openreview.net/forum?id=TUBpc5rqGA,"~Aldo_Pacchiano1, ~Drausin_Wulsin1, ~Robert_A_Barton1, luis@immunai.com",1.66E+12
4l5iO9eoh3f,Supervised Permutation Invariant Networks for solving the CVRP with bounded fleet size,"Learning to solve combinatorial optimization problems, such as the vehicle routing problem, offers great computational advantages over classical operation research solvers and heuristics. The recently developed deep reinforcement learning approaches either improve an initially given solution iteratively or sequentially construct a set of individual tours. 
However, all existing learning-based approaches are not able to work for a fixed number of vehicles and thus bypass the NP-hardness of the original problem. On the other hand, this makes them less suitable for real applications, as many logistic service providers rely on solutions provided for a specific bounded fleet size and cannot accommodate short term changes to the number of vehicles.
In contrast we propose a powerful supervised deep learning framework that constructs a complete tour plan from scratch while respecting an apriori fixed number of vehicles. 
In combination with an efficient post-processing scheme, our supervised approach is not only much faster and easier to train but also achieves competitive results that incorporate the practical aspect of vehicle costs.
In thorough controlled experiments we re-evaluate and compare our method to multiple state-of-the-art approaches where we demonstrate stable performance and shed some light on existent inconsistencies in the experimentation protocols of the related work.","Daniela Thyssens, Jonas Falkner, Lars Schmidt-Thieme",,"Deep Learning, Combinatorial Optimization, Vehicle Routing",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=4l5iO9eoh3f,https://openreview.net/forum?id=4l5iO9eoh3f,"~Daniela_Thyssens1, ~Jonas_Falkner1, ~Lars_Schmidt-Thieme1",1.63E+12
r1eVX0EFvH,Exploiting Excessive Invariance caused by Norm-Bounded Adversarial Robustness,"Adversarial examples are malicious inputs crafted to cause a model to misclassify them. In their most common instantiation, ""perturbation-based"" adversarial examples introduce  changes to the input that leave its true label unchanged, yet result in a different model prediction.  Conversely, ""invariance-based"" adversarial examples insert changes to the input that leave the model's prediction unaffected despite the underlying input's label having changed. So far, the relationship between these two notions of adversarial examples has not been studied, we close this gap.

We demonstrate that solely achieving perturbation-based robustness is insufficient for complete adversarial robustness. Worse, we find that classifiers trained to be Lp-norm robust are more vulnerable to invariance-based adversarial examples than their undefended counterparts. We construct theoretical arguments and analytical examples to justify why this is the case. We then illustrate empirically that the consequences of excessive perturbation-robustness can be exploited to craft new attacks. Finally, we show how to attack a provably robust defense --- certified on the MNIST test set to have at least 87% accuracy (with respect to the original test labels) under perturbations of Linfinity-norm below epsilon=0.4 --- and reduce its accuracy (under this threat model with respect to an ensemble of human labelers) to 60% with an automated attack, or just 12% with human-crafted adversarial examples.","Jörn-Henrik Jacobsen, Jens Behrmann, Nicholas Carlini, Florian Tramèr, Nicolas Papernot",,"Invariance, Robustness, Adversarial Examples",,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=r1eVX0EFvH,https://openreview.net/forum?id=r1eVX0EFvH,"j.jacobsen@vectorinstitute.ai, jensb@uni-bremen.de, nicholas@carlini.com, tramer@cs.stanford.edu, nicolas.papernot@utoronto.ca",1.57E+12
YmONQIWli--,Gotta Go Fast When Generating Data with Score-Based Models,"Score-based (denoising diffusion) generative models have recently gained a lot of success in generating realistic and diverse data. These approaches define a forward diffusion process for transforming data to noise and generate data by reversing it (thereby going from noise to data). Unfortunately, current score-based models generate data very slowly due to the sheer number of score network evaluations required by numerical SDE solvers. 
   
In this work, we aim to accelerate this process by devising a more efficient SDE solver. Existing approaches rely on the Euler-Maruyama (EM) solver, which uses a fixed step size. We found that naively replacing it with other SDE solvers fares poorly - they either result in low-quality samples or become slower than EM. To get around this issue, we carefully devise an SDE solver with adaptive step sizes tailored to score-based generative models piece by piece. Our solver requires only two score function evaluations, rarely rejects samples, and leads to high-quality samples. Our approach generates data 2 to 10 times faster than EM while achieving better or equal sample quality. For high-resolution images, our method leads to significantly higher quality samples than all other methods tested. Our SDE solver has the benefit of requiring no step size tuning.","Alexia Jolicoeur-Martineau, Ke Li, Rémi Piché-Taillefer, Tal Kachman, Ioannis Mitliagkas",,"score-based, generative model, denoising diffusion, SDE, diffusion process",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=YmONQIWli--,https://openreview.net/forum?id=YmONQIWli--,"~Alexia_Jolicoeur-Martineau1, ~Ke_Li1, ~Rémi_Piché-Taillefer1, ~Tal_Kachman1, ~Ioannis_Mitliagkas1",1.63E+12
BJgd81SYwr,Meta Dropout: Learning to Perturb Latent Features for Generalization,"A machine learning model that generalizes well should obtain low errors on unseen test examples. Thus, if we know how to optimally perturb training examples to account for test examples, we may achieve better generalization performance. However, obtaining such perturbation is not possible in standard machine learning frameworks as the distribution of the test data is unknown. To tackle this challenge, we propose a novel regularization method, meta-dropout, which learns to perturb the latent features of training examples for generalization in a meta-learning framework. Specifically, we meta-learn a noise generator which outputs a multiplicative noise distribution for latent features, to obtain low errors on the test instances in an input-dependent manner. Then, the learned noise generator can perturb the training examples of unseen tasks at the meta-test time for improved generalization. We validate our method on few-shot classification datasets, whose results show that it significantly improves the generalization performance of the base model, and largely outperforms existing regularization methods such as information bottleneck, manifold mixup, and information dropout.","Hae Beom Lee, Taewook Nam, Eunho Yang, Sung Ju Hwang",,,,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=BJgd81SYwr,https://openreview.net/forum?id=BJgd81SYwr,"haebeom.lee@kaist.ac.kr, namsan@kaist.ac.kr, eunhoy@kaist.ac.kr, sjhwang82@kaist.ac.kr",1.57E+12
FIrQfNSOoTr,Instance-wise Batch Label Restoration via Gradients in Federated Learning,"Gradient inversion attacks have posed a serious threat to the privacy of federated learning. The attacks search for the optimal pair of input and label best matching the shared gradients and the search space of the attacks can be reduced by pre-restoring labels. Recently, label restoration technique allows for the extraction of labels from gradients analytically, but even the state-of-the-art remains limited to identify the presence of categories (i.e., the class-wise label restoration). This work considers the more real-world settings, where there are multiple instances of each class in a training batch. An analytic method is proposed to perform instance-wise batch label restoration from only the gradient of the final layer. On the basis of the approximate recovered class-wise embeddings and post-softmax probabilities, we establish linear equations of the gradients, probabilities and labels to derive the Number of Instances (NoI) per class by the Moore-Penrose pseudoinverse algorithm. Our experimental evaluations reach over 99% Label existence Accuracy (LeAcc) and exceed 96% Label number Accuracy (LnAcc) in most cases on three image datasets and four classification models. The two metrics are used to evaluate class-wise and instance-wise label restoration accuracy, respectively. And the recovery is made feasible even with a batch size of 4096 and partially negative activations (e.g., Leaky ReLU and Swish). Furthermore, we demonstrate that our method facilitates the existing gradient inversion attacks by exploiting the recovered labels, with an increase of 6-7 in PSNR on both MNIST and CIFAR100. Our code is
available at https://github.com/BUAA-CST/iLRG.","Kailang Ma, Yu Sun, Jian Cui, Dawei Li, Zhenyu Guan, Jianwei Liu",,"federated learning, batch label restoration, gradient inversion attack.",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=FIrQfNSOoTr,https://openreview.net/forum?id=FIrQfNSOoTr,"~Kailang_Ma1, sunyv@buaa.edu.cn, cuijianw@buaa.edu.cn, lidawei@buaa.edu.cn, ~Zhenyu_Guan1, liujianwei@buaa.edu.cn",1.66E+12
CuV_qYkmKb3,Scarf: Self-Supervised Contrastive Learning using Random Feature Corruption,"Self-supervised contrastive representation learning has proved incredibly successful in the vision and natural language domains, enabling state-of-the-art performance with orders of magnitude less labeled data. However, such methods are domain-specific and little has been done to leverage this technique on real-world \emph{tabular} datasets. We propose \textsc{Scarf}, a simple, widely-applicable technique for contrastive learning, where views are formed by corrupting a random subset of features. When applied to pre-train deep neural networks on the 69 real-world, tabular classification datasets from the OpenML-CC18 benchmark, \textsc{Scarf} not only improves classification accuracy in the fully-supervised setting but does so also in the presence of label noise and in the semi-supervised setting where only a fraction of the available training data is labeled. We show that \textsc{Scarf} complements existing strategies and outperforms alternatives like autoencoders. We conduct comprehensive ablations, detailing the importance of a range of factors.","Dara Bahri, Heinrich Jiang, Yi Tay, Donald Metzler",,"self-supervised learning, tabular data, pre-training, contrastive learning, openML",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=CuV_qYkmKb3,https://openreview.net/forum?id=CuV_qYkmKb3,"~Dara_Bahri1, ~Heinrich_Jiang1, ~Yi_Tay1, ~Donald_Metzler1",1.63E+12
7sWLxZBLPO5,Multiple Modes for Continual Learning,"Adapting model parameters to incoming streams of data is a crucial factor to deep learning scalability. Interestingly, prior continual learning strategies in online settings inadvertently anchor their updated parameters to a local parameter subspace to remember old tasks, else drift away from the subspace and forget. From this observation, we formulate a trade-off between constructing multiple parameter modes and allocating tasks per mode. Mode-Optimized Task Allocation (MOTA), our contributed adaptation strategy, trains multiple modes in parallel, then optimizes task allocation per mode. We empirically demonstrate improvements over baseline continual learning strategies and across varying distribution shifts, namely sub-population, domain, and task shift.","Siddhartha Datta, Nigel Shadbolt",,,,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=7sWLxZBLPO5,https://openreview.net/forum?id=7sWLxZBLPO5,"~Siddhartha_Datta1, ~Nigel_Shadbolt1",1.66E+12
tyyNcEVrklJ,Decentralized Policy Optimization,"The study of decentralized learning or independent learning in cooperative multi-agent reinforcement learning has a history of decades. Recently empirical studies show that independent PPO (IPPO) can obtain good performance, close to or even better than the methods of centralized training with decentralized execution, in several benchmarks. However, decentralized actor-critic with convergence guarantee is still open. In this paper, we propose decentralized policy optimization (DPO), a decentralized actor-critic algorithm with monotonic improvement and convergence guarantee. We derive a novel decentralized surrogate for policy optimization such that the monotonic improvement of joint policy can be guaranteed by each agent independently optimizing the surrogate. In practice, this decentralized surrogate can be realized by two adaptive coefficients for policy optimization at each agent. Empirically, we compare DPO with IPPO in a variety of cooperative multi-agent tasks, covering discrete and continuous action spaces, and fully and partially observable environments. The results show DPO outperforms IPPO in most tasks, which can be the evidence for our theoretical results.","Kefan Su, Zongqing Lu",,multi-agent reinforcement learning,,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=tyyNcEVrklJ,https://openreview.net/forum?id=tyyNcEVrklJ,"~Kefan_Su1, ~Zongqing_Lu2",1.66E+12
Jnspzp-oIZE,Gauge Equivariant Mesh CNNs: Anisotropic convolutions on geometric graphs,"A common approach to define convolutions on meshes is to interpret them as a graph and apply graph convolutional networks (GCNs).  Such GCNs utilize isotropic kernels and are therefore insensitive to the relative orientation of vertices and thus to the geometry of the mesh as a whole. We propose Gauge Equivariant Mesh CNNs which generalize GCNs to apply anisotropic gauge equivariant kernels. Since the resulting features carry orientation information, we introduce a geometric message passing scheme defined by parallel transporting features over mesh edges. Our experiments validate the significantly improved expressivity of the proposed model over conventional GCNs and other methods.","Pim De Haan, Maurice Weiler, Taco Cohen, Max Welling",,"symmetry, equivariance, mesh, geometric, convolution",,ICLR.cc/2021/Conference,2021,https://openreview.net/pdf?id=Jnspzp-oIZE,https://openreview.net/forum?id=Jnspzp-oIZE,"~Pim_De_Haan1, ~Maurice_Weiler1, ~Taco_Cohen1, ~Max_Welling1",1.60E+12
UjynxfqnGWG,Inductive Biases and Variable Creation in Self-Attention Mechanisms,"Self-attention, an architectural motif designed to model long-range interactions in sequential data, has driven numerous recent breakthroughs in natural language processing and beyond. This work provides a theoretical analysis of the inductive biases of self-attention modules, where our focus is to rigorously establish which functions and long-range dependencies self-attention blocks prefer to represent. We show that bounded-norm Transformer layers create sparse variables: they can represent sparse Lipschitz functions of the input sequence, with sample complexity scaling only logarithmically with the context length. We propose new experimental protocols to support the analysis and guide the practice of training Transformers, built around the rich theory of learning sparse Boolean functions.","Benjamin L. Edelman, Surbhi Goel, Sham M. Kakade, Cyril Zhang",,"transformers, attention",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=UjynxfqnGWG,https://openreview.net/forum?id=UjynxfqnGWG,"~Benjamin_L._Edelman1, ~Surbhi_Goel1, ~Sham_M._Kakade1, ~Cyril_Zhang1",1.63E+12
8xuFD1yCoH,TuneUp: A Training Strategy for Improving Generalization of Graph Neural Networks,"Despite many advances in Graph Neural Networks (GNNs), their training strategies simply focus on minimizing a loss over nodes in a graph. However, such simplistic training strategies may be sub-optimal as they neglect that certain nodes are much harder to make accurate predictions on than others. Here we present TuneUp, a curriculum learning strategy for better training GNNs. Crucially, TuneUp trains a GNN in two stages. The first stage aims to produce a strong base GNN. Such base GNNs tend to perform well on head nodes (nodes with large degrees) but less so on tail nodes (nodes with small degrees). So, the second stage of TuneUp specifically focuses on improving prediction on tail nodes. Concretely, TuneUp synthesizes many additional supervised tail node data by dropping edges from head nodes and reusing the supervision on the original head nodes. TuneUp then minimizes the loss over the synthetic tail nodes to finetune the base GNN. TuneUp is a general training strategy that can be used with any GNN architecture and any loss, making TuneUp applicable to a wide range of prediction tasks. Extensive evaluation of TuneUp on two GNN architectures, three types of prediction tasks, and both inductive and transductive settings shows that TuneUp significantly improves the performance of the base GNN on tail nodes, while often even improving the performance on head nodes, which together leads up to 58.5% relative improvement in GNN predictive performance. Moreover, TuneUp significantly outperforms its variants without the two-stage curriculum learning, existing graph data augmentation techniques, as well as other specialized methods for tail nodes.","Weihua Hu, Kaidi Cao, Kexin Huang, Edward W Huang, Karthik Subbian, Jure Leskovec",,"Graph Neural Networks, Curriculum learning, Tail nodes",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=8xuFD1yCoH,https://openreview.net/forum?id=8xuFD1yCoH,"~Weihua_Hu1, ~Kaidi_Cao1, ~Kexin_Huang1, ~Edward_W_Huang1, ~Karthik_Subbian1, ~Jure_Leskovec1",1.66E+12
rqzZDh8jqGj,Experimental Design for Overparameterized Learning with Application to Single Shot Deep Active Learning,"Abstract The impressive performance exhibited by modern machine learning models hinges on the ability to train such models on a very large amounts of labeled data. However, since access to large volumes of labeled data is often limited or expensive, it is desirable to alleviate this bottleneck by carefully curating the training set. Optimal experimental design is a well-established paradigm for selecting data point to be labeled so to maximally inform the learning process. Unfortunately, classical theory on optimal experimental design focuses on selecting examples in order to learn underparameterized (and thus, non-interpolative) models, while modern machine learning models such as deep neural networks are overparameterized, and oftentimes are trained to be interpolative. As such, classical experimental design methods are not applicable in many modern learning setups. Indeed, the predictive performance of underparameterized models tends to be variance dominated, so classical experimental design focuses on variance reduction, while the predictive performance of overparameterized models can also be, as is shown in this paper, bias dominated or of mixed nature. In this paper we propose a design strategy that is well suited for overparameterized regression and interpolation, and we demonstrate the applicability of our method in the context of deep learning by proposing a new algorithm for single shot deep active learning.","Neta Shoham, Haim Avron",,,,ICLR.cc/2021/Conference,2021,https://openreview.net/pdf?id=rqzZDh8jqGj,https://openreview.net/forum?id=rqzZDh8jqGj,"~Neta_Shoham1, ~Haim_Avron4",1.60E+12
yLv6eSBmA-,Adversarial Detector for Decision Tree Ensembles Using Representation Learning,"Research on adversarial evasion attacks focuses mainly on neural network models. Among other reasons, this is because of their popularity in certain fields (e.g., computer vision and NLP) and the models' properties, making it easier to search for adversarial examples with minimal input change. Decision trees and tree ensembles are still very popular due to their high
performance in fields dominated by tabular data and their explainability. In recent years, several works have defined new adversarial attacks targeting decision trees and tree ensembles. As a result, several papers were published focusing on robust versions of tree ensembles. This research aims to create an adversarial detector for attacks on an ensemble of decision trees. While several previous works have demonstrated the generation of more robust tree ensembles, the process of considering evasion attacks during ensemble generation can affect model performance. We demonstrate a method to detect adversarial samples without affecting either the target model structure or its original performance. We showed that by using representation learning based on the structure of the trees, we achieved better detection rates than the state-of-the-art technique and better than using the original representation of the dataset to train an adversarial detector.","Gal Braun, Lior Rokach",,"Machine Learning, Representation Learning, Adversarial Learning, Evasion Attacks, Adversarial Detection, Tree Ensembles, Decision Trees",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=yLv6eSBmA-,https://openreview.net/forum?id=yLv6eSBmA-,"~Gal_Braun1, ~Lior_Rokach2",1.66E+12
V6BjBgku7Ro,Planning from Pixels using Inverse Dynamics Models,"Learning dynamics models in high-dimensional observation spaces can be challenging for model-based RL agents. We propose a novel way to learn models in a latent space by learning to predict sequences of future actions conditioned on task completion. These models track task-relevant environment dynamics over a distribution of tasks, while simultaneously serving as an effective heuristic for planning with sparse rewards. We evaluate our method on challenging visual goal completion tasks and show a substantial increase in performance compared to prior model-free approaches.","Keiran Paster, Sheila A. McIlraith, Jimmy Ba",,"model based reinforcement learning, deep reinforcement learning, multi-task learning, deep learning, goal-conditioned reinforcement learning",,ICLR.cc/2021/Conference,2021,https://openreview.net/pdf?id=V6BjBgku7Ro,https://openreview.net/forum?id=V6BjBgku7Ro,"~Keiran_Paster1, ~Sheila_A._McIlraith1, ~Jimmy_Ba1",1.60E+12
hqkN6lE1fFQ,Kernel Deformed Exponential Families for Sparse Continuous Attention,"Attention mechanisms take an expectation of a data representation with respect to probability weights. This creates summary statistics that focus on important features. Recently, Martins et al. (2020, 2021) proposed continuous attention mechanisms, focusing on unimodal attention densities from the exponential and deformed exponential families: the latter has sparse support. Farinhas et al. (2021) extended this to use Gaussian mixture attention densities, which are a flexible class with dense support. In this paper, we extend this to two general flexible classes: kernel exponential families and our new sparse counterpart kernel deformed exponential families. Theoretically, we show new existence results for both kernel exponential and deformed exponential families, and that the deformed case has similar approximation capabilities to kernel exponential families. Experiments show that kernel deformed exponential families can attend to non-overlapping intervals of time.","Alexander Moreno, Supriya Nagesh, Zhenke Wu, Walter Dempsey, James Matthew Rehg",,"kernel methods, attention mechanism, theory, exponential families, deformed exponential families",,ICLR.cc/2022/Conference,2022,https://openreview.net/pdf?id=hqkN6lE1fFQ,https://openreview.net/forum?id=hqkN6lE1fFQ,"~Alexander_Moreno1, ~Supriya_Nagesh1, ~Zhenke_Wu1, wdem@umich.edu, ~James_Matthew_Rehg1",1.63E+12
Dk7QQp8jHEo,Batch Multivalid Conformal Prediction,"We develop  fast distribution-free conformal prediction algorithms for obtaining multivalid coverage on exchangeable data in the batch setting. Multivalid coverage guarantees are stronger than marginal coverage guarantees in two ways: (1) They hold even conditional on group membership---that is, the target coverage level $1-\alpha$ holds conditionally on membership in each of an arbitrary (potentially intersecting) group in a finite collection $\mathcal{G}$ of regions in the feature space. (2) They hold even conditional on the value of the threshold used to produce the prediction set on a given example. In fact multivalid coverage guarantees hold even when conditioning on group membership and threshold value simultaneously.

We give two algorithms: both take as input an arbitrary non-conformity score and an arbitrary collection of possibly intersecting groups $\mathcal{G}$, and then can equip arbitrary black-box predictors with prediction sets.  Our first algorithm is a direct extension of quantile regression, needs to solve only a single convex minimization problem, and produces an estimator which has group-conditional guarantees for each group in $\mathcal{G}$. Our second algorithm is iterative, and gives the full guarantees of multivalid conformal prediction: prediction sets that are valid conditionally both on group membership and non-conformity threshold. We evaluate the performance of both of our algorithms in an extensive set of experiments.","Christopher Jung, Georgy Noarov, Ramya Ramalingam, Aaron Roth",,"Conformal prediction, multicalibration, uncertainty quantification",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=Dk7QQp8jHEo,https://openreview.net/forum?id=Dk7QQp8jHEo,"~Christopher_Jung1, ~Georgy_Noarov1, ~Ramya_Ramalingam1, ~Aaron_Roth1",1.66E+12
H1g79ySYvB,Revisiting Gradient Episodic Memory for Continual Learning,"Gradient Episodic Memory (GEM) is an effective model for continual learning, where each gradient update for the current task is formulated as a quadratic program problem with inequality constraints that alleviate catastrophic forgetting of previous tasks. However, practical use of GEM is impeded by several limitations: (1) the data examples stored in the episodic memory may not be representative of past tasks; (2)  the inequality constraints appear to be rather restrictive for competing or conflicting tasks; (3) the inequality constraints can only avoid catastrophic forgetting but can not assure positive backward transfer. To address these issues, in this paper we aim at improving the original GEM model via three handy techniques without extra computational cost. Experiments on MNIST Permutations and incremental CIFAR100 datasets demonstrate that our techniques enhance the performance of GEM remarkably. On CIFAR100 the average accuracy is improved from 66.48% to 68.76%, along with the backward (knowledge) transfer growing from 1.38% to 4.03%.","Zhiyi Chen, Tong Lin*",,,,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=H1g79ySYvB,https://openreview.net/forum?id=H1g79ySYvB,"chenzhiy16@mails.tsinghua.edu.cn, lintong@pku.edu.cn",1.57E+12
Ojpb1y8jflw,StyleMorph: Disentangled 3D-Aware Image Synthesis with a 3D Morphable StyleGAN,"We introduce StyleMorph, a 3D-aware generative model that disentangles 3D shape, camera pose, object appearance, and background appearance for high quality image synthesis. We account for shape variability by morphing a canonical 3D object template, effectively learning a 3D morphable model in an entirely unsupervised manner through backprop. We chain 3D morphable modelling with deferred neural rendering by performing an implicit surface rendering of “Template Object Coordinates” (TOCS), which can be understood as an unsupervised counterpart to UV maps. This provides a detailed 2D TOCS map signal that reflects the compounded geometric effects of non-rigid shape variation, camera pose, and perspective projection. We combine 2D TOCS maps with an independent appearance code to condition a StyleGAN-based deferred neural rendering (DNR) network for foreground image (object) synthesis; we use a separate code for background synthesis and do late fusion to deliver the final result. We show competitive synthesis results on 4 datasets (FFHQ faces, AFHQ Cats, Dogs, Wild), while achieving the joint disentanglement of shape, pose, object and background texture.","Eric-Tuan Le, Edward Bartrum, Iasonas Kokkinos",,"3D-aware GAN, Template-based, Morphable, Disentanglement, Photorealistic, Neural Radiance Field, StyleGAN",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=Ojpb1y8jflw,https://openreview.net/forum?id=Ojpb1y8jflw,"~Eric-Tuan_Le1, ~Edward_Bartrum1, ~Iasonas_Kokkinos1",1.66E+12
SkxWnkStvS,Searching for Stage-wise Neural Graphs In the Limit,"Search space is a key consideration for neural architecture search. Recently, Xie et al. (2019a) found that randomly generated networks from the same distribution perform similarly, which suggest we should search for random graph distributions instead of graphs. We propose graphon as a new search space. A graphon is the limit of Cauchy sequence of graphs and a scale-free probabilistic distribution, from which graphs of different number of vertices can be drawn. This property enables us to perform NAS using fast, low-capacity models and scale the found models up when necessary. We develop an algorithm for NAS in the space of graphons and empirically demonstrate that it can find stage-wise graphs that outperform DenseNet and other baselines on ImageNet.","Xin Zhou, Dejing Dou, Boyang Li",,"neural architecture search, graphon, random graphs",,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=SkxWnkStvS,https://openreview.net/forum?id=SkxWnkStvS,"chow459@gmail.com, doudejing@baidu.com, libo0001@gmail.com",1.57E+12
xYGNO86OWDH,Isotropy in the Contextual Embedding Space: Clusters and Manifolds,"The geometric properties of contextual embedding spaces for deep language models such as BERT and ERNIE, have attracted considerable attention in recent years. Investigations on the contextual embeddings demonstrate a strong anisotropic space such that most of the vectors fall within a narrow cone, leading to high cosine similarities.  It is surprising that these LMs are as successful as they are, given that most of their embedding vectors are as similar to one another as they are. In this paper, we argue that the isotropy indeed exists in the space, from a different but more constructive perspective. We identify isolated clusters and low dimensional manifolds in the contextual embedding space, and introduce tools to both qualitatively and quantitatively analyze them. We hope the study in this paper could provide insights towards a better understanding of the deep language models.","Xingyu Cai, Jiaji Huang, Yuchen Bian, Kenneth Church",,"Contextual embedding space, Isotropy, Clusters, Manifolds",,ICLR.cc/2021/Conference,2021,https://openreview.net/pdf?id=xYGNO86OWDH,https://openreview.net/forum?id=xYGNO86OWDH,"~Xingyu_Cai1, ~Jiaji_Huang1, ~Yuchen_Bian1, ~Kenneth_Church1",1.60E+12
arg1dQSS6Mh,Attribute Alignment and Enhancement for Generalized Zero-Shot Learning,"Generalized zero-shot learning (GZSL) aims to recognize both seen and unseen classes, which challenges the generalization ability of a model. In this paper, we propose a novel approach to fully utilize attributes information, referred to as attribute alignment and enhancement (A3E) network. It contains two modules. First, attribute localization (AL) module utilizes the supervision of class attribute vectors to guide visual localization for attributes through the implicit localization capability within the feature extractor, and the visual features corresponding to the attributes (attribute-visual features) are obtained. Second, enhanced attribute scoring (EAS) module employs the supervision of the attribute word vectors (attribute semantics) to project input attribute visual features to attribute semantic space using Graph Attention Network (GAT). Based on the constructed attribute relation graph (ARG), EAS module generates enhanced representation of attributes. Experiments on standard datasets demonstrate that the enhanced attribute representation greatly improves the classification performance, which helps A3E to achieve state-of-the-art performances in both ZSL and GZSL tasks.","Nannan Lu, MingKai Qiu",,"zero-shot learning, image classification, attribute alignment, graph neural network, attention network",,ICLR.cc/2023/Conference,2023,https://openreview.net/pdf?id=arg1dQSS6Mh,https://openreview.net/forum?id=arg1dQSS6Mh,"~Nannan_Lu1, ~MingKai_Qiu1",1.66E+12
S1ecYANtPr,Representation Learning Through Latent Canonicalizations,"We seek to learn a representation on a large annotated data source that generalizes to a target domain using limited new supervision. Many prior approaches to this problem have focused on learning disentangled representations so that as individual factors vary in a new domain, only a portion of the representation need be updated. In this work, we seek the generalization power of disentangled representations, but relax the requirement of explicit latent disentanglement and instead encourage linearity of individual factors of variation by requiring them to be manipulable by learned linear transformations. We dub these transformations latent canonicalizers, as they aim to modify the value of a factor to a pre-determined (but arbitrary) canonical value (e.g., recoloring the image foreground to black). Assuming a source domain with access to meta-labels specifying the factors of variation within an image, we demonstrate experimentally that our method helps reduce the number of observations needed to generalize to a similar target domain when compared to a number of supervised baselines. ","Or Litany, Ari Morcos, Srinath Sridhar, Leonidas Guibas, Judy Hoffman",,"representation learning, latent canonicalization, sim2real, few shot, disentanglement",,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=S1ecYANtPr,https://openreview.net/forum?id=S1ecYANtPr,"orlitany@gmail.com, arimorcos@gmail.com, ssrinath@cs.stanford.edu, guibas@cs.stanford.edu, judy@gatech.edu",1.57E+12
HyeJmlrFvH,Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization,"As the size and complexity of models and datasets grow, so does the need for communication-efficient variants of stochastic gradient descent that can be deployed on clusters to perform model fitting in parallel. Alistarh et al. (2017) describe two variants of data-parallel SGD that quantize and encode gradients to lessen communication costs. For the first variant, QSGD, they provide strong theoretical guarantees. For the second variant, which we call QSGDinf, they demonstrate impressive empirical gains for distributed training of large neural networks. Building on their work, we propose an alternative scheme for quantizing gradients and show that it yields stronger theoretical guarantees than exist for QSGD while matching the empirical performance of QSGDinf.","Ali Ramezani-Kebrya, Fartash Faghri, Ilya Markov, Vitalii Aksenov, Dan Alistarh, Daniel M. Roy",,,,ICLR.cc/2020/Conference,2020,https://openreview.net/pdf?id=HyeJmlrFvH,https://openreview.net/forum?id=HyeJmlrFvH,"alir@vectorinstitute.ai, faghri@cs.toronto.edu, droy@utstat.toronto.edu, dan.alistarh@ist.ac.at, markovilya197@gmail.com, vitalii.aksenov@ist.ac.at",1.57E+12
